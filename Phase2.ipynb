{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AIProjectPhase2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPjp0ylZ0/wdj+lMy8zSdn4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sirishanarayansa/AI/blob/main/Phase2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mRNgwRguLVx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb69eea9-eec7-4102-a7f7-88b0605b6964"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/sirishanarayansa/AI/main/winequality-red0.csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-24 15:51:44--  https://raw.githubusercontent.com/sirishanarayansa/AI/main/winequality-red0.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 85733 (84K) [text/plain]\n",
            "Saving to: ‘winequality-red0.csv.2’\n",
            "\n",
            "winequality-red0.cs 100%[===================>]  83.72K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2021-04-24 15:51:44 (5.47 MB/s) - ‘winequality-red0.csv.2’ saved [85733/85733]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMfCJctCuZKe"
      },
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('winequality-red0.csv', delimiter = ',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Jz9_0QL1ue58",
        "outputId": "e9a3da3a-76d0-4b27-c4c6-ef0346e58173"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixedAcidity</th>\n",
              "      <th>volatileAcidity</th>\n",
              "      <th>citricAcid</th>\n",
              "      <th>residualSugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>freeSulfurDioxide</th>\n",
              "      <th>totalSulfurDioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.9978</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.6</td>\n",
              "      <td>0.098</td>\n",
              "      <td>25.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0.9968</td>\n",
              "      <td>3.20</td>\n",
              "      <td>0.68</td>\n",
              "      <td>9.8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.04</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0.092</td>\n",
              "      <td>15.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0.9970</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.65</td>\n",
              "      <td>9.8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.2</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.075</td>\n",
              "      <td>17.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.9980</td>\n",
              "      <td>3.16</td>\n",
              "      <td>0.58</td>\n",
              "      <td>9.8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.9978</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   fixedAcidity  volatileAcidity  citricAcid  ...  sulphates  alcohol  quality\n",
              "0           7.4             0.70        0.00  ...       0.56      9.4        0\n",
              "1           7.8             0.88        0.00  ...       0.68      9.8        0\n",
              "2           7.8             0.76        0.04  ...       0.65      9.8        0\n",
              "3          11.2             0.28        0.56  ...       0.58      9.8        1\n",
              "4           7.4             0.70        0.00  ...       0.56      9.4        0\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YoPu6AwwulqN",
        "outputId": "7e1f5713-28de-4754-9fd8-64f857c3d6ce"
      },
      "source": [
        "print(data.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1599, 12)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J41CCbD2utRz"
      },
      "source": [
        "import numpy as np\n",
        "dataset = np.genfromtxt('winequality-red0.csv', delimiter = ',', skip_header = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNAGXZO6uyGc",
        "outputId": "57728b0a-1138-4b61-e808-764c437a5fe6"
      },
      "source": [
        "print(dataset.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1599, 12)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fpLrZC5u2ZO"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCs5QcAjHTet"
      },
      "source": [
        "np.set_printoptions(formatter = {'float': '{: 0.2f}'.format})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxhvKsh2u8sD"
      },
      "source": [
        "X = dataset[:,]\n",
        "Y = dataset[:,-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yT3F2D4nvkQI",
        "outputId": "fb01d09b-a43e-4082-eb75-3732ae618979"
      },
      "source": [
        "print(X.shape , Y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1599, 12) (1599,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_DT8MYavpO3",
        "outputId": "19c92faf-9e76-41d9-b70a-94ae21118df2"
      },
      "source": [
        "print(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 7.40  0.70  0.00 ...  0.56  9.40  0.00]\n",
            " [ 7.80  0.88  0.00 ...  0.68  9.80  0.00]\n",
            " [ 7.80  0.76  0.04 ...  0.65  9.80  0.00]\n",
            " ...\n",
            " [ 6.30  0.51  0.13 ...  0.75  11.00  1.00]\n",
            " [ 5.90  0.65  0.12 ...  0.71  10.20  0.00]\n",
            " [ 6.00  0.31  0.47 ...  0.66  11.00  1.00]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ql8BgjTG3rk"
      },
      "source": [
        "min = X.min(axis = 0) \n",
        "max = X.max(axis = 0) \n",
        "X = (X - min) / (max - min)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUWjtuMvG-yn",
        "outputId": "f1c76580-ecba-4cda-ebce-6a2c04f965ff"
      },
      "source": [
        "print(X[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.25  0.40  0.00  0.07  0.11  0.14  0.10  0.57  0.61  0.14  0.15  0.00]\n",
            " [ 0.28  0.52  0.00  0.12  0.14  0.34  0.22  0.49  0.36  0.21  0.22  0.00]\n",
            " [ 0.28  0.44  0.04  0.10  0.13  0.20  0.17  0.51  0.41  0.19  0.22  0.00]\n",
            " [ 0.58  0.11  0.56  0.07  0.11  0.23  0.19  0.58  0.33  0.15  0.22  1.00]\n",
            " [ 0.25  0.40  0.00  0.07  0.11  0.14  0.10  0.57  0.61  0.14  0.15  0.00]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2u_EYDCiHIgG"
      },
      "source": [
        "import random\n",
        "np.random.shuffle(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cd1XLHMHxmE",
        "outputId": "20ca6e2f-8cfc-41fa-f251-ed4d98bd480e"
      },
      "source": [
        "print(X[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.13  0.14  0.25  0.10  0.10  0.31  0.18  0.46  0.54  0.38  0.34  0.00]\n",
            " [ 0.47  0.16  0.55  0.08  0.08  0.06  0.03  0.52  0.41  0.28  0.34  0.00]\n",
            " [ 0.70  0.18  0.60  0.12  0.12  0.42  0.23  0.70  0.28  0.24  0.32  0.00]\n",
            " [ 0.73  0.16  0.49  0.34  0.09  0.06  0.10  0.83  0.36  0.20  0.55  1.00]\n",
            " [ 0.13  0.14  0.25  0.10  0.10  0.31  0.18  0.46  0.54  0.38  0.34  0.00]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqEcUKITH1KN",
        "outputId": "90ba42c9-35a4-44ce-b318-53f9ce3bf0e4"
      },
      "source": [
        "index_30percent = int(0.3 * len(X[:, 0]))\n",
        "print(index_30percent)\n",
        "XVALID = X[:index_30percent, :-1]\n",
        "YVALID = X[:index_30percent, -1]\n",
        "XTRAIN = X[index_30percent:, :-1]\n",
        "YTRAIN = X[index_30percent:, -1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "479\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LUPITWzGW0g",
        "outputId": "3d60f762-f30c-4f03-e45d-72bba04badf0"
      },
      "source": [
        "high = len(YVALID) - sum(YVALID)\n",
        "print(\"Baseline accuracy : \",high/len(YVALID))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Baseline accuracy :  0.4759916492693111\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7xpK_EpKHTh",
        "outputId": "1e12650b-11da-4089-a0a2-4ed8ab39dd54"
      },
      "source": [
        "print(XTRAIN)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.23  0.27  0.07 ...  0.46  0.29  0.18]\n",
            " [ 0.00  0.27  0.15 ...  0.91  0.14  0.72]\n",
            " [ 0.22  0.43  0.01 ...  0.51  0.04  0.68]\n",
            " ...\n",
            " [ 0.23  0.15  0.24 ...  0.55  0.15  0.26]\n",
            " [ 0.25  0.26  0.47 ...  0.49  0.14  0.11]\n",
            " [ 0.27  0.23  0.11 ...  0.37  0.14  0.25]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATSKufxkJW0Z"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnyenP_cJAFm"
      },
      "source": [
        "model_0 = Sequential()\n",
        "model_0.add(Dense(1, input_dim = len(XTRAIN[0, :]), activation='sigmoid'))\n",
        "model_0.compile(loss='binary_crossentropy', optimizer = 'rmsprop', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kGYAVshJkj8",
        "outputId": "72b18e2e-95da-4636-cc12-a60543435616"
      },
      "source": [
        "history_0 = model_0.fit(XTRAIN, YTRAIN, validation_data=(XVALID, YVALID), epochs = 1000, batch_size=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "112/112 [==============================] - 1s 3ms/step - loss: 0.7144 - accuracy: 0.5180 - val_loss: 0.6892 - val_accuracy: 0.5324\n",
            "Epoch 2/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6943 - accuracy: 0.5299 - val_loss: 0.6801 - val_accuracy: 0.5511\n",
            "Epoch 3/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6796 - accuracy: 0.5478 - val_loss: 0.6738 - val_accuracy: 0.5783\n",
            "Epoch 4/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6773 - accuracy: 0.5773 - val_loss: 0.6685 - val_accuracy: 0.5992\n",
            "Epoch 5/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6721 - accuracy: 0.5949 - val_loss: 0.6642 - val_accuracy: 0.6159\n",
            "Epoch 6/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6627 - accuracy: 0.6148 - val_loss: 0.6604 - val_accuracy: 0.6159\n",
            "Epoch 7/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6647 - accuracy: 0.6109 - val_loss: 0.6564 - val_accuracy: 0.6263\n",
            "Epoch 8/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6666 - accuracy: 0.6173 - val_loss: 0.6529 - val_accuracy: 0.6284\n",
            "Epoch 9/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6531 - accuracy: 0.6619 - val_loss: 0.6498 - val_accuracy: 0.6326\n",
            "Epoch 10/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6546 - accuracy: 0.6396 - val_loss: 0.6461 - val_accuracy: 0.6388\n",
            "Epoch 11/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6492 - accuracy: 0.6772 - val_loss: 0.6430 - val_accuracy: 0.6493\n",
            "Epoch 12/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6404 - accuracy: 0.6758 - val_loss: 0.6399 - val_accuracy: 0.6493\n",
            "Epoch 13/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6440 - accuracy: 0.6573 - val_loss: 0.6369 - val_accuracy: 0.6514\n",
            "Epoch 14/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6456 - accuracy: 0.6498 - val_loss: 0.6340 - val_accuracy: 0.6597\n",
            "Epoch 15/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6408 - accuracy: 0.6603 - val_loss: 0.6307 - val_accuracy: 0.6639\n",
            "Epoch 16/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6359 - accuracy: 0.6575 - val_loss: 0.6279 - val_accuracy: 0.6764\n",
            "Epoch 17/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6336 - accuracy: 0.6736 - val_loss: 0.6252 - val_accuracy: 0.6743\n",
            "Epoch 18/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6225 - accuracy: 0.7086 - val_loss: 0.6225 - val_accuracy: 0.6848\n",
            "Epoch 19/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6301 - accuracy: 0.6921 - val_loss: 0.6200 - val_accuracy: 0.6827\n",
            "Epoch 20/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6155 - accuracy: 0.7221 - val_loss: 0.6178 - val_accuracy: 0.6806\n",
            "Epoch 21/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6188 - accuracy: 0.7000 - val_loss: 0.6156 - val_accuracy: 0.6806\n",
            "Epoch 22/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6220 - accuracy: 0.6826 - val_loss: 0.6132 - val_accuracy: 0.6910\n",
            "Epoch 23/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6179 - accuracy: 0.6862 - val_loss: 0.6109 - val_accuracy: 0.6973\n",
            "Epoch 24/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6059 - accuracy: 0.7365 - val_loss: 0.6088 - val_accuracy: 0.7015\n",
            "Epoch 25/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6044 - accuracy: 0.7189 - val_loss: 0.6067 - val_accuracy: 0.7056\n",
            "Epoch 26/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5996 - accuracy: 0.7260 - val_loss: 0.6045 - val_accuracy: 0.7035\n",
            "Epoch 27/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6051 - accuracy: 0.7221 - val_loss: 0.6026 - val_accuracy: 0.7119\n",
            "Epoch 28/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6130 - accuracy: 0.7184 - val_loss: 0.6009 - val_accuracy: 0.7098\n",
            "Epoch 29/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6101 - accuracy: 0.7034 - val_loss: 0.5992 - val_accuracy: 0.7182\n",
            "Epoch 30/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5903 - accuracy: 0.7464 - val_loss: 0.5974 - val_accuracy: 0.7161\n",
            "Epoch 31/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5919 - accuracy: 0.7305 - val_loss: 0.5957 - val_accuracy: 0.7077\n",
            "Epoch 32/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5916 - accuracy: 0.7420 - val_loss: 0.5939 - val_accuracy: 0.7098\n",
            "Epoch 33/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5917 - accuracy: 0.7456 - val_loss: 0.5922 - val_accuracy: 0.7119\n",
            "Epoch 34/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5835 - accuracy: 0.7455 - val_loss: 0.5905 - val_accuracy: 0.7182\n",
            "Epoch 35/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5939 - accuracy: 0.7326 - val_loss: 0.5889 - val_accuracy: 0.7223\n",
            "Epoch 36/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5798 - accuracy: 0.7487 - val_loss: 0.5873 - val_accuracy: 0.7182\n",
            "Epoch 37/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5920 - accuracy: 0.7407 - val_loss: 0.5858 - val_accuracy: 0.7223\n",
            "Epoch 38/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5941 - accuracy: 0.7159 - val_loss: 0.5845 - val_accuracy: 0.7203\n",
            "Epoch 39/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5935 - accuracy: 0.7223 - val_loss: 0.5831 - val_accuracy: 0.7203\n",
            "Epoch 40/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5887 - accuracy: 0.7359 - val_loss: 0.5817 - val_accuracy: 0.7203\n",
            "Epoch 41/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5898 - accuracy: 0.7324 - val_loss: 0.5804 - val_accuracy: 0.7203\n",
            "Epoch 42/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5862 - accuracy: 0.7353 - val_loss: 0.5791 - val_accuracy: 0.7265\n",
            "Epoch 43/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5842 - accuracy: 0.7340 - val_loss: 0.5778 - val_accuracy: 0.7328\n",
            "Epoch 44/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5674 - accuracy: 0.7549 - val_loss: 0.5766 - val_accuracy: 0.7286\n",
            "Epoch 45/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5893 - accuracy: 0.7183 - val_loss: 0.5756 - val_accuracy: 0.7265\n",
            "Epoch 46/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5717 - accuracy: 0.7296 - val_loss: 0.5744 - val_accuracy: 0.7286\n",
            "Epoch 47/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5775 - accuracy: 0.7342 - val_loss: 0.5732 - val_accuracy: 0.7370\n",
            "Epoch 48/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5726 - accuracy: 0.7343 - val_loss: 0.5721 - val_accuracy: 0.7370\n",
            "Epoch 49/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5706 - accuracy: 0.7249 - val_loss: 0.5709 - val_accuracy: 0.7328\n",
            "Epoch 50/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5864 - accuracy: 0.7248 - val_loss: 0.5698 - val_accuracy: 0.7328\n",
            "Epoch 51/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5695 - accuracy: 0.7282 - val_loss: 0.5689 - val_accuracy: 0.7328\n",
            "Epoch 52/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5643 - accuracy: 0.7433 - val_loss: 0.5679 - val_accuracy: 0.7307\n",
            "Epoch 53/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5699 - accuracy: 0.7371 - val_loss: 0.5668 - val_accuracy: 0.7328\n",
            "Epoch 54/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5852 - accuracy: 0.7123 - val_loss: 0.5661 - val_accuracy: 0.7286\n",
            "Epoch 55/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5609 - accuracy: 0.7491 - val_loss: 0.5651 - val_accuracy: 0.7328\n",
            "Epoch 56/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5561 - accuracy: 0.7452 - val_loss: 0.5640 - val_accuracy: 0.7370\n",
            "Epoch 57/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5603 - accuracy: 0.7440 - val_loss: 0.5631 - val_accuracy: 0.7411\n",
            "Epoch 58/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5688 - accuracy: 0.7389 - val_loss: 0.5624 - val_accuracy: 0.7370\n",
            "Epoch 59/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5652 - accuracy: 0.7429 - val_loss: 0.5615 - val_accuracy: 0.7390\n",
            "Epoch 60/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5619 - accuracy: 0.7363 - val_loss: 0.5607 - val_accuracy: 0.7390\n",
            "Epoch 61/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5622 - accuracy: 0.7437 - val_loss: 0.5600 - val_accuracy: 0.7349\n",
            "Epoch 62/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5682 - accuracy: 0.7326 - val_loss: 0.5592 - val_accuracy: 0.7411\n",
            "Epoch 63/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5643 - accuracy: 0.7236 - val_loss: 0.5585 - val_accuracy: 0.7411\n",
            "Epoch 64/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5444 - accuracy: 0.7421 - val_loss: 0.5579 - val_accuracy: 0.7349\n",
            "Epoch 65/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5604 - accuracy: 0.7236 - val_loss: 0.5570 - val_accuracy: 0.7390\n",
            "Epoch 66/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5526 - accuracy: 0.7387 - val_loss: 0.5563 - val_accuracy: 0.7390\n",
            "Epoch 67/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5561 - accuracy: 0.7351 - val_loss: 0.5555 - val_accuracy: 0.7390\n",
            "Epoch 68/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5654 - accuracy: 0.7019 - val_loss: 0.5547 - val_accuracy: 0.7390\n",
            "Epoch 69/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 0.7445 - val_loss: 0.5542 - val_accuracy: 0.7370\n",
            "Epoch 70/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5597 - accuracy: 0.7352 - val_loss: 0.5537 - val_accuracy: 0.7390\n",
            "Epoch 71/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5704 - accuracy: 0.7186 - val_loss: 0.5530 - val_accuracy: 0.7390\n",
            "Epoch 72/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5548 - accuracy: 0.7306 - val_loss: 0.5523 - val_accuracy: 0.7370\n",
            "Epoch 73/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5449 - accuracy: 0.7378 - val_loss: 0.5517 - val_accuracy: 0.7411\n",
            "Epoch 74/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5513 - accuracy: 0.7447 - val_loss: 0.5511 - val_accuracy: 0.7390\n",
            "Epoch 75/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5446 - accuracy: 0.7261 - val_loss: 0.5506 - val_accuracy: 0.7390\n",
            "Epoch 76/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5502 - accuracy: 0.7443 - val_loss: 0.5501 - val_accuracy: 0.7411\n",
            "Epoch 77/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5509 - accuracy: 0.7290 - val_loss: 0.5495 - val_accuracy: 0.7390\n",
            "Epoch 78/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5471 - accuracy: 0.7435 - val_loss: 0.5490 - val_accuracy: 0.7411\n",
            "Epoch 79/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5371 - accuracy: 0.7604 - val_loss: 0.5484 - val_accuracy: 0.7390\n",
            "Epoch 80/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5711 - accuracy: 0.7049 - val_loss: 0.5478 - val_accuracy: 0.7390\n",
            "Epoch 81/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5591 - accuracy: 0.7395 - val_loss: 0.5473 - val_accuracy: 0.7390\n",
            "Epoch 82/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5589 - accuracy: 0.7199 - val_loss: 0.5468 - val_accuracy: 0.7390\n",
            "Epoch 83/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5365 - accuracy: 0.7543 - val_loss: 0.5464 - val_accuracy: 0.7370\n",
            "Epoch 84/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5653 - accuracy: 0.7155 - val_loss: 0.5461 - val_accuracy: 0.7349\n",
            "Epoch 85/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5679 - accuracy: 0.7139 - val_loss: 0.5455 - val_accuracy: 0.7370\n",
            "Epoch 86/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5398 - accuracy: 0.7452 - val_loss: 0.5451 - val_accuracy: 0.7370\n",
            "Epoch 87/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5389 - accuracy: 0.7406 - val_loss: 0.5447 - val_accuracy: 0.7411\n",
            "Epoch 88/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5554 - accuracy: 0.7346 - val_loss: 0.5442 - val_accuracy: 0.7411\n",
            "Epoch 89/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5312 - accuracy: 0.7437 - val_loss: 0.5438 - val_accuracy: 0.7411\n",
            "Epoch 90/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5482 - accuracy: 0.7355 - val_loss: 0.5434 - val_accuracy: 0.7411\n",
            "Epoch 91/1000\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.5484 - accuracy: 0.7518 - val_loss: 0.5429 - val_accuracy: 0.7432\n",
            "Epoch 92/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5495 - accuracy: 0.7279 - val_loss: 0.5425 - val_accuracy: 0.7432\n",
            "Epoch 93/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5456 - accuracy: 0.7375 - val_loss: 0.5422 - val_accuracy: 0.7432\n",
            "Epoch 94/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5404 - accuracy: 0.7208 - val_loss: 0.5419 - val_accuracy: 0.7411\n",
            "Epoch 95/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5368 - accuracy: 0.7425 - val_loss: 0.5414 - val_accuracy: 0.7432\n",
            "Epoch 96/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5387 - accuracy: 0.7475 - val_loss: 0.5411 - val_accuracy: 0.7432\n",
            "Epoch 97/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5574 - accuracy: 0.7173 - val_loss: 0.5408 - val_accuracy: 0.7432\n",
            "Epoch 98/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5511 - accuracy: 0.7275 - val_loss: 0.5403 - val_accuracy: 0.7453\n",
            "Epoch 99/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5514 - accuracy: 0.7307 - val_loss: 0.5401 - val_accuracy: 0.7432\n",
            "Epoch 100/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5587 - accuracy: 0.7281 - val_loss: 0.5399 - val_accuracy: 0.7411\n",
            "Epoch 101/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5474 - accuracy: 0.7206 - val_loss: 0.5395 - val_accuracy: 0.7432\n",
            "Epoch 102/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5298 - accuracy: 0.7576 - val_loss: 0.5392 - val_accuracy: 0.7453\n",
            "Epoch 103/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5460 - accuracy: 0.7268 - val_loss: 0.5389 - val_accuracy: 0.7453\n",
            "Epoch 104/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5375 - accuracy: 0.7417 - val_loss: 0.5386 - val_accuracy: 0.7453\n",
            "Epoch 105/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5430 - accuracy: 0.7216 - val_loss: 0.5383 - val_accuracy: 0.7453\n",
            "Epoch 106/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5322 - accuracy: 0.7522 - val_loss: 0.5380 - val_accuracy: 0.7495\n",
            "Epoch 107/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5548 - accuracy: 0.7287 - val_loss: 0.5377 - val_accuracy: 0.7495\n",
            "Epoch 108/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5253 - accuracy: 0.7486 - val_loss: 0.5373 - val_accuracy: 0.7495\n",
            "Epoch 109/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5293 - accuracy: 0.7475 - val_loss: 0.5371 - val_accuracy: 0.7495\n",
            "Epoch 110/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5522 - accuracy: 0.7269 - val_loss: 0.5368 - val_accuracy: 0.7495\n",
            "Epoch 111/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5444 - accuracy: 0.7377 - val_loss: 0.5365 - val_accuracy: 0.7495\n",
            "Epoch 112/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5613 - accuracy: 0.7325 - val_loss: 0.5362 - val_accuracy: 0.7474\n",
            "Epoch 113/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5411 - accuracy: 0.7374 - val_loss: 0.5359 - val_accuracy: 0.7474\n",
            "Epoch 114/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5396 - accuracy: 0.7489 - val_loss: 0.5356 - val_accuracy: 0.7453\n",
            "Epoch 115/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5430 - accuracy: 0.7450 - val_loss: 0.5354 - val_accuracy: 0.7495\n",
            "Epoch 116/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5443 - accuracy: 0.7307 - val_loss: 0.5352 - val_accuracy: 0.7495\n",
            "Epoch 117/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5477 - accuracy: 0.7390 - val_loss: 0.5352 - val_accuracy: 0.7495\n",
            "Epoch 118/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5330 - accuracy: 0.7514 - val_loss: 0.5348 - val_accuracy: 0.7495\n",
            "Epoch 119/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5523 - accuracy: 0.7355 - val_loss: 0.5345 - val_accuracy: 0.7495\n",
            "Epoch 120/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5378 - accuracy: 0.7278 - val_loss: 0.5343 - val_accuracy: 0.7474\n",
            "Epoch 121/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5172 - accuracy: 0.7627 - val_loss: 0.5341 - val_accuracy: 0.7474\n",
            "Epoch 122/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5325 - accuracy: 0.7520 - val_loss: 0.5339 - val_accuracy: 0.7495\n",
            "Epoch 123/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5465 - accuracy: 0.7221 - val_loss: 0.5337 - val_accuracy: 0.7474\n",
            "Epoch 124/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5543 - accuracy: 0.7303 - val_loss: 0.5336 - val_accuracy: 0.7495\n",
            "Epoch 125/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5421 - accuracy: 0.7313 - val_loss: 0.5334 - val_accuracy: 0.7495\n",
            "Epoch 126/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5224 - accuracy: 0.7510 - val_loss: 0.5332 - val_accuracy: 0.7474\n",
            "Epoch 127/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5443 - accuracy: 0.7392 - val_loss: 0.5329 - val_accuracy: 0.7474\n",
            "Epoch 128/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5478 - accuracy: 0.7342 - val_loss: 0.5328 - val_accuracy: 0.7474\n",
            "Epoch 129/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5326 - accuracy: 0.7330 - val_loss: 0.5325 - val_accuracy: 0.7432\n",
            "Epoch 130/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5461 - accuracy: 0.7345 - val_loss: 0.5323 - val_accuracy: 0.7432\n",
            "Epoch 131/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5164 - accuracy: 0.7455 - val_loss: 0.5322 - val_accuracy: 0.7432\n",
            "Epoch 132/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5326 - accuracy: 0.7366 - val_loss: 0.5320 - val_accuracy: 0.7432\n",
            "Epoch 133/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5443 - accuracy: 0.7422 - val_loss: 0.5318 - val_accuracy: 0.7432\n",
            "Epoch 134/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5392 - accuracy: 0.7294 - val_loss: 0.5315 - val_accuracy: 0.7432\n",
            "Epoch 135/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5216 - accuracy: 0.7469 - val_loss: 0.5314 - val_accuracy: 0.7432\n",
            "Epoch 136/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5365 - accuracy: 0.7339 - val_loss: 0.5312 - val_accuracy: 0.7411\n",
            "Epoch 137/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5293 - accuracy: 0.7426 - val_loss: 0.5311 - val_accuracy: 0.7432\n",
            "Epoch 138/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5341 - accuracy: 0.7240 - val_loss: 0.5309 - val_accuracy: 0.7432\n",
            "Epoch 139/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5381 - accuracy: 0.7411 - val_loss: 0.5308 - val_accuracy: 0.7453\n",
            "Epoch 140/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5350 - accuracy: 0.7491 - val_loss: 0.5306 - val_accuracy: 0.7432\n",
            "Epoch 141/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5321 - accuracy: 0.7237 - val_loss: 0.5305 - val_accuracy: 0.7453\n",
            "Epoch 142/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5369 - accuracy: 0.7498 - val_loss: 0.5303 - val_accuracy: 0.7453\n",
            "Epoch 143/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5383 - accuracy: 0.7293 - val_loss: 0.5302 - val_accuracy: 0.7432\n",
            "Epoch 144/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5478 - accuracy: 0.7265 - val_loss: 0.5301 - val_accuracy: 0.7453\n",
            "Epoch 145/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5285 - accuracy: 0.7442 - val_loss: 0.5300 - val_accuracy: 0.7453\n",
            "Epoch 146/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5342 - accuracy: 0.7413 - val_loss: 0.5298 - val_accuracy: 0.7453\n",
            "Epoch 147/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5573 - accuracy: 0.7151 - val_loss: 0.5296 - val_accuracy: 0.7432\n",
            "Epoch 148/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5409 - accuracy: 0.7379 - val_loss: 0.5295 - val_accuracy: 0.7453\n",
            "Epoch 149/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5462 - accuracy: 0.7339 - val_loss: 0.5294 - val_accuracy: 0.7432\n",
            "Epoch 150/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5230 - accuracy: 0.7394 - val_loss: 0.5293 - val_accuracy: 0.7453\n",
            "Epoch 151/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5206 - accuracy: 0.7393 - val_loss: 0.5291 - val_accuracy: 0.7453\n",
            "Epoch 152/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5280 - accuracy: 0.7378 - val_loss: 0.5290 - val_accuracy: 0.7432\n",
            "Epoch 153/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5403 - accuracy: 0.7197 - val_loss: 0.5288 - val_accuracy: 0.7432\n",
            "Epoch 154/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5281 - accuracy: 0.7421 - val_loss: 0.5287 - val_accuracy: 0.7432\n",
            "Epoch 155/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5300 - accuracy: 0.7474 - val_loss: 0.5286 - val_accuracy: 0.7453\n",
            "Epoch 156/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5194 - accuracy: 0.7479 - val_loss: 0.5285 - val_accuracy: 0.7453\n",
            "Epoch 157/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5088 - accuracy: 0.7714 - val_loss: 0.5283 - val_accuracy: 0.7453\n",
            "Epoch 158/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5265 - accuracy: 0.7425 - val_loss: 0.5283 - val_accuracy: 0.7474\n",
            "Epoch 159/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5236 - accuracy: 0.7479 - val_loss: 0.5282 - val_accuracy: 0.7453\n",
            "Epoch 160/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5254 - accuracy: 0.7485 - val_loss: 0.5281 - val_accuracy: 0.7453\n",
            "Epoch 161/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5256 - accuracy: 0.7421 - val_loss: 0.5279 - val_accuracy: 0.7474\n",
            "Epoch 162/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5457 - accuracy: 0.7158 - val_loss: 0.5278 - val_accuracy: 0.7474\n",
            "Epoch 163/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5200 - accuracy: 0.7570 - val_loss: 0.5277 - val_accuracy: 0.7474\n",
            "Epoch 164/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5256 - accuracy: 0.7557 - val_loss: 0.5276 - val_accuracy: 0.7474\n",
            "Epoch 165/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5393 - accuracy: 0.7328 - val_loss: 0.5274 - val_accuracy: 0.7453\n",
            "Epoch 166/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5278 - accuracy: 0.7438 - val_loss: 0.5273 - val_accuracy: 0.7453\n",
            "Epoch 167/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5184 - accuracy: 0.7436 - val_loss: 0.5272 - val_accuracy: 0.7453\n",
            "Epoch 168/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5253 - accuracy: 0.7388 - val_loss: 0.5271 - val_accuracy: 0.7453\n",
            "Epoch 169/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5134 - accuracy: 0.7384 - val_loss: 0.5270 - val_accuracy: 0.7453\n",
            "Epoch 170/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5390 - accuracy: 0.7461 - val_loss: 0.5269 - val_accuracy: 0.7453\n",
            "Epoch 171/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5440 - accuracy: 0.7318 - val_loss: 0.5269 - val_accuracy: 0.7474\n",
            "Epoch 172/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5351 - accuracy: 0.7349 - val_loss: 0.5267 - val_accuracy: 0.7474\n",
            "Epoch 173/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7757 - val_loss: 0.5267 - val_accuracy: 0.7474\n",
            "Epoch 174/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5109 - accuracy: 0.7592 - val_loss: 0.5266 - val_accuracy: 0.7474\n",
            "Epoch 175/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5219 - accuracy: 0.7442 - val_loss: 0.5265 - val_accuracy: 0.7474\n",
            "Epoch 176/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5250 - accuracy: 0.7425 - val_loss: 0.5264 - val_accuracy: 0.7453\n",
            "Epoch 177/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5346 - accuracy: 0.7415 - val_loss: 0.5263 - val_accuracy: 0.7474\n",
            "Epoch 178/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5205 - accuracy: 0.7410 - val_loss: 0.5263 - val_accuracy: 0.7474\n",
            "Epoch 179/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5293 - accuracy: 0.7418 - val_loss: 0.5262 - val_accuracy: 0.7474\n",
            "Epoch 180/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5129 - accuracy: 0.7539 - val_loss: 0.5261 - val_accuracy: 0.7474\n",
            "Epoch 181/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5199 - accuracy: 0.7598 - val_loss: 0.5260 - val_accuracy: 0.7474\n",
            "Epoch 182/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5408 - accuracy: 0.7274 - val_loss: 0.5259 - val_accuracy: 0.7474\n",
            "Epoch 183/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5267 - accuracy: 0.7392 - val_loss: 0.5258 - val_accuracy: 0.7474\n",
            "Epoch 184/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5315 - accuracy: 0.7512 - val_loss: 0.5258 - val_accuracy: 0.7474\n",
            "Epoch 185/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5267 - accuracy: 0.7422 - val_loss: 0.5257 - val_accuracy: 0.7474\n",
            "Epoch 186/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5309 - accuracy: 0.7326 - val_loss: 0.5257 - val_accuracy: 0.7474\n",
            "Epoch 187/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5239 - accuracy: 0.7453 - val_loss: 0.5255 - val_accuracy: 0.7474\n",
            "Epoch 188/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5474 - accuracy: 0.7270 - val_loss: 0.5255 - val_accuracy: 0.7474\n",
            "Epoch 189/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5295 - accuracy: 0.7503 - val_loss: 0.5254 - val_accuracy: 0.7474\n",
            "Epoch 190/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5345 - accuracy: 0.7386 - val_loss: 0.5254 - val_accuracy: 0.7453\n",
            "Epoch 191/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5300 - accuracy: 0.7496 - val_loss: 0.5254 - val_accuracy: 0.7453\n",
            "Epoch 192/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5400 - accuracy: 0.7284 - val_loss: 0.5253 - val_accuracy: 0.7453\n",
            "Epoch 193/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5229 - accuracy: 0.7518 - val_loss: 0.5251 - val_accuracy: 0.7453\n",
            "Epoch 194/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5401 - accuracy: 0.7366 - val_loss: 0.5250 - val_accuracy: 0.7474\n",
            "Epoch 195/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.7609 - val_loss: 0.5249 - val_accuracy: 0.7474\n",
            "Epoch 196/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5256 - accuracy: 0.7525 - val_loss: 0.5248 - val_accuracy: 0.7474\n",
            "Epoch 197/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5573 - accuracy: 0.7006 - val_loss: 0.5248 - val_accuracy: 0.7474\n",
            "Epoch 198/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5363 - accuracy: 0.7331 - val_loss: 0.5247 - val_accuracy: 0.7474\n",
            "Epoch 199/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5289 - accuracy: 0.7427 - val_loss: 0.5247 - val_accuracy: 0.7453\n",
            "Epoch 200/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5324 - accuracy: 0.7351 - val_loss: 0.5246 - val_accuracy: 0.7453\n",
            "Epoch 201/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5331 - accuracy: 0.7359 - val_loss: 0.5246 - val_accuracy: 0.7453\n",
            "Epoch 202/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7586 - val_loss: 0.5245 - val_accuracy: 0.7453\n",
            "Epoch 203/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5217 - accuracy: 0.7603 - val_loss: 0.5245 - val_accuracy: 0.7453\n",
            "Epoch 204/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7608 - val_loss: 0.5244 - val_accuracy: 0.7453\n",
            "Epoch 205/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7630 - val_loss: 0.5242 - val_accuracy: 0.7474\n",
            "Epoch 206/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5453 - accuracy: 0.7242 - val_loss: 0.5242 - val_accuracy: 0.7453\n",
            "Epoch 207/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5200 - accuracy: 0.7512 - val_loss: 0.5242 - val_accuracy: 0.7453\n",
            "Epoch 208/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5365 - accuracy: 0.7305 - val_loss: 0.5241 - val_accuracy: 0.7474\n",
            "Epoch 209/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5245 - accuracy: 0.7426 - val_loss: 0.5241 - val_accuracy: 0.7453\n",
            "Epoch 210/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5187 - accuracy: 0.7499 - val_loss: 0.5241 - val_accuracy: 0.7453\n",
            "Epoch 211/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5163 - accuracy: 0.7578 - val_loss: 0.5240 - val_accuracy: 0.7453\n",
            "Epoch 212/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5250 - accuracy: 0.7541 - val_loss: 0.5240 - val_accuracy: 0.7453\n",
            "Epoch 213/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5223 - accuracy: 0.7539 - val_loss: 0.5239 - val_accuracy: 0.7453\n",
            "Epoch 214/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5273 - accuracy: 0.7426 - val_loss: 0.5238 - val_accuracy: 0.7453\n",
            "Epoch 215/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5186 - accuracy: 0.7472 - val_loss: 0.5238 - val_accuracy: 0.7453\n",
            "Epoch 216/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5271 - accuracy: 0.7570 - val_loss: 0.5237 - val_accuracy: 0.7453\n",
            "Epoch 217/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5246 - accuracy: 0.7288 - val_loss: 0.5236 - val_accuracy: 0.7453\n",
            "Epoch 218/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5514 - accuracy: 0.7427 - val_loss: 0.5236 - val_accuracy: 0.7453\n",
            "Epoch 219/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7641 - val_loss: 0.5236 - val_accuracy: 0.7453\n",
            "Epoch 220/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5408 - accuracy: 0.7358 - val_loss: 0.5235 - val_accuracy: 0.7453\n",
            "Epoch 221/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5194 - accuracy: 0.7472 - val_loss: 0.5235 - val_accuracy: 0.7453\n",
            "Epoch 222/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5231 - accuracy: 0.7520 - val_loss: 0.5234 - val_accuracy: 0.7453\n",
            "Epoch 223/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7587 - val_loss: 0.5234 - val_accuracy: 0.7453\n",
            "Epoch 224/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5259 - accuracy: 0.7351 - val_loss: 0.5233 - val_accuracy: 0.7453\n",
            "Epoch 225/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5262 - accuracy: 0.7394 - val_loss: 0.5233 - val_accuracy: 0.7453\n",
            "Epoch 226/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5287 - accuracy: 0.7437 - val_loss: 0.5232 - val_accuracy: 0.7453\n",
            "Epoch 227/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5276 - accuracy: 0.7387 - val_loss: 0.5232 - val_accuracy: 0.7453\n",
            "Epoch 228/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5417 - accuracy: 0.7365 - val_loss: 0.5232 - val_accuracy: 0.7453\n",
            "Epoch 229/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5369 - accuracy: 0.7489 - val_loss: 0.5231 - val_accuracy: 0.7453\n",
            "Epoch 230/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5327 - accuracy: 0.7368 - val_loss: 0.5231 - val_accuracy: 0.7453\n",
            "Epoch 231/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5196 - accuracy: 0.7535 - val_loss: 0.5231 - val_accuracy: 0.7432\n",
            "Epoch 232/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5158 - accuracy: 0.7415 - val_loss: 0.5231 - val_accuracy: 0.7432\n",
            "Epoch 233/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5357 - accuracy: 0.7307 - val_loss: 0.5230 - val_accuracy: 0.7432\n",
            "Epoch 234/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5000 - accuracy: 0.7775 - val_loss: 0.5230 - val_accuracy: 0.7432\n",
            "Epoch 235/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5301 - accuracy: 0.7459 - val_loss: 0.5230 - val_accuracy: 0.7432\n",
            "Epoch 236/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5277 - accuracy: 0.7411 - val_loss: 0.5228 - val_accuracy: 0.7453\n",
            "Epoch 237/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5351 - accuracy: 0.7268 - val_loss: 0.5229 - val_accuracy: 0.7432\n",
            "Epoch 238/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5279 - accuracy: 0.7362 - val_loss: 0.5227 - val_accuracy: 0.7432\n",
            "Epoch 239/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.7541 - val_loss: 0.5227 - val_accuracy: 0.7432\n",
            "Epoch 240/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5281 - accuracy: 0.7420 - val_loss: 0.5226 - val_accuracy: 0.7432\n",
            "Epoch 241/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5128 - accuracy: 0.7582 - val_loss: 0.5225 - val_accuracy: 0.7432\n",
            "Epoch 242/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5542 - accuracy: 0.7280 - val_loss: 0.5225 - val_accuracy: 0.7432\n",
            "Epoch 243/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5234 - accuracy: 0.7479 - val_loss: 0.5225 - val_accuracy: 0.7432\n",
            "Epoch 244/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5341 - accuracy: 0.7302 - val_loss: 0.5225 - val_accuracy: 0.7432\n",
            "Epoch 245/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5326 - accuracy: 0.7450 - val_loss: 0.5224 - val_accuracy: 0.7432\n",
            "Epoch 246/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7611 - val_loss: 0.5224 - val_accuracy: 0.7432\n",
            "Epoch 247/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7513 - val_loss: 0.5223 - val_accuracy: 0.7432\n",
            "Epoch 248/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5204 - accuracy: 0.7471 - val_loss: 0.5222 - val_accuracy: 0.7453\n",
            "Epoch 249/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5427 - accuracy: 0.7369 - val_loss: 0.5223 - val_accuracy: 0.7453\n",
            "Epoch 250/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5312 - accuracy: 0.7368 - val_loss: 0.5222 - val_accuracy: 0.7453\n",
            "Epoch 251/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5397 - accuracy: 0.7365 - val_loss: 0.5222 - val_accuracy: 0.7453\n",
            "Epoch 252/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7512 - val_loss: 0.5221 - val_accuracy: 0.7453\n",
            "Epoch 253/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5235 - accuracy: 0.7406 - val_loss: 0.5221 - val_accuracy: 0.7453\n",
            "Epoch 254/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5099 - accuracy: 0.7537 - val_loss: 0.5220 - val_accuracy: 0.7453\n",
            "Epoch 255/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5220 - accuracy: 0.7489 - val_loss: 0.5220 - val_accuracy: 0.7474\n",
            "Epoch 256/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5364 - accuracy: 0.7392 - val_loss: 0.5219 - val_accuracy: 0.7453\n",
            "Epoch 257/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5246 - accuracy: 0.7395 - val_loss: 0.5219 - val_accuracy: 0.7453\n",
            "Epoch 258/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5158 - accuracy: 0.7300 - val_loss: 0.5219 - val_accuracy: 0.7453\n",
            "Epoch 259/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5522 - accuracy: 0.7234 - val_loss: 0.5218 - val_accuracy: 0.7453\n",
            "Epoch 260/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5210 - accuracy: 0.7254 - val_loss: 0.5218 - val_accuracy: 0.7453\n",
            "Epoch 261/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5385 - accuracy: 0.7171 - val_loss: 0.5218 - val_accuracy: 0.7453\n",
            "Epoch 262/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5264 - accuracy: 0.7398 - val_loss: 0.5217 - val_accuracy: 0.7453\n",
            "Epoch 263/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4950 - accuracy: 0.7558 - val_loss: 0.5217 - val_accuracy: 0.7453\n",
            "Epoch 264/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5109 - accuracy: 0.7604 - val_loss: 0.5217 - val_accuracy: 0.7474\n",
            "Epoch 265/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5159 - accuracy: 0.7499 - val_loss: 0.5216 - val_accuracy: 0.7453\n",
            "Epoch 266/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7480 - val_loss: 0.5216 - val_accuracy: 0.7474\n",
            "Epoch 267/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5200 - accuracy: 0.7622 - val_loss: 0.5216 - val_accuracy: 0.7474\n",
            "Epoch 268/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5139 - accuracy: 0.7401 - val_loss: 0.5215 - val_accuracy: 0.7495\n",
            "Epoch 269/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7683 - val_loss: 0.5215 - val_accuracy: 0.7474\n",
            "Epoch 270/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5098 - accuracy: 0.7620 - val_loss: 0.5215 - val_accuracy: 0.7495\n",
            "Epoch 271/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5189 - accuracy: 0.7378 - val_loss: 0.5215 - val_accuracy: 0.7495\n",
            "Epoch 272/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5327 - accuracy: 0.7304 - val_loss: 0.5214 - val_accuracy: 0.7474\n",
            "Epoch 273/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7593 - val_loss: 0.5213 - val_accuracy: 0.7474\n",
            "Epoch 274/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5190 - accuracy: 0.7340 - val_loss: 0.5213 - val_accuracy: 0.7432\n",
            "Epoch 275/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5369 - accuracy: 0.7341 - val_loss: 0.5213 - val_accuracy: 0.7474\n",
            "Epoch 276/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5009 - accuracy: 0.7487 - val_loss: 0.5213 - val_accuracy: 0.7474\n",
            "Epoch 277/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5460 - accuracy: 0.7133 - val_loss: 0.5213 - val_accuracy: 0.7474\n",
            "Epoch 278/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5102 - accuracy: 0.7542 - val_loss: 0.5213 - val_accuracy: 0.7474\n",
            "Epoch 279/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5142 - accuracy: 0.7455 - val_loss: 0.5213 - val_accuracy: 0.7495\n",
            "Epoch 280/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5346 - accuracy: 0.7502 - val_loss: 0.5213 - val_accuracy: 0.7495\n",
            "Epoch 281/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5297 - accuracy: 0.7343 - val_loss: 0.5213 - val_accuracy: 0.7495\n",
            "Epoch 282/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5321 - accuracy: 0.7361 - val_loss: 0.5213 - val_accuracy: 0.7495\n",
            "Epoch 283/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5274 - accuracy: 0.7374 - val_loss: 0.5212 - val_accuracy: 0.7495\n",
            "Epoch 284/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5195 - accuracy: 0.7478 - val_loss: 0.5212 - val_accuracy: 0.7495\n",
            "Epoch 285/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5216 - accuracy: 0.7505 - val_loss: 0.5212 - val_accuracy: 0.7495\n",
            "Epoch 286/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5301 - accuracy: 0.7355 - val_loss: 0.5212 - val_accuracy: 0.7495\n",
            "Epoch 287/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5138 - accuracy: 0.7588 - val_loss: 0.5211 - val_accuracy: 0.7474\n",
            "Epoch 288/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5305 - accuracy: 0.7478 - val_loss: 0.5210 - val_accuracy: 0.7453\n",
            "Epoch 289/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7525 - val_loss: 0.5210 - val_accuracy: 0.7474\n",
            "Epoch 290/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5279 - accuracy: 0.7413 - val_loss: 0.5211 - val_accuracy: 0.7495\n",
            "Epoch 291/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4982 - accuracy: 0.7647 - val_loss: 0.5211 - val_accuracy: 0.7495\n",
            "Epoch 292/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5300 - accuracy: 0.7202 - val_loss: 0.5211 - val_accuracy: 0.7495\n",
            "Epoch 293/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5379 - accuracy: 0.7392 - val_loss: 0.5210 - val_accuracy: 0.7495\n",
            "Epoch 294/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5302 - accuracy: 0.7483 - val_loss: 0.5209 - val_accuracy: 0.7453\n",
            "Epoch 295/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5283 - accuracy: 0.7397 - val_loss: 0.5210 - val_accuracy: 0.7495\n",
            "Epoch 296/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7708 - val_loss: 0.5209 - val_accuracy: 0.7474\n",
            "Epoch 297/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5437 - accuracy: 0.7438 - val_loss: 0.5209 - val_accuracy: 0.7453\n",
            "Epoch 298/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5382 - accuracy: 0.7403 - val_loss: 0.5208 - val_accuracy: 0.7453\n",
            "Epoch 299/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5230 - accuracy: 0.7513 - val_loss: 0.5209 - val_accuracy: 0.7495\n",
            "Epoch 300/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5393 - accuracy: 0.7382 - val_loss: 0.5208 - val_accuracy: 0.7495\n",
            "Epoch 301/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7519 - val_loss: 0.5208 - val_accuracy: 0.7495\n",
            "Epoch 302/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5351 - accuracy: 0.7526 - val_loss: 0.5208 - val_accuracy: 0.7495\n",
            "Epoch 303/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5377 - accuracy: 0.7421 - val_loss: 0.5208 - val_accuracy: 0.7495\n",
            "Epoch 304/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5342 - accuracy: 0.7328 - val_loss: 0.5208 - val_accuracy: 0.7495\n",
            "Epoch 305/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5222 - accuracy: 0.7589 - val_loss: 0.5207 - val_accuracy: 0.7495\n",
            "Epoch 306/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5107 - accuracy: 0.7581 - val_loss: 0.5207 - val_accuracy: 0.7495\n",
            "Epoch 307/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5000 - accuracy: 0.7654 - val_loss: 0.5207 - val_accuracy: 0.7495\n",
            "Epoch 308/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.7644 - val_loss: 0.5206 - val_accuracy: 0.7453\n",
            "Epoch 309/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5295 - accuracy: 0.7400 - val_loss: 0.5206 - val_accuracy: 0.7453\n",
            "Epoch 310/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5305 - accuracy: 0.7347 - val_loss: 0.5206 - val_accuracy: 0.7474\n",
            "Epoch 311/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5197 - accuracy: 0.7476 - val_loss: 0.5206 - val_accuracy: 0.7495\n",
            "Epoch 312/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5222 - accuracy: 0.7443 - val_loss: 0.5205 - val_accuracy: 0.7474\n",
            "Epoch 313/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5276 - accuracy: 0.7490 - val_loss: 0.5205 - val_accuracy: 0.7453\n",
            "Epoch 314/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5653 - accuracy: 0.7168 - val_loss: 0.5205 - val_accuracy: 0.7474\n",
            "Epoch 315/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7634 - val_loss: 0.5205 - val_accuracy: 0.7495\n",
            "Epoch 316/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5160 - accuracy: 0.7481 - val_loss: 0.5205 - val_accuracy: 0.7495\n",
            "Epoch 317/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5453 - accuracy: 0.7267 - val_loss: 0.5204 - val_accuracy: 0.7474\n",
            "Epoch 318/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5158 - accuracy: 0.7474 - val_loss: 0.5204 - val_accuracy: 0.7495\n",
            "Epoch 319/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5341 - accuracy: 0.7389 - val_loss: 0.5203 - val_accuracy: 0.7453\n",
            "Epoch 320/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5295 - accuracy: 0.7379 - val_loss: 0.5203 - val_accuracy: 0.7474\n",
            "Epoch 321/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5262 - accuracy: 0.7487 - val_loss: 0.5203 - val_accuracy: 0.7453\n",
            "Epoch 322/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7527 - val_loss: 0.5202 - val_accuracy: 0.7453\n",
            "Epoch 323/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5138 - accuracy: 0.7515 - val_loss: 0.5202 - val_accuracy: 0.7453\n",
            "Epoch 324/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5185 - accuracy: 0.7465 - val_loss: 0.5202 - val_accuracy: 0.7474\n",
            "Epoch 325/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5381 - accuracy: 0.7281 - val_loss: 0.5202 - val_accuracy: 0.7474\n",
            "Epoch 326/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5134 - accuracy: 0.7579 - val_loss: 0.5202 - val_accuracy: 0.7474\n",
            "Epoch 327/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5107 - accuracy: 0.7477 - val_loss: 0.5202 - val_accuracy: 0.7495\n",
            "Epoch 328/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5405 - accuracy: 0.7377 - val_loss: 0.5202 - val_accuracy: 0.7495\n",
            "Epoch 329/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5384 - accuracy: 0.7263 - val_loss: 0.5201 - val_accuracy: 0.7474\n",
            "Epoch 330/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5106 - accuracy: 0.7527 - val_loss: 0.5201 - val_accuracy: 0.7474\n",
            "Epoch 331/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5274 - accuracy: 0.7414 - val_loss: 0.5201 - val_accuracy: 0.7474\n",
            "Epoch 332/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4990 - accuracy: 0.7672 - val_loss: 0.5202 - val_accuracy: 0.7495\n",
            "Epoch 333/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5245 - accuracy: 0.7552 - val_loss: 0.5202 - val_accuracy: 0.7516\n",
            "Epoch 334/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5305 - accuracy: 0.7428 - val_loss: 0.5202 - val_accuracy: 0.7516\n",
            "Epoch 335/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5132 - accuracy: 0.7521 - val_loss: 0.5201 - val_accuracy: 0.7516\n",
            "Epoch 336/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5195 - accuracy: 0.7411 - val_loss: 0.5200 - val_accuracy: 0.7474\n",
            "Epoch 337/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5140 - accuracy: 0.7542 - val_loss: 0.5200 - val_accuracy: 0.7474\n",
            "Epoch 338/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5225 - accuracy: 0.7445 - val_loss: 0.5199 - val_accuracy: 0.7474\n",
            "Epoch 339/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5119 - accuracy: 0.7395 - val_loss: 0.5200 - val_accuracy: 0.7474\n",
            "Epoch 340/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5217 - accuracy: 0.7573 - val_loss: 0.5200 - val_accuracy: 0.7474\n",
            "Epoch 341/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5180 - accuracy: 0.7450 - val_loss: 0.5199 - val_accuracy: 0.7474\n",
            "Epoch 342/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5294 - accuracy: 0.7486 - val_loss: 0.5199 - val_accuracy: 0.7474\n",
            "Epoch 343/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5231 - accuracy: 0.7563 - val_loss: 0.5199 - val_accuracy: 0.7474\n",
            "Epoch 344/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5532 - accuracy: 0.7133 - val_loss: 0.5198 - val_accuracy: 0.7474\n",
            "Epoch 345/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5332 - accuracy: 0.7381 - val_loss: 0.5198 - val_accuracy: 0.7474\n",
            "Epoch 346/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5191 - accuracy: 0.7385 - val_loss: 0.5198 - val_accuracy: 0.7474\n",
            "Epoch 347/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5206 - accuracy: 0.7543 - val_loss: 0.5198 - val_accuracy: 0.7474\n",
            "Epoch 348/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5000 - accuracy: 0.7500 - val_loss: 0.5198 - val_accuracy: 0.7474\n",
            "Epoch 349/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5472 - accuracy: 0.7242 - val_loss: 0.5198 - val_accuracy: 0.7474\n",
            "Epoch 350/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5173 - accuracy: 0.7544 - val_loss: 0.5198 - val_accuracy: 0.7474\n",
            "Epoch 351/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5259 - accuracy: 0.7528 - val_loss: 0.5198 - val_accuracy: 0.7474\n",
            "Epoch 352/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5132 - accuracy: 0.7609 - val_loss: 0.5198 - val_accuracy: 0.7474\n",
            "Epoch 353/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5248 - accuracy: 0.7419 - val_loss: 0.5199 - val_accuracy: 0.7495\n",
            "Epoch 354/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5224 - accuracy: 0.7345 - val_loss: 0.5199 - val_accuracy: 0.7495\n",
            "Epoch 355/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5145 - accuracy: 0.7489 - val_loss: 0.5199 - val_accuracy: 0.7495\n",
            "Epoch 356/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5012 - accuracy: 0.7703 - val_loss: 0.5198 - val_accuracy: 0.7495\n",
            "Epoch 357/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4928 - accuracy: 0.7758 - val_loss: 0.5198 - val_accuracy: 0.7495\n",
            "Epoch 358/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5360 - accuracy: 0.7331 - val_loss: 0.5197 - val_accuracy: 0.7495\n",
            "Epoch 359/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5352 - accuracy: 0.7282 - val_loss: 0.5198 - val_accuracy: 0.7516\n",
            "Epoch 360/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5301 - accuracy: 0.7397 - val_loss: 0.5197 - val_accuracy: 0.7495\n",
            "Epoch 361/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5282 - accuracy: 0.7380 - val_loss: 0.5197 - val_accuracy: 0.7495\n",
            "Epoch 362/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5230 - accuracy: 0.7275 - val_loss: 0.5197 - val_accuracy: 0.7495\n",
            "Epoch 363/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5260 - accuracy: 0.7445 - val_loss: 0.5197 - val_accuracy: 0.7495\n",
            "Epoch 364/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5122 - accuracy: 0.7487 - val_loss: 0.5197 - val_accuracy: 0.7495\n",
            "Epoch 365/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5138 - accuracy: 0.7620 - val_loss: 0.5196 - val_accuracy: 0.7453\n",
            "Epoch 366/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5228 - accuracy: 0.7401 - val_loss: 0.5196 - val_accuracy: 0.7453\n",
            "Epoch 367/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5245 - accuracy: 0.7474 - val_loss: 0.5196 - val_accuracy: 0.7474\n",
            "Epoch 368/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5314 - accuracy: 0.7339 - val_loss: 0.5196 - val_accuracy: 0.7432\n",
            "Epoch 369/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.7430 - val_loss: 0.5196 - val_accuracy: 0.7453\n",
            "Epoch 370/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5341 - accuracy: 0.7468 - val_loss: 0.5195 - val_accuracy: 0.7453\n",
            "Epoch 371/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5318 - accuracy: 0.7399 - val_loss: 0.5195 - val_accuracy: 0.7474\n",
            "Epoch 372/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5252 - accuracy: 0.7474 - val_loss: 0.5195 - val_accuracy: 0.7474\n",
            "Epoch 373/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7509 - val_loss: 0.5195 - val_accuracy: 0.7453\n",
            "Epoch 374/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5210 - accuracy: 0.7359 - val_loss: 0.5195 - val_accuracy: 0.7432\n",
            "Epoch 375/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5253 - accuracy: 0.7452 - val_loss: 0.5195 - val_accuracy: 0.7453\n",
            "Epoch 376/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5013 - accuracy: 0.7696 - val_loss: 0.5195 - val_accuracy: 0.7453\n",
            "Epoch 377/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5145 - accuracy: 0.7498 - val_loss: 0.5195 - val_accuracy: 0.7453\n",
            "Epoch 378/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5327 - accuracy: 0.7435 - val_loss: 0.5195 - val_accuracy: 0.7453\n",
            "Epoch 379/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5250 - accuracy: 0.7359 - val_loss: 0.5195 - val_accuracy: 0.7453\n",
            "Epoch 380/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4978 - accuracy: 0.7610 - val_loss: 0.5195 - val_accuracy: 0.7453\n",
            "Epoch 381/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4936 - accuracy: 0.7742 - val_loss: 0.5195 - val_accuracy: 0.7453\n",
            "Epoch 382/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5118 - accuracy: 0.7537 - val_loss: 0.5194 - val_accuracy: 0.7453\n",
            "Epoch 383/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5102 - accuracy: 0.7580 - val_loss: 0.5194 - val_accuracy: 0.7453\n",
            "Epoch 384/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5153 - accuracy: 0.7485 - val_loss: 0.5194 - val_accuracy: 0.7432\n",
            "Epoch 385/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5162 - accuracy: 0.7511 - val_loss: 0.5194 - val_accuracy: 0.7453\n",
            "Epoch 386/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7620 - val_loss: 0.5194 - val_accuracy: 0.7453\n",
            "Epoch 387/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5001 - accuracy: 0.7625 - val_loss: 0.5194 - val_accuracy: 0.7453\n",
            "Epoch 388/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5423 - accuracy: 0.7310 - val_loss: 0.5193 - val_accuracy: 0.7453\n",
            "Epoch 389/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5248 - accuracy: 0.7473 - val_loss: 0.5193 - val_accuracy: 0.7453\n",
            "Epoch 390/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5379 - accuracy: 0.7456 - val_loss: 0.5194 - val_accuracy: 0.7453\n",
            "Epoch 391/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7692 - val_loss: 0.5193 - val_accuracy: 0.7453\n",
            "Epoch 392/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5102 - accuracy: 0.7598 - val_loss: 0.5193 - val_accuracy: 0.7453\n",
            "Epoch 393/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5381 - accuracy: 0.7445 - val_loss: 0.5193 - val_accuracy: 0.7432\n",
            "Epoch 394/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4936 - accuracy: 0.7678 - val_loss: 0.5193 - val_accuracy: 0.7453\n",
            "Epoch 395/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5192 - accuracy: 0.7479 - val_loss: 0.5192 - val_accuracy: 0.7453\n",
            "Epoch 396/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5144 - accuracy: 0.7508 - val_loss: 0.5192 - val_accuracy: 0.7453\n",
            "Epoch 397/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5257 - accuracy: 0.7459 - val_loss: 0.5192 - val_accuracy: 0.7453\n",
            "Epoch 398/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7557 - val_loss: 0.5192 - val_accuracy: 0.7453\n",
            "Epoch 399/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5427 - accuracy: 0.7379 - val_loss: 0.5192 - val_accuracy: 0.7453\n",
            "Epoch 400/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5453 - accuracy: 0.7204 - val_loss: 0.5192 - val_accuracy: 0.7453\n",
            "Epoch 401/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5170 - accuracy: 0.7565 - val_loss: 0.5192 - val_accuracy: 0.7474\n",
            "Epoch 402/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5154 - accuracy: 0.7516 - val_loss: 0.5192 - val_accuracy: 0.7453\n",
            "Epoch 403/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4956 - accuracy: 0.7660 - val_loss: 0.5192 - val_accuracy: 0.7474\n",
            "Epoch 404/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5385 - accuracy: 0.7271 - val_loss: 0.5192 - val_accuracy: 0.7474\n",
            "Epoch 405/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5471 - accuracy: 0.7453 - val_loss: 0.5193 - val_accuracy: 0.7474\n",
            "Epoch 406/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4998 - accuracy: 0.7611 - val_loss: 0.5192 - val_accuracy: 0.7474\n",
            "Epoch 407/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5217 - accuracy: 0.7349 - val_loss: 0.5192 - val_accuracy: 0.7453\n",
            "Epoch 408/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5125 - accuracy: 0.7725 - val_loss: 0.5192 - val_accuracy: 0.7474\n",
            "Epoch 409/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5113 - accuracy: 0.7563 - val_loss: 0.5192 - val_accuracy: 0.7453\n",
            "Epoch 410/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5022 - accuracy: 0.7582 - val_loss: 0.5192 - val_accuracy: 0.7474\n",
            "Epoch 411/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5338 - accuracy: 0.7421 - val_loss: 0.5192 - val_accuracy: 0.7474\n",
            "Epoch 412/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5445 - accuracy: 0.7372 - val_loss: 0.5192 - val_accuracy: 0.7474\n",
            "Epoch 413/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5199 - accuracy: 0.7502 - val_loss: 0.5192 - val_accuracy: 0.7474\n",
            "Epoch 414/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5400 - accuracy: 0.7348 - val_loss: 0.5191 - val_accuracy: 0.7474\n",
            "Epoch 415/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5113 - accuracy: 0.7608 - val_loss: 0.5191 - val_accuracy: 0.7474\n",
            "Epoch 416/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5525 - accuracy: 0.7258 - val_loss: 0.5191 - val_accuracy: 0.7474\n",
            "Epoch 417/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5309 - accuracy: 0.7350 - val_loss: 0.5191 - val_accuracy: 0.7453\n",
            "Epoch 418/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5106 - accuracy: 0.7390 - val_loss: 0.5190 - val_accuracy: 0.7453\n",
            "Epoch 419/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5225 - accuracy: 0.7418 - val_loss: 0.5190 - val_accuracy: 0.7453\n",
            "Epoch 420/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5263 - accuracy: 0.7452 - val_loss: 0.5191 - val_accuracy: 0.7453\n",
            "Epoch 421/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5303 - accuracy: 0.7424 - val_loss: 0.5191 - val_accuracy: 0.7453\n",
            "Epoch 422/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7438 - val_loss: 0.5191 - val_accuracy: 0.7474\n",
            "Epoch 423/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5006 - accuracy: 0.7500 - val_loss: 0.5191 - val_accuracy: 0.7474\n",
            "Epoch 424/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.7585 - val_loss: 0.5191 - val_accuracy: 0.7453\n",
            "Epoch 425/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5262 - accuracy: 0.7355 - val_loss: 0.5191 - val_accuracy: 0.7453\n",
            "Epoch 426/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5132 - accuracy: 0.7498 - val_loss: 0.5191 - val_accuracy: 0.7474\n",
            "Epoch 427/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4989 - accuracy: 0.7739 - val_loss: 0.5190 - val_accuracy: 0.7474\n",
            "Epoch 428/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4872 - accuracy: 0.7732 - val_loss: 0.5190 - val_accuracy: 0.7453\n",
            "Epoch 429/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5128 - accuracy: 0.7651 - val_loss: 0.5190 - val_accuracy: 0.7474\n",
            "Epoch 430/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5358 - accuracy: 0.7238 - val_loss: 0.5190 - val_accuracy: 0.7474\n",
            "Epoch 431/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5334 - accuracy: 0.7356 - val_loss: 0.5190 - val_accuracy: 0.7474\n",
            "Epoch 432/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5266 - accuracy: 0.7456 - val_loss: 0.5190 - val_accuracy: 0.7474\n",
            "Epoch 433/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5210 - accuracy: 0.7597 - val_loss: 0.5190 - val_accuracy: 0.7474\n",
            "Epoch 434/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5289 - accuracy: 0.7347 - val_loss: 0.5190 - val_accuracy: 0.7474\n",
            "Epoch 435/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5105 - accuracy: 0.7495 - val_loss: 0.5190 - val_accuracy: 0.7474\n",
            "Epoch 436/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5291 - accuracy: 0.7434 - val_loss: 0.5190 - val_accuracy: 0.7474\n",
            "Epoch 437/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5194 - accuracy: 0.7476 - val_loss: 0.5190 - val_accuracy: 0.7474\n",
            "Epoch 438/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5400 - accuracy: 0.7317 - val_loss: 0.5191 - val_accuracy: 0.7474\n",
            "Epoch 439/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5182 - accuracy: 0.7453 - val_loss: 0.5190 - val_accuracy: 0.7474\n",
            "Epoch 440/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.7600 - val_loss: 0.5190 - val_accuracy: 0.7474\n",
            "Epoch 441/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5082 - accuracy: 0.7611 - val_loss: 0.5190 - val_accuracy: 0.7453\n",
            "Epoch 442/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5307 - accuracy: 0.7542 - val_loss: 0.5190 - val_accuracy: 0.7474\n",
            "Epoch 443/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7602 - val_loss: 0.5190 - val_accuracy: 0.7453\n",
            "Epoch 444/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7586 - val_loss: 0.5190 - val_accuracy: 0.7453\n",
            "Epoch 445/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4919 - accuracy: 0.7822 - val_loss: 0.5190 - val_accuracy: 0.7453\n",
            "Epoch 446/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5445 - accuracy: 0.7301 - val_loss: 0.5190 - val_accuracy: 0.7453\n",
            "Epoch 447/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5291 - accuracy: 0.7437 - val_loss: 0.5190 - val_accuracy: 0.7453\n",
            "Epoch 448/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5539 - accuracy: 0.7147 - val_loss: 0.5190 - val_accuracy: 0.7474\n",
            "Epoch 449/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5244 - accuracy: 0.7470 - val_loss: 0.5190 - val_accuracy: 0.7453\n",
            "Epoch 450/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5142 - accuracy: 0.7371 - val_loss: 0.5189 - val_accuracy: 0.7453\n",
            "Epoch 451/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5119 - accuracy: 0.7585 - val_loss: 0.5189 - val_accuracy: 0.7474\n",
            "Epoch 452/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.7550 - val_loss: 0.5189 - val_accuracy: 0.7453\n",
            "Epoch 453/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5323 - accuracy: 0.7297 - val_loss: 0.5189 - val_accuracy: 0.7453\n",
            "Epoch 454/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5223 - accuracy: 0.7460 - val_loss: 0.5189 - val_accuracy: 0.7453\n",
            "Epoch 455/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5296 - accuracy: 0.7321 - val_loss: 0.5189 - val_accuracy: 0.7453\n",
            "Epoch 456/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5233 - accuracy: 0.7444 - val_loss: 0.5189 - val_accuracy: 0.7453\n",
            "Epoch 457/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5269 - accuracy: 0.7520 - val_loss: 0.5189 - val_accuracy: 0.7453\n",
            "Epoch 458/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5435 - accuracy: 0.7294 - val_loss: 0.5189 - val_accuracy: 0.7453\n",
            "Epoch 459/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5179 - accuracy: 0.7577 - val_loss: 0.5189 - val_accuracy: 0.7453\n",
            "Epoch 460/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5140 - accuracy: 0.7506 - val_loss: 0.5189 - val_accuracy: 0.7453\n",
            "Epoch 461/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5159 - accuracy: 0.7560 - val_loss: 0.5189 - val_accuracy: 0.7453\n",
            "Epoch 462/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5020 - accuracy: 0.7693 - val_loss: 0.5190 - val_accuracy: 0.7474\n",
            "Epoch 463/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5198 - accuracy: 0.7319 - val_loss: 0.5189 - val_accuracy: 0.7453\n",
            "Epoch 464/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5237 - accuracy: 0.7419 - val_loss: 0.5189 - val_accuracy: 0.7453\n",
            "Epoch 465/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5127 - accuracy: 0.7611 - val_loss: 0.5189 - val_accuracy: 0.7453\n",
            "Epoch 466/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5290 - accuracy: 0.7370 - val_loss: 0.5189 - val_accuracy: 0.7453\n",
            "Epoch 467/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5331 - accuracy: 0.7400 - val_loss: 0.5190 - val_accuracy: 0.7453\n",
            "Epoch 468/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5206 - accuracy: 0.7510 - val_loss: 0.5190 - val_accuracy: 0.7474\n",
            "Epoch 469/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5239 - accuracy: 0.7473 - val_loss: 0.5190 - val_accuracy: 0.7453\n",
            "Epoch 470/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5362 - accuracy: 0.7368 - val_loss: 0.5189 - val_accuracy: 0.7453\n",
            "Epoch 471/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5429 - accuracy: 0.7481 - val_loss: 0.5189 - val_accuracy: 0.7453\n",
            "Epoch 472/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4998 - accuracy: 0.7621 - val_loss: 0.5189 - val_accuracy: 0.7453\n",
            "Epoch 473/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5178 - accuracy: 0.7642 - val_loss: 0.5188 - val_accuracy: 0.7453\n",
            "Epoch 474/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4985 - accuracy: 0.7663 - val_loss: 0.5188 - val_accuracy: 0.7453\n",
            "Epoch 475/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5203 - accuracy: 0.7494 - val_loss: 0.5188 - val_accuracy: 0.7453\n",
            "Epoch 476/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5184 - accuracy: 0.7616 - val_loss: 0.5188 - val_accuracy: 0.7453\n",
            "Epoch 477/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5302 - accuracy: 0.7467 - val_loss: 0.5188 - val_accuracy: 0.7453\n",
            "Epoch 478/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5438 - accuracy: 0.7276 - val_loss: 0.5188 - val_accuracy: 0.7474\n",
            "Epoch 479/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7579 - val_loss: 0.5188 - val_accuracy: 0.7453\n",
            "Epoch 480/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5197 - accuracy: 0.7370 - val_loss: 0.5188 - val_accuracy: 0.7453\n",
            "Epoch 481/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5160 - accuracy: 0.7469 - val_loss: 0.5187 - val_accuracy: 0.7453\n",
            "Epoch 482/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5357 - accuracy: 0.7243 - val_loss: 0.5187 - val_accuracy: 0.7453\n",
            "Epoch 483/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5258 - accuracy: 0.7389 - val_loss: 0.5187 - val_accuracy: 0.7453\n",
            "Epoch 484/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5003 - accuracy: 0.7673 - val_loss: 0.5187 - val_accuracy: 0.7453\n",
            "Epoch 485/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5104 - accuracy: 0.7665 - val_loss: 0.5187 - val_accuracy: 0.7453\n",
            "Epoch 486/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5376 - accuracy: 0.7435 - val_loss: 0.5188 - val_accuracy: 0.7474\n",
            "Epoch 487/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5227 - accuracy: 0.7517 - val_loss: 0.5187 - val_accuracy: 0.7453\n",
            "Epoch 488/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5452 - accuracy: 0.7206 - val_loss: 0.5187 - val_accuracy: 0.7453\n",
            "Epoch 489/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5194 - accuracy: 0.7544 - val_loss: 0.5188 - val_accuracy: 0.7474\n",
            "Epoch 490/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5295 - accuracy: 0.7483 - val_loss: 0.5188 - val_accuracy: 0.7474\n",
            "Epoch 491/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5234 - accuracy: 0.7345 - val_loss: 0.5188 - val_accuracy: 0.7474\n",
            "Epoch 492/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7614 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 493/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5263 - accuracy: 0.7397 - val_loss: 0.5187 - val_accuracy: 0.7453\n",
            "Epoch 494/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5006 - accuracy: 0.7587 - val_loss: 0.5187 - val_accuracy: 0.7453\n",
            "Epoch 495/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5021 - accuracy: 0.7588 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 496/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5096 - accuracy: 0.7445 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 497/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7593 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 498/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5342 - accuracy: 0.7327 - val_loss: 0.5188 - val_accuracy: 0.7474\n",
            "Epoch 499/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5105 - accuracy: 0.7568 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 500/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5358 - accuracy: 0.7423 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 501/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5430 - accuracy: 0.7521 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 502/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5271 - accuracy: 0.7438 - val_loss: 0.5187 - val_accuracy: 0.7453\n",
            "Epoch 503/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5183 - accuracy: 0.7537 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 504/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5280 - accuracy: 0.7384 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 505/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7466 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 506/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7609 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 507/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5228 - accuracy: 0.7376 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 508/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5285 - accuracy: 0.7365 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 509/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5299 - accuracy: 0.7418 - val_loss: 0.5188 - val_accuracy: 0.7474\n",
            "Epoch 510/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4968 - accuracy: 0.7501 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 511/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.7621 - val_loss: 0.5188 - val_accuracy: 0.7474\n",
            "Epoch 512/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5290 - accuracy: 0.7296 - val_loss: 0.5188 - val_accuracy: 0.7474\n",
            "Epoch 513/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.7482 - val_loss: 0.5187 - val_accuracy: 0.7453\n",
            "Epoch 514/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5218 - accuracy: 0.7554 - val_loss: 0.5187 - val_accuracy: 0.7453\n",
            "Epoch 515/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5207 - accuracy: 0.7369 - val_loss: 0.5187 - val_accuracy: 0.7453\n",
            "Epoch 516/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5144 - accuracy: 0.7652 - val_loss: 0.5188 - val_accuracy: 0.7474\n",
            "Epoch 517/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5338 - accuracy: 0.7351 - val_loss: 0.5188 - val_accuracy: 0.7474\n",
            "Epoch 518/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4862 - accuracy: 0.7782 - val_loss: 0.5188 - val_accuracy: 0.7474\n",
            "Epoch 519/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.7583 - val_loss: 0.5188 - val_accuracy: 0.7474\n",
            "Epoch 520/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5450 - accuracy: 0.7288 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 521/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5273 - accuracy: 0.7452 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 522/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5166 - accuracy: 0.7437 - val_loss: 0.5188 - val_accuracy: 0.7474\n",
            "Epoch 523/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5369 - accuracy: 0.7414 - val_loss: 0.5188 - val_accuracy: 0.7474\n",
            "Epoch 524/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5256 - accuracy: 0.7452 - val_loss: 0.5188 - val_accuracy: 0.7474\n",
            "Epoch 525/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5330 - accuracy: 0.7488 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 526/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7559 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 527/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5013 - accuracy: 0.7609 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 528/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5152 - accuracy: 0.7504 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 529/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5314 - accuracy: 0.7316 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 530/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5252 - accuracy: 0.7603 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 531/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5134 - accuracy: 0.7543 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 532/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5508 - accuracy: 0.7264 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 533/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5215 - accuracy: 0.7452 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 534/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4972 - accuracy: 0.7719 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 535/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5270 - accuracy: 0.7465 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 536/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5110 - accuracy: 0.7475 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 537/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4964 - accuracy: 0.7553 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 538/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4967 - accuracy: 0.7647 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 539/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5252 - accuracy: 0.7336 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 540/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4895 - accuracy: 0.7696 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 541/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5269 - accuracy: 0.7440 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 542/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5263 - accuracy: 0.7267 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 543/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5171 - accuracy: 0.7478 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 544/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5253 - accuracy: 0.7334 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 545/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5330 - accuracy: 0.7317 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 546/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5450 - accuracy: 0.7166 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 547/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5113 - accuracy: 0.7593 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 548/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5533 - accuracy: 0.7281 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 549/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4953 - accuracy: 0.7528 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 550/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5148 - accuracy: 0.7523 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 551/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5231 - accuracy: 0.7400 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 552/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5214 - accuracy: 0.7353 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 553/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4913 - accuracy: 0.7685 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 554/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7636 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 555/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7548 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 556/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5244 - accuracy: 0.7561 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 557/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5349 - accuracy: 0.7324 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 558/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5181 - accuracy: 0.7457 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 559/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5114 - accuracy: 0.7498 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 560/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5314 - accuracy: 0.7438 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 561/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5468 - accuracy: 0.7271 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 562/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5356 - accuracy: 0.7248 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 563/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5132 - accuracy: 0.7575 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 564/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5468 - accuracy: 0.7415 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 565/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5170 - accuracy: 0.7523 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 566/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5360 - accuracy: 0.7379 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 567/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5207 - accuracy: 0.7331 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 568/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5012 - accuracy: 0.7634 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 569/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7480 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 570/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5195 - accuracy: 0.7549 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 571/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5012 - accuracy: 0.7660 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 572/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7671 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 573/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5355 - accuracy: 0.7337 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 574/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5210 - accuracy: 0.7344 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 575/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5139 - accuracy: 0.7473 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 576/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5000 - accuracy: 0.7528 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 577/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5471 - accuracy: 0.7325 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 578/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5201 - accuracy: 0.7515 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 579/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7539 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 580/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5141 - accuracy: 0.7479 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 581/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5011 - accuracy: 0.7682 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 582/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4868 - accuracy: 0.7779 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 583/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5157 - accuracy: 0.7590 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 584/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5312 - accuracy: 0.7350 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 585/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5536 - accuracy: 0.7262 - val_loss: 0.5184 - val_accuracy: 0.7474\n",
            "Epoch 586/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5251 - accuracy: 0.7524 - val_loss: 0.5184 - val_accuracy: 0.7474\n",
            "Epoch 587/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5165 - accuracy: 0.7530 - val_loss: 0.5184 - val_accuracy: 0.7474\n",
            "Epoch 588/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5424 - accuracy: 0.7416 - val_loss: 0.5184 - val_accuracy: 0.7474\n",
            "Epoch 589/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5199 - accuracy: 0.7601 - val_loss: 0.5184 - val_accuracy: 0.7474\n",
            "Epoch 590/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5116 - accuracy: 0.7423 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 591/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5287 - accuracy: 0.7402 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 592/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5509 - accuracy: 0.7334 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 593/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4882 - accuracy: 0.7711 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 594/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4983 - accuracy: 0.7772 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 595/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5170 - accuracy: 0.7371 - val_loss: 0.5185 - val_accuracy: 0.7495\n",
            "Epoch 596/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4960 - accuracy: 0.7657 - val_loss: 0.5185 - val_accuracy: 0.7495\n",
            "Epoch 597/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5351 - accuracy: 0.7334 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 598/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5145 - accuracy: 0.7696 - val_loss: 0.5185 - val_accuracy: 0.7495\n",
            "Epoch 599/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5153 - accuracy: 0.7479 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 600/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5345 - accuracy: 0.7427 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 601/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7715 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 602/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5370 - accuracy: 0.7443 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 603/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5252 - accuracy: 0.7447 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 604/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5264 - accuracy: 0.7460 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 605/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5019 - accuracy: 0.7708 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 606/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5012 - accuracy: 0.7683 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 607/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5272 - accuracy: 0.7381 - val_loss: 0.5185 - val_accuracy: 0.7495\n",
            "Epoch 608/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5121 - accuracy: 0.7532 - val_loss: 0.5185 - val_accuracy: 0.7495\n",
            "Epoch 609/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5231 - accuracy: 0.7438 - val_loss: 0.5185 - val_accuracy: 0.7495\n",
            "Epoch 610/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5194 - accuracy: 0.7392 - val_loss: 0.5185 - val_accuracy: 0.7495\n",
            "Epoch 611/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5146 - accuracy: 0.7418 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 612/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5103 - accuracy: 0.7504 - val_loss: 0.5185 - val_accuracy: 0.7495\n",
            "Epoch 613/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5120 - accuracy: 0.7568 - val_loss: 0.5185 - val_accuracy: 0.7495\n",
            "Epoch 614/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7606 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 615/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5576 - accuracy: 0.7304 - val_loss: 0.5185 - val_accuracy: 0.7495\n",
            "Epoch 616/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5497 - accuracy: 0.7288 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 617/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5185 - accuracy: 0.7501 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 618/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5293 - accuracy: 0.7304 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 619/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5275 - accuracy: 0.7503 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 620/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5404 - accuracy: 0.7403 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 621/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5245 - accuracy: 0.7236 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 622/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5140 - accuracy: 0.7402 - val_loss: 0.5185 - val_accuracy: 0.7495\n",
            "Epoch 623/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4948 - accuracy: 0.7572 - val_loss: 0.5185 - val_accuracy: 0.7495\n",
            "Epoch 624/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5248 - accuracy: 0.7416 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 625/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5247 - accuracy: 0.7340 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 626/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5010 - accuracy: 0.7734 - val_loss: 0.5184 - val_accuracy: 0.7474\n",
            "Epoch 627/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5317 - accuracy: 0.7434 - val_loss: 0.5184 - val_accuracy: 0.7495\n",
            "Epoch 628/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7529 - val_loss: 0.5184 - val_accuracy: 0.7495\n",
            "Epoch 629/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7480 - val_loss: 0.5184 - val_accuracy: 0.7495\n",
            "Epoch 630/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7400 - val_loss: 0.5185 - val_accuracy: 0.7495\n",
            "Epoch 631/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.7482 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 632/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5208 - accuracy: 0.7383 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 633/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5241 - accuracy: 0.7385 - val_loss: 0.5185 - val_accuracy: 0.7495\n",
            "Epoch 634/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5127 - accuracy: 0.7597 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 635/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4899 - accuracy: 0.7696 - val_loss: 0.5184 - val_accuracy: 0.7495\n",
            "Epoch 636/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5405 - accuracy: 0.7384 - val_loss: 0.5185 - val_accuracy: 0.7495\n",
            "Epoch 637/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5371 - accuracy: 0.7322 - val_loss: 0.5184 - val_accuracy: 0.7474\n",
            "Epoch 638/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5189 - accuracy: 0.7382 - val_loss: 0.5184 - val_accuracy: 0.7474\n",
            "Epoch 639/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5344 - accuracy: 0.7359 - val_loss: 0.5184 - val_accuracy: 0.7495\n",
            "Epoch 640/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7784 - val_loss: 0.5184 - val_accuracy: 0.7474\n",
            "Epoch 641/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5128 - accuracy: 0.7565 - val_loss: 0.5184 - val_accuracy: 0.7474\n",
            "Epoch 642/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5194 - accuracy: 0.7416 - val_loss: 0.5184 - val_accuracy: 0.7474\n",
            "Epoch 643/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4953 - accuracy: 0.7679 - val_loss: 0.5184 - val_accuracy: 0.7495\n",
            "Epoch 644/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5113 - accuracy: 0.7437 - val_loss: 0.5184 - val_accuracy: 0.7474\n",
            "Epoch 645/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7469 - val_loss: 0.5184 - val_accuracy: 0.7474\n",
            "Epoch 646/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5264 - accuracy: 0.7480 - val_loss: 0.5184 - val_accuracy: 0.7474\n",
            "Epoch 647/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5199 - accuracy: 0.7444 - val_loss: 0.5184 - val_accuracy: 0.7474\n",
            "Epoch 648/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5322 - accuracy: 0.7360 - val_loss: 0.5184 - val_accuracy: 0.7474\n",
            "Epoch 649/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5196 - accuracy: 0.7464 - val_loss: 0.5184 - val_accuracy: 0.7474\n",
            "Epoch 650/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5203 - accuracy: 0.7501 - val_loss: 0.5184 - val_accuracy: 0.7495\n",
            "Epoch 651/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5154 - accuracy: 0.7553 - val_loss: 0.5183 - val_accuracy: 0.7495\n",
            "Epoch 652/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5270 - accuracy: 0.7381 - val_loss: 0.5184 - val_accuracy: 0.7474\n",
            "Epoch 653/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5299 - accuracy: 0.7446 - val_loss: 0.5184 - val_accuracy: 0.7495\n",
            "Epoch 654/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5209 - accuracy: 0.7663 - val_loss: 0.5184 - val_accuracy: 0.7495\n",
            "Epoch 655/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5198 - accuracy: 0.7415 - val_loss: 0.5183 - val_accuracy: 0.7474\n",
            "Epoch 656/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5307 - accuracy: 0.7342 - val_loss: 0.5183 - val_accuracy: 0.7495\n",
            "Epoch 657/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5163 - accuracy: 0.7520 - val_loss: 0.5184 - val_accuracy: 0.7474\n",
            "Epoch 658/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5127 - accuracy: 0.7525 - val_loss: 0.5184 - val_accuracy: 0.7474\n",
            "Epoch 659/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5157 - accuracy: 0.7372 - val_loss: 0.5184 - val_accuracy: 0.7474\n",
            "Epoch 660/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5130 - accuracy: 0.7553 - val_loss: 0.5184 - val_accuracy: 0.7495\n",
            "Epoch 661/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5442 - accuracy: 0.7311 - val_loss: 0.5184 - val_accuracy: 0.7474\n",
            "Epoch 662/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5455 - accuracy: 0.7277 - val_loss: 0.5184 - val_accuracy: 0.7474\n",
            "Epoch 663/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5109 - accuracy: 0.7462 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 664/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5248 - accuracy: 0.7529 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 665/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5163 - accuracy: 0.7544 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 666/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7590 - val_loss: 0.5184 - val_accuracy: 0.7474\n",
            "Epoch 667/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5295 - accuracy: 0.7296 - val_loss: 0.5184 - val_accuracy: 0.7474\n",
            "Epoch 668/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5501 - accuracy: 0.7351 - val_loss: 0.5184 - val_accuracy: 0.7474\n",
            "Epoch 669/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5151 - accuracy: 0.7513 - val_loss: 0.5184 - val_accuracy: 0.7474\n",
            "Epoch 670/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4996 - accuracy: 0.7599 - val_loss: 0.5184 - val_accuracy: 0.7474\n",
            "Epoch 671/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5201 - accuracy: 0.7525 - val_loss: 0.5184 - val_accuracy: 0.7495\n",
            "Epoch 672/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5162 - accuracy: 0.7584 - val_loss: 0.5184 - val_accuracy: 0.7474\n",
            "Epoch 673/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7584 - val_loss: 0.5184 - val_accuracy: 0.7474\n",
            "Epoch 674/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5211 - accuracy: 0.7430 - val_loss: 0.5184 - val_accuracy: 0.7495\n",
            "Epoch 675/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5299 - accuracy: 0.7493 - val_loss: 0.5184 - val_accuracy: 0.7495\n",
            "Epoch 676/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5154 - accuracy: 0.7395 - val_loss: 0.5184 - val_accuracy: 0.7474\n",
            "Epoch 677/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.7531 - val_loss: 0.5184 - val_accuracy: 0.7474\n",
            "Epoch 678/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5515 - accuracy: 0.7177 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 679/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4953 - accuracy: 0.7606 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 680/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5317 - accuracy: 0.7392 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 681/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5324 - accuracy: 0.7360 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 682/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5019 - accuracy: 0.7632 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 683/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5157 - accuracy: 0.7470 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 684/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5304 - accuracy: 0.7413 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 685/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5192 - accuracy: 0.7495 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 686/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5220 - accuracy: 0.7466 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 687/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.7475 - val_loss: 0.5184 - val_accuracy: 0.7474\n",
            "Epoch 688/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5016 - accuracy: 0.7548 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 689/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5182 - accuracy: 0.7471 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 690/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5276 - accuracy: 0.7383 - val_loss: 0.5184 - val_accuracy: 0.7474\n",
            "Epoch 691/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5138 - accuracy: 0.7521 - val_loss: 0.5184 - val_accuracy: 0.7474\n",
            "Epoch 692/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.7422 - val_loss: 0.5184 - val_accuracy: 0.7474\n",
            "Epoch 693/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5022 - accuracy: 0.7548 - val_loss: 0.5184 - val_accuracy: 0.7474\n",
            "Epoch 694/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5130 - accuracy: 0.7613 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 695/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5351 - accuracy: 0.7269 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 696/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7598 - val_loss: 0.5184 - val_accuracy: 0.7474\n",
            "Epoch 697/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5000 - accuracy: 0.7767 - val_loss: 0.5184 - val_accuracy: 0.7474\n",
            "Epoch 698/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5233 - accuracy: 0.7472 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 699/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5193 - accuracy: 0.7398 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 700/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5192 - accuracy: 0.7197 - val_loss: 0.5184 - val_accuracy: 0.7474\n",
            "Epoch 701/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5422 - accuracy: 0.7365 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 702/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5296 - accuracy: 0.7342 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 703/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5001 - accuracy: 0.7651 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 704/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5308 - accuracy: 0.7281 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 705/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5420 - accuracy: 0.7319 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 706/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5164 - accuracy: 0.7549 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 707/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5337 - accuracy: 0.7451 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 708/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5119 - accuracy: 0.7569 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 709/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4975 - accuracy: 0.7575 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 710/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5236 - accuracy: 0.7461 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 711/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5318 - accuracy: 0.7398 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 712/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5220 - accuracy: 0.7480 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 713/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5371 - accuracy: 0.7345 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 714/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5296 - accuracy: 0.7408 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 715/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5298 - accuracy: 0.7402 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 716/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5731 - accuracy: 0.7128 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 717/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5170 - accuracy: 0.7557 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 718/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5309 - accuracy: 0.7473 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 719/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4980 - accuracy: 0.7592 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 720/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4966 - accuracy: 0.7706 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 721/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7654 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 722/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5173 - accuracy: 0.7496 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 723/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5183 - accuracy: 0.7425 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 724/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5150 - accuracy: 0.7422 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 725/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5103 - accuracy: 0.7618 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 726/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5283 - accuracy: 0.7462 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 727/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5463 - accuracy: 0.7279 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 728/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7399 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 729/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5325 - accuracy: 0.7389 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 730/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5102 - accuracy: 0.7508 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 731/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5266 - accuracy: 0.7328 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 732/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5432 - accuracy: 0.7377 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 733/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5165 - accuracy: 0.7599 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 734/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5294 - accuracy: 0.7346 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 735/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5323 - accuracy: 0.7405 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 736/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7508 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 737/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7607 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 738/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7545 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 739/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5174 - accuracy: 0.7435 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 740/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5374 - accuracy: 0.7508 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 741/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5250 - accuracy: 0.7355 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 742/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5367 - accuracy: 0.7357 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 743/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5439 - accuracy: 0.7315 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 744/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5390 - accuracy: 0.7351 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 745/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5153 - accuracy: 0.7426 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 746/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5428 - accuracy: 0.7324 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 747/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5278 - accuracy: 0.7426 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 748/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5246 - accuracy: 0.7434 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 749/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7555 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 750/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4972 - accuracy: 0.7656 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 751/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5299 - accuracy: 0.7485 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 752/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4998 - accuracy: 0.7541 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 753/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5338 - accuracy: 0.7453 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 754/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4929 - accuracy: 0.7542 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 755/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5225 - accuracy: 0.7429 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 756/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5169 - accuracy: 0.7488 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 757/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5316 - accuracy: 0.7394 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 758/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5007 - accuracy: 0.7706 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 759/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5324 - accuracy: 0.7360 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 760/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5296 - accuracy: 0.7306 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 761/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5190 - accuracy: 0.7531 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 762/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7475 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 763/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5182 - accuracy: 0.7469 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 764/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7578 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 765/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5238 - accuracy: 0.7409 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 766/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5182 - accuracy: 0.7376 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 767/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5431 - accuracy: 0.7237 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 768/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7565 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 769/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5313 - accuracy: 0.7427 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 770/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5164 - accuracy: 0.7527 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 771/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5235 - accuracy: 0.7497 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 772/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7607 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 773/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5269 - accuracy: 0.7421 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 774/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5339 - accuracy: 0.7338 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 775/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4978 - accuracy: 0.7687 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 776/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5155 - accuracy: 0.7518 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 777/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4976 - accuracy: 0.7624 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 778/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5306 - accuracy: 0.7223 - val_loss: 0.5184 - val_accuracy: 0.7474\n",
            "Epoch 779/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5169 - accuracy: 0.7499 - val_loss: 0.5184 - val_accuracy: 0.7474\n",
            "Epoch 780/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5357 - accuracy: 0.7377 - val_loss: 0.5184 - val_accuracy: 0.7474\n",
            "Epoch 781/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5367 - accuracy: 0.7560 - val_loss: 0.5184 - val_accuracy: 0.7474\n",
            "Epoch 782/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5250 - accuracy: 0.7550 - val_loss: 0.5184 - val_accuracy: 0.7474\n",
            "Epoch 783/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7496 - val_loss: 0.5183 - val_accuracy: 0.7474\n",
            "Epoch 784/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5168 - accuracy: 0.7512 - val_loss: 0.5183 - val_accuracy: 0.7474\n",
            "Epoch 785/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4978 - accuracy: 0.7779 - val_loss: 0.5184 - val_accuracy: 0.7474\n",
            "Epoch 786/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4898 - accuracy: 0.7684 - val_loss: 0.5184 - val_accuracy: 0.7474\n",
            "Epoch 787/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5381 - accuracy: 0.7531 - val_loss: 0.5183 - val_accuracy: 0.7474\n",
            "Epoch 788/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5367 - accuracy: 0.7339 - val_loss: 0.5183 - val_accuracy: 0.7474\n",
            "Epoch 789/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5244 - accuracy: 0.7376 - val_loss: 0.5183 - val_accuracy: 0.7474\n",
            "Epoch 790/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5226 - accuracy: 0.7289 - val_loss: 0.5183 - val_accuracy: 0.7474\n",
            "Epoch 791/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5172 - accuracy: 0.7357 - val_loss: 0.5183 - val_accuracy: 0.7474\n",
            "Epoch 792/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5007 - accuracy: 0.7724 - val_loss: 0.5183 - val_accuracy: 0.7474\n",
            "Epoch 793/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7359 - val_loss: 0.5183 - val_accuracy: 0.7474\n",
            "Epoch 794/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5428 - accuracy: 0.7321 - val_loss: 0.5183 - val_accuracy: 0.7474\n",
            "Epoch 795/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5225 - accuracy: 0.7513 - val_loss: 0.5183 - val_accuracy: 0.7474\n",
            "Epoch 796/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7356 - val_loss: 0.5183 - val_accuracy: 0.7474\n",
            "Epoch 797/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5384 - accuracy: 0.7353 - val_loss: 0.5183 - val_accuracy: 0.7474\n",
            "Epoch 798/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5150 - accuracy: 0.7499 - val_loss: 0.5184 - val_accuracy: 0.7474\n",
            "Epoch 799/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4981 - accuracy: 0.7654 - val_loss: 0.5184 - val_accuracy: 0.7474\n",
            "Epoch 800/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5105 - accuracy: 0.7417 - val_loss: 0.5184 - val_accuracy: 0.7474\n",
            "Epoch 801/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5325 - accuracy: 0.7449 - val_loss: 0.5184 - val_accuracy: 0.7474\n",
            "Epoch 802/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5272 - accuracy: 0.7402 - val_loss: 0.5184 - val_accuracy: 0.7474\n",
            "Epoch 803/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5537 - accuracy: 0.7276 - val_loss: 0.5184 - val_accuracy: 0.7474\n",
            "Epoch 804/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5456 - accuracy: 0.7325 - val_loss: 0.5184 - val_accuracy: 0.7474\n",
            "Epoch 805/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5261 - accuracy: 0.7510 - val_loss: 0.5184 - val_accuracy: 0.7474\n",
            "Epoch 806/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5344 - accuracy: 0.7339 - val_loss: 0.5184 - val_accuracy: 0.7474\n",
            "Epoch 807/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5201 - accuracy: 0.7390 - val_loss: 0.5184 - val_accuracy: 0.7474\n",
            "Epoch 808/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5173 - accuracy: 0.7543 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 809/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5312 - accuracy: 0.7509 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 810/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5309 - accuracy: 0.7266 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 811/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5379 - accuracy: 0.7272 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 812/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5193 - accuracy: 0.7524 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 813/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7714 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 814/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4924 - accuracy: 0.7649 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 815/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5012 - accuracy: 0.7617 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 816/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5187 - accuracy: 0.7405 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 817/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5433 - accuracy: 0.7320 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 818/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5423 - accuracy: 0.7353 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 819/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5195 - accuracy: 0.7422 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 820/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5350 - accuracy: 0.7366 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 821/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5265 - accuracy: 0.7417 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 822/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5443 - accuracy: 0.7305 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 823/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5176 - accuracy: 0.7410 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 824/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5082 - accuracy: 0.7536 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 825/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5268 - accuracy: 0.7317 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 826/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7469 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 827/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7645 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 828/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5222 - accuracy: 0.7567 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 829/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7546 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 830/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5223 - accuracy: 0.7357 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 831/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5336 - accuracy: 0.7530 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
            "Epoch 832/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7487 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 833/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5324 - accuracy: 0.7219 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 834/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5158 - accuracy: 0.7580 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 835/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5018 - accuracy: 0.7664 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 836/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5528 - accuracy: 0.7196 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 837/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.7552 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 838/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5194 - accuracy: 0.7486 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 839/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5104 - accuracy: 0.7454 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 840/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5283 - accuracy: 0.7475 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 841/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.7576 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 842/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.7454 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 843/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7619 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 844/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5351 - accuracy: 0.7438 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 845/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.7540 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 846/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5010 - accuracy: 0.7593 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 847/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5315 - accuracy: 0.7455 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 848/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5355 - accuracy: 0.7291 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 849/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5228 - accuracy: 0.7393 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 850/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5333 - accuracy: 0.7547 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 851/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5130 - accuracy: 0.7529 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 852/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5316 - accuracy: 0.7315 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 853/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5241 - accuracy: 0.7507 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 854/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5290 - accuracy: 0.7562 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 855/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5358 - accuracy: 0.7415 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 856/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5195 - accuracy: 0.7490 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 857/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5273 - accuracy: 0.7397 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 858/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.7497 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 859/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5154 - accuracy: 0.7346 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 860/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5145 - accuracy: 0.7566 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 861/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5380 - accuracy: 0.7408 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 862/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5179 - accuracy: 0.7479 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 863/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7553 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 864/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5096 - accuracy: 0.7586 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 865/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7531 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 866/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5226 - accuracy: 0.7543 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 867/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5607 - accuracy: 0.7302 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 868/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5192 - accuracy: 0.7565 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 869/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5148 - accuracy: 0.7413 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 870/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5252 - accuracy: 0.7474 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 871/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5526 - accuracy: 0.7153 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 872/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5464 - accuracy: 0.7319 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 873/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5102 - accuracy: 0.7413 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 874/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5198 - accuracy: 0.7558 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 875/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5208 - accuracy: 0.7462 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 876/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5252 - accuracy: 0.7352 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 877/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5250 - accuracy: 0.7510 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 878/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4781 - accuracy: 0.7809 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 879/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.7482 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 880/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4924 - accuracy: 0.7613 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
            "Epoch 881/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.7551 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 882/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7539 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 883/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5511 - accuracy: 0.7306 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 884/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5170 - accuracy: 0.7594 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 885/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5222 - accuracy: 0.7511 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 886/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5349 - accuracy: 0.7376 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 887/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5373 - accuracy: 0.7270 - val_loss: 0.5188 - val_accuracy: 0.7474\n",
            "Epoch 888/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5489 - accuracy: 0.7437 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 889/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7542 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 890/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5416 - accuracy: 0.7230 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 891/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4864 - accuracy: 0.7619 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 892/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7528 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 893/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5347 - accuracy: 0.7405 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 894/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5431 - accuracy: 0.7363 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 895/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4920 - accuracy: 0.7685 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 896/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7452 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 897/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5561 - accuracy: 0.7299 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 898/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5472 - accuracy: 0.7272 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 899/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5573 - accuracy: 0.7328 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 900/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5014 - accuracy: 0.7538 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 901/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4957 - accuracy: 0.7670 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 902/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5286 - accuracy: 0.7443 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 903/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4870 - accuracy: 0.7750 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 904/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7435 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 905/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4998 - accuracy: 0.7612 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 906/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5760 - accuracy: 0.7173 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 907/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5012 - accuracy: 0.7692 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 908/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5314 - accuracy: 0.7496 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 909/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5422 - accuracy: 0.7263 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 910/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5179 - accuracy: 0.7564 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 911/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5430 - accuracy: 0.7353 - val_loss: 0.5188 - val_accuracy: 0.7474\n",
            "Epoch 912/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5137 - accuracy: 0.7441 - val_loss: 0.5188 - val_accuracy: 0.7474\n",
            "Epoch 913/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4836 - accuracy: 0.7690 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 914/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7599 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 915/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5294 - accuracy: 0.7503 - val_loss: 0.5188 - val_accuracy: 0.7474\n",
            "Epoch 916/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5306 - accuracy: 0.7301 - val_loss: 0.5188 - val_accuracy: 0.7474\n",
            "Epoch 917/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5179 - accuracy: 0.7533 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 918/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5291 - accuracy: 0.7259 - val_loss: 0.5188 - val_accuracy: 0.7474\n",
            "Epoch 919/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5355 - accuracy: 0.7336 - val_loss: 0.5188 - val_accuracy: 0.7474\n",
            "Epoch 920/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5111 - accuracy: 0.7373 - val_loss: 0.5188 - val_accuracy: 0.7474\n",
            "Epoch 921/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7526 - val_loss: 0.5188 - val_accuracy: 0.7474\n",
            "Epoch 922/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5134 - accuracy: 0.7532 - val_loss: 0.5188 - val_accuracy: 0.7474\n",
            "Epoch 923/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5135 - accuracy: 0.7427 - val_loss: 0.5188 - val_accuracy: 0.7474\n",
            "Epoch 924/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5259 - accuracy: 0.7509 - val_loss: 0.5188 - val_accuracy: 0.7474\n",
            "Epoch 925/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5189 - accuracy: 0.7450 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 926/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5115 - accuracy: 0.7532 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 927/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5163 - accuracy: 0.7451 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 928/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4852 - accuracy: 0.7622 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 929/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4982 - accuracy: 0.7689 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 930/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4993 - accuracy: 0.7736 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 931/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5227 - accuracy: 0.7367 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 932/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5284 - accuracy: 0.7456 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 933/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5225 - accuracy: 0.7530 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 934/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5298 - accuracy: 0.7476 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 935/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5398 - accuracy: 0.7247 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 936/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5146 - accuracy: 0.7558 - val_loss: 0.5188 - val_accuracy: 0.7474\n",
            "Epoch 937/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5010 - accuracy: 0.7620 - val_loss: 0.5188 - val_accuracy: 0.7474\n",
            "Epoch 938/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5243 - accuracy: 0.7517 - val_loss: 0.5188 - val_accuracy: 0.7474\n",
            "Epoch 939/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7556 - val_loss: 0.5188 - val_accuracy: 0.7474\n",
            "Epoch 940/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5379 - accuracy: 0.7252 - val_loss: 0.5188 - val_accuracy: 0.7474\n",
            "Epoch 941/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.7437 - val_loss: 0.5188 - val_accuracy: 0.7474\n",
            "Epoch 942/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5361 - accuracy: 0.7482 - val_loss: 0.5188 - val_accuracy: 0.7474\n",
            "Epoch 943/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4834 - accuracy: 0.7798 - val_loss: 0.5188 - val_accuracy: 0.7474\n",
            "Epoch 944/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5389 - accuracy: 0.7497 - val_loss: 0.5188 - val_accuracy: 0.7474\n",
            "Epoch 945/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5395 - accuracy: 0.7432 - val_loss: 0.5188 - val_accuracy: 0.7474\n",
            "Epoch 946/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7457 - val_loss: 0.5188 - val_accuracy: 0.7474\n",
            "Epoch 947/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5351 - accuracy: 0.7302 - val_loss: 0.5188 - val_accuracy: 0.7474\n",
            "Epoch 948/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5282 - accuracy: 0.7355 - val_loss: 0.5188 - val_accuracy: 0.7474\n",
            "Epoch 949/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5304 - accuracy: 0.7406 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 950/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4961 - accuracy: 0.7545 - val_loss: 0.5188 - val_accuracy: 0.7474\n",
            "Epoch 951/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4997 - accuracy: 0.7777 - val_loss: 0.5188 - val_accuracy: 0.7474\n",
            "Epoch 952/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5160 - accuracy: 0.7457 - val_loss: 0.5189 - val_accuracy: 0.7474\n",
            "Epoch 953/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5407 - accuracy: 0.7424 - val_loss: 0.5188 - val_accuracy: 0.7474\n",
            "Epoch 954/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5215 - accuracy: 0.7431 - val_loss: 0.5188 - val_accuracy: 0.7474\n",
            "Epoch 955/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5016 - accuracy: 0.7578 - val_loss: 0.5188 - val_accuracy: 0.7474\n",
            "Epoch 956/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4973 - accuracy: 0.7566 - val_loss: 0.5188 - val_accuracy: 0.7474\n",
            "Epoch 957/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5190 - accuracy: 0.7497 - val_loss: 0.5188 - val_accuracy: 0.7474\n",
            "Epoch 958/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5386 - accuracy: 0.7358 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 959/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4977 - accuracy: 0.7581 - val_loss: 0.5188 - val_accuracy: 0.7474\n",
            "Epoch 960/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5121 - accuracy: 0.7446 - val_loss: 0.5188 - val_accuracy: 0.7474\n",
            "Epoch 961/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5146 - accuracy: 0.7468 - val_loss: 0.5188 - val_accuracy: 0.7474\n",
            "Epoch 962/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5137 - accuracy: 0.7548 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 963/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4984 - accuracy: 0.7538 - val_loss: 0.5188 - val_accuracy: 0.7474\n",
            "Epoch 964/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.7451 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 965/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5107 - accuracy: 0.7457 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 966/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5197 - accuracy: 0.7396 - val_loss: 0.5188 - val_accuracy: 0.7474\n",
            "Epoch 967/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5140 - accuracy: 0.7548 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 968/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5340 - accuracy: 0.7370 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 969/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5141 - accuracy: 0.7447 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
            "Epoch 970/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5227 - accuracy: 0.7408 - val_loss: 0.5188 - val_accuracy: 0.7474\n",
            "Epoch 971/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.7549 - val_loss: 0.5188 - val_accuracy: 0.7474\n",
            "Epoch 972/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5426 - accuracy: 0.7371 - val_loss: 0.5188 - val_accuracy: 0.7474\n",
            "Epoch 973/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5222 - accuracy: 0.7322 - val_loss: 0.5188 - val_accuracy: 0.7474\n",
            "Epoch 974/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5240 - accuracy: 0.7541 - val_loss: 0.5188 - val_accuracy: 0.7474\n",
            "Epoch 975/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5334 - accuracy: 0.7474 - val_loss: 0.5188 - val_accuracy: 0.7474\n",
            "Epoch 976/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7567 - val_loss: 0.5189 - val_accuracy: 0.7474\n",
            "Epoch 977/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7710 - val_loss: 0.5189 - val_accuracy: 0.7474\n",
            "Epoch 978/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5258 - accuracy: 0.7307 - val_loss: 0.5188 - val_accuracy: 0.7474\n",
            "Epoch 979/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5291 - accuracy: 0.7418 - val_loss: 0.5188 - val_accuracy: 0.7474\n",
            "Epoch 980/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5326 - accuracy: 0.7272 - val_loss: 0.5188 - val_accuracy: 0.7474\n",
            "Epoch 981/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4993 - accuracy: 0.7554 - val_loss: 0.5188 - val_accuracy: 0.7474\n",
            "Epoch 982/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5149 - accuracy: 0.7445 - val_loss: 0.5189 - val_accuracy: 0.7474\n",
            "Epoch 983/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5260 - accuracy: 0.7293 - val_loss: 0.5189 - val_accuracy: 0.7474\n",
            "Epoch 984/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5394 - accuracy: 0.7355 - val_loss: 0.5188 - val_accuracy: 0.7474\n",
            "Epoch 985/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5296 - accuracy: 0.7388 - val_loss: 0.5188 - val_accuracy: 0.7474\n",
            "Epoch 986/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7582 - val_loss: 0.5189 - val_accuracy: 0.7474\n",
            "Epoch 987/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5310 - accuracy: 0.7468 - val_loss: 0.5189 - val_accuracy: 0.7474\n",
            "Epoch 988/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5339 - accuracy: 0.7347 - val_loss: 0.5189 - val_accuracy: 0.7474\n",
            "Epoch 989/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5157 - accuracy: 0.7434 - val_loss: 0.5188 - val_accuracy: 0.7474\n",
            "Epoch 990/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4954 - accuracy: 0.7610 - val_loss: 0.5188 - val_accuracy: 0.7474\n",
            "Epoch 991/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5255 - accuracy: 0.7447 - val_loss: 0.5188 - val_accuracy: 0.7474\n",
            "Epoch 992/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5269 - accuracy: 0.7284 - val_loss: 0.5188 - val_accuracy: 0.7474\n",
            "Epoch 993/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5020 - accuracy: 0.7548 - val_loss: 0.5189 - val_accuracy: 0.7474\n",
            "Epoch 994/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7458 - val_loss: 0.5189 - val_accuracy: 0.7474\n",
            "Epoch 995/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5224 - accuracy: 0.7301 - val_loss: 0.5189 - val_accuracy: 0.7474\n",
            "Epoch 996/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5169 - accuracy: 0.7443 - val_loss: 0.5189 - val_accuracy: 0.7474\n",
            "Epoch 997/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5132 - accuracy: 0.7575 - val_loss: 0.5189 - val_accuracy: 0.7474\n",
            "Epoch 998/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5228 - accuracy: 0.7518 - val_loss: 0.5189 - val_accuracy: 0.7474\n",
            "Epoch 999/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4949 - accuracy: 0.7615 - val_loss: 0.5189 - val_accuracy: 0.7474\n",
            "Epoch 1000/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5291 - accuracy: 0.7420 - val_loss: 0.5190 - val_accuracy: 0.7474\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "DWSMWTP9KVrw",
        "outputId": "abf41384-d03a-4a89-d1d0-8d3b5497d8d2"
      },
      "source": [
        "plt.plot(history_0.history['accuracy'])\n",
        "plt.plot(history_0.history['val_accuracy'])\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training data', 'validation data'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "2PRVxEfLKeCc",
        "outputId": "b8b25632-287c-47ce-9858-723dc26aeefb"
      },
      "source": [
        "plt.plot(history_0.history['loss'])\n",
        "plt.plot(history_0.history['val_loss'])\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training data', 'validation data'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIkyBnQJKu3B",
        "outputId": "25670938-e2cd-4f3e-ebbf-6430dd42d522"
      },
      "source": [
        "P0 = model_0.predict(XTRAIN)\n",
        "accuracy_train0 = model_0.evaluate(XTRAIN, YTRAIN)\n",
        "\n",
        "print(accuracy_train0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5189 - accuracy: 0.7473\n",
            "[0.5189390182495117, 0.7473214268684387]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6S-wZffKy8J",
        "outputId": "0f0f1df1-0283-4735-a4c0-af1f562f5087"
      },
      "source": [
        "P0 = model_0.predict(XVALID)\n",
        "accuracy_valid0 = model_0.evaluate(XVALID, YVALID)\n",
        "\n",
        "print(accuracy_valid0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15/15 [==============================] - 0s 1ms/step - loss: 0.5190 - accuracy: 0.7474\n",
            "[0.5189520120620728, 0.7473903894424438]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAx92LfsLwpk",
        "outputId": "cb4a1182-4d25-4d59-a360-b76a78329f15"
      },
      "source": [
        "from sklearn.metrics import mean_absolute_error as mae\n",
        "mae(accuracy_train0, accuracy_valid0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.0978193283081055e-05"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJKlXxxqlvI7"
      },
      "source": [
        "prediction = model_0.predict(XTRAIN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFM4EGdHMQDb"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZD1Hg2oxMSDp",
        "outputId": "86895fbc-a3ac-4315-a239-270b0c440f19"
      },
      "source": [
        "new_accuracy = accuracy_score(YTRAIN, prediction.round())\n",
        "new_precision = precision_score(YTRAIN , prediction.round())\n",
        "new_recall = recall_score(YTRAIN , prediction.round())\n",
        "new_f1 = f1_score(YTRAIN, prediction.round())\n",
        "\n",
        "print(new_accuracy)\n",
        "print(new_precision)\n",
        "print(new_recall)\n",
        "print(new_f1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7473214285714286\n",
            "0.7715736040609137\n",
            "0.7549668874172185\n",
            "0.7631799163179916\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLicRTD6Lm9O"
      },
      "source": [
        "model_1 = Sequential()\n",
        "model_1.add(Dense(8, input_dim = len(XTRAIN[0, :]), activation='relu'))\n",
        "model_1.add(Dense(6, activation='relu'))\n",
        "model_1.add(Dense(4, activation='relu'))\n",
        "model_1.add(Dense(4, activation='relu'))\n",
        "model_1.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9WUdPziMGj3"
      },
      "source": [
        "model_1.compile(loss='binary_crossentropy', optimizer = 'rmsprop', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McfdydhPMWy3",
        "outputId": "c0426e38-a99e-4059-941f-65893c68bda1"
      },
      "source": [
        "history_1 = model_1.fit(XTRAIN, YTRAIN, validation_data=(XVALID, YVALID), epochs = 100, batch_size=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "112/112 [==============================] - 1s 3ms/step - loss: 0.6940 - accuracy: 0.4811 - val_loss: 0.6914 - val_accuracy: 0.6180\n",
            "Epoch 2/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6910 - accuracy: 0.5685 - val_loss: 0.6894 - val_accuracy: 0.6075\n",
            "Epoch 3/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6882 - accuracy: 0.6288 - val_loss: 0.6861 - val_accuracy: 0.6096\n",
            "Epoch 4/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6841 - accuracy: 0.6453 - val_loss: 0.6799 - val_accuracy: 0.6660\n",
            "Epoch 5/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6788 - accuracy: 0.6602 - val_loss: 0.6728 - val_accuracy: 0.6701\n",
            "Epoch 6/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6705 - accuracy: 0.6722 - val_loss: 0.6639 - val_accuracy: 0.6827\n",
            "Epoch 7/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6621 - accuracy: 0.6669 - val_loss: 0.6523 - val_accuracy: 0.6931\n",
            "Epoch 8/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6501 - accuracy: 0.6917 - val_loss: 0.6421 - val_accuracy: 0.6910\n",
            "Epoch 9/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6368 - accuracy: 0.6840 - val_loss: 0.6307 - val_accuracy: 0.6931\n",
            "Epoch 10/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6248 - accuracy: 0.7067 - val_loss: 0.6211 - val_accuracy: 0.6994\n",
            "Epoch 11/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6205 - accuracy: 0.6986 - val_loss: 0.6140 - val_accuracy: 0.7098\n",
            "Epoch 12/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6218 - accuracy: 0.6920 - val_loss: 0.6044 - val_accuracy: 0.6994\n",
            "Epoch 13/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6054 - accuracy: 0.7073 - val_loss: 0.5979 - val_accuracy: 0.7119\n",
            "Epoch 14/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5975 - accuracy: 0.7082 - val_loss: 0.5917 - val_accuracy: 0.7161\n",
            "Epoch 15/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5832 - accuracy: 0.7236 - val_loss: 0.5857 - val_accuracy: 0.7203\n",
            "Epoch 16/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5785 - accuracy: 0.7216 - val_loss: 0.5812 - val_accuracy: 0.7223\n",
            "Epoch 17/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6003 - accuracy: 0.7051 - val_loss: 0.5779 - val_accuracy: 0.7265\n",
            "Epoch 18/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5726 - accuracy: 0.7227 - val_loss: 0.5742 - val_accuracy: 0.7307\n",
            "Epoch 19/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5626 - accuracy: 0.7366 - val_loss: 0.5748 - val_accuracy: 0.7328\n",
            "Epoch 20/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5630 - accuracy: 0.7343 - val_loss: 0.5684 - val_accuracy: 0.7349\n",
            "Epoch 21/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5709 - accuracy: 0.7236 - val_loss: 0.5656 - val_accuracy: 0.7349\n",
            "Epoch 22/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5470 - accuracy: 0.7523 - val_loss: 0.5629 - val_accuracy: 0.7370\n",
            "Epoch 23/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5544 - accuracy: 0.7498 - val_loss: 0.5620 - val_accuracy: 0.7432\n",
            "Epoch 24/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5440 - accuracy: 0.7575 - val_loss: 0.5586 - val_accuracy: 0.7432\n",
            "Epoch 25/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5696 - accuracy: 0.7242 - val_loss: 0.5577 - val_accuracy: 0.7411\n",
            "Epoch 26/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5550 - accuracy: 0.7392 - val_loss: 0.5568 - val_accuracy: 0.7286\n",
            "Epoch 27/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5519 - accuracy: 0.7286 - val_loss: 0.5536 - val_accuracy: 0.7495\n",
            "Epoch 28/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5356 - accuracy: 0.7645 - val_loss: 0.5527 - val_accuracy: 0.7432\n",
            "Epoch 29/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5580 - accuracy: 0.7353 - val_loss: 0.5510 - val_accuracy: 0.7516\n",
            "Epoch 30/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5527 - accuracy: 0.7256 - val_loss: 0.5520 - val_accuracy: 0.7453\n",
            "Epoch 31/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5368 - accuracy: 0.7382 - val_loss: 0.5496 - val_accuracy: 0.7349\n",
            "Epoch 32/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5463 - accuracy: 0.7494 - val_loss: 0.5486 - val_accuracy: 0.7411\n",
            "Epoch 33/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5368 - accuracy: 0.7523 - val_loss: 0.5497 - val_accuracy: 0.7328\n",
            "Epoch 34/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5584 - accuracy: 0.7296 - val_loss: 0.5456 - val_accuracy: 0.7557\n",
            "Epoch 35/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5284 - accuracy: 0.7617 - val_loss: 0.5462 - val_accuracy: 0.7370\n",
            "Epoch 36/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5311 - accuracy: 0.7614 - val_loss: 0.5448 - val_accuracy: 0.7537\n",
            "Epoch 37/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5488 - accuracy: 0.7378 - val_loss: 0.5437 - val_accuracy: 0.7516\n",
            "Epoch 38/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5512 - accuracy: 0.7350 - val_loss: 0.5431 - val_accuracy: 0.7495\n",
            "Epoch 39/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5413 - accuracy: 0.7365 - val_loss: 0.5424 - val_accuracy: 0.7516\n",
            "Epoch 40/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5238 - accuracy: 0.7478 - val_loss: 0.5416 - val_accuracy: 0.7516\n",
            "Epoch 41/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5474 - accuracy: 0.7300 - val_loss: 0.5412 - val_accuracy: 0.7516\n",
            "Epoch 42/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5333 - accuracy: 0.7585 - val_loss: 0.5409 - val_accuracy: 0.7516\n",
            "Epoch 43/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5503 - accuracy: 0.7276 - val_loss: 0.5396 - val_accuracy: 0.7537\n",
            "Epoch 44/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5511 - accuracy: 0.7463 - val_loss: 0.5394 - val_accuracy: 0.7578\n",
            "Epoch 45/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5307 - accuracy: 0.7282 - val_loss: 0.5379 - val_accuracy: 0.7537\n",
            "Epoch 46/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5446 - accuracy: 0.7252 - val_loss: 0.5376 - val_accuracy: 0.7537\n",
            "Epoch 47/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5373 - accuracy: 0.7552 - val_loss: 0.5380 - val_accuracy: 0.7516\n",
            "Epoch 48/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7600 - val_loss: 0.5370 - val_accuracy: 0.7474\n",
            "Epoch 49/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5477 - accuracy: 0.7391 - val_loss: 0.5388 - val_accuracy: 0.7557\n",
            "Epoch 50/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5306 - accuracy: 0.7402 - val_loss: 0.5359 - val_accuracy: 0.7432\n",
            "Epoch 51/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5345 - accuracy: 0.7465 - val_loss: 0.5362 - val_accuracy: 0.7474\n",
            "Epoch 52/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5360 - accuracy: 0.7428 - val_loss: 0.5356 - val_accuracy: 0.7474\n",
            "Epoch 53/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5168 - accuracy: 0.7617 - val_loss: 0.5347 - val_accuracy: 0.7474\n",
            "Epoch 54/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5233 - accuracy: 0.7548 - val_loss: 0.5340 - val_accuracy: 0.7474\n",
            "Epoch 55/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5228 - accuracy: 0.7436 - val_loss: 0.5350 - val_accuracy: 0.7599\n",
            "Epoch 56/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5344 - accuracy: 0.7557 - val_loss: 0.5332 - val_accuracy: 0.7557\n",
            "Epoch 57/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5460 - accuracy: 0.7353 - val_loss: 0.5338 - val_accuracy: 0.7578\n",
            "Epoch 58/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5190 - accuracy: 0.7537 - val_loss: 0.5350 - val_accuracy: 0.7557\n",
            "Epoch 59/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5457 - accuracy: 0.7285 - val_loss: 0.5316 - val_accuracy: 0.7537\n",
            "Epoch 60/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5317 - accuracy: 0.7372 - val_loss: 0.5332 - val_accuracy: 0.7557\n",
            "Epoch 61/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5418 - accuracy: 0.7288 - val_loss: 0.5326 - val_accuracy: 0.7599\n",
            "Epoch 62/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5349 - accuracy: 0.7329 - val_loss: 0.5318 - val_accuracy: 0.7599\n",
            "Epoch 63/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5257 - accuracy: 0.7478 - val_loss: 0.5315 - val_accuracy: 0.7599\n",
            "Epoch 64/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5302 - accuracy: 0.7415 - val_loss: 0.5315 - val_accuracy: 0.7453\n",
            "Epoch 65/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5273 - accuracy: 0.7296 - val_loss: 0.5312 - val_accuracy: 0.7578\n",
            "Epoch 66/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5190 - accuracy: 0.7642 - val_loss: 0.5307 - val_accuracy: 0.7578\n",
            "Epoch 67/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5253 - accuracy: 0.7400 - val_loss: 0.5305 - val_accuracy: 0.7453\n",
            "Epoch 68/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5372 - accuracy: 0.7459 - val_loss: 0.5312 - val_accuracy: 0.7516\n",
            "Epoch 69/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5140 - accuracy: 0.7529 - val_loss: 0.5306 - val_accuracy: 0.7578\n",
            "Epoch 70/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4971 - accuracy: 0.7603 - val_loss: 0.5297 - val_accuracy: 0.7453\n",
            "Epoch 71/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5295 - accuracy: 0.7423 - val_loss: 0.5299 - val_accuracy: 0.7474\n",
            "Epoch 72/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5165 - accuracy: 0.7492 - val_loss: 0.5298 - val_accuracy: 0.7432\n",
            "Epoch 73/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7641 - val_loss: 0.5328 - val_accuracy: 0.7453\n",
            "Epoch 74/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5193 - accuracy: 0.7486 - val_loss: 0.5299 - val_accuracy: 0.7495\n",
            "Epoch 75/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5215 - accuracy: 0.7417 - val_loss: 0.5299 - val_accuracy: 0.7516\n",
            "Epoch 76/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7602 - val_loss: 0.5294 - val_accuracy: 0.7495\n",
            "Epoch 77/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5294 - accuracy: 0.7362 - val_loss: 0.5297 - val_accuracy: 0.7495\n",
            "Epoch 78/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5352 - accuracy: 0.7387 - val_loss: 0.5295 - val_accuracy: 0.7474\n",
            "Epoch 79/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5222 - accuracy: 0.7410 - val_loss: 0.5319 - val_accuracy: 0.7537\n",
            "Epoch 80/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5125 - accuracy: 0.7578 - val_loss: 0.5306 - val_accuracy: 0.7474\n",
            "Epoch 81/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5145 - accuracy: 0.7525 - val_loss: 0.5291 - val_accuracy: 0.7453\n",
            "Epoch 82/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5169 - accuracy: 0.7574 - val_loss: 0.5274 - val_accuracy: 0.7516\n",
            "Epoch 83/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5335 - accuracy: 0.7452 - val_loss: 0.5305 - val_accuracy: 0.7537\n",
            "Epoch 84/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5002 - accuracy: 0.7612 - val_loss: 0.5288 - val_accuracy: 0.7453\n",
            "Epoch 85/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5155 - accuracy: 0.7534 - val_loss: 0.5274 - val_accuracy: 0.7495\n",
            "Epoch 86/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5264 - accuracy: 0.7325 - val_loss: 0.5295 - val_accuracy: 0.7495\n",
            "Epoch 87/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5135 - accuracy: 0.7457 - val_loss: 0.5278 - val_accuracy: 0.7495\n",
            "Epoch 88/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7537 - val_loss: 0.5265 - val_accuracy: 0.7453\n",
            "Epoch 89/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.7497 - val_loss: 0.5264 - val_accuracy: 0.7516\n",
            "Epoch 90/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5231 - accuracy: 0.7461 - val_loss: 0.5274 - val_accuracy: 0.7474\n",
            "Epoch 91/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5245 - accuracy: 0.7509 - val_loss: 0.5261 - val_accuracy: 0.7495\n",
            "Epoch 92/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.7548 - val_loss: 0.5327 - val_accuracy: 0.7495\n",
            "Epoch 93/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5184 - accuracy: 0.7486 - val_loss: 0.5257 - val_accuracy: 0.7516\n",
            "Epoch 94/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5315 - accuracy: 0.7392 - val_loss: 0.5301 - val_accuracy: 0.7557\n",
            "Epoch 95/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.7429 - val_loss: 0.5252 - val_accuracy: 0.7516\n",
            "Epoch 96/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5256 - accuracy: 0.7375 - val_loss: 0.5268 - val_accuracy: 0.7474\n",
            "Epoch 97/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5458 - accuracy: 0.7215 - val_loss: 0.5294 - val_accuracy: 0.7557\n",
            "Epoch 98/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7589 - val_loss: 0.5244 - val_accuracy: 0.7495\n",
            "Epoch 99/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.7422 - val_loss: 0.5275 - val_accuracy: 0.7516\n",
            "Epoch 100/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5135 - accuracy: 0.7497 - val_loss: 0.5234 - val_accuracy: 0.7516\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "a-7m4hN1MrYE",
        "outputId": "129e91d9-9d4c-4303-d8c1-6f9f0d767531"
      },
      "source": [
        "plt.plot(history_1.history['accuracy'])\n",
        "plt.plot(history_1.history['val_accuracy'])\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training data', 'validation data'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "YgfAjyTkM2Fh",
        "outputId": "388e331b-de6a-4307-8c60-e06333ac42d5"
      },
      "source": [
        "plt.plot(history_1.history['loss'])\n",
        "plt.plot(history_1.history['val_loss'])\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training data', 'validation data'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTb5zGtjNLA-",
        "outputId": "657cbe78-6bd0-4e4b-bcda-b35662c00833"
      },
      "source": [
        "P0 = model_1.predict(XTRAIN)\n",
        "accuracy_train = model_1.evaluate(XTRAIN, YTRAIN)\n",
        "\n",
        "print(accuracy_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7750\n",
            "[0.4620613753795624, 0.7749999761581421]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_gBjE59NPHn",
        "outputId": "d1ebb9d5-b826-449e-a864-415629d7559f"
      },
      "source": [
        "P0 = model_1.predict(XVALID)\n",
        "accuracy_valid = model_1.evaluate(XVALID, YVALID)\n",
        "\n",
        "print(accuracy_valid)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15/15 [==============================] - 0s 1ms/step - loss: 0.5604 - accuracy: 0.7557\n",
            "[0.5604380369186401, 0.7557411193847656]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kuem8ZDNibz",
        "outputId": "fd171a03-ecf7-4dd8-c732-aef1b4fd4f07"
      },
      "source": [
        "from sklearn.metrics import mean_absolute_error as mae\n",
        "mae(accuracy_train, accuracy_valid)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.005200862884521484"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgqCnUAPOGGT"
      },
      "source": [
        "model_2 = Sequential()\n",
        "model_2.add(Dense(12, input_dim = len(XTRAIN[0, :]), activation='relu'))\n",
        "model_2.add(Dense(8, activation='relu'))\n",
        "model_2.add(Dense(4, activation='relu'))\n",
        "model_2.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4P2CpgvJOpm4"
      },
      "source": [
        "model_2.compile(loss='binary_crossentropy', optimizer = 'rmsprop', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4o6GmsMO2Td",
        "outputId": "6adf4123-8a10-4d0e-a14f-245cfe3e2bb2"
      },
      "source": [
        "history_2 = model_2.fit(XTRAIN, YTRAIN, validation_data=(XVALID, YVALID), epochs=300, batch_size=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "112/112 [==============================] - 1s 3ms/step - loss: 0.6891 - accuracy: 0.5845 - val_loss: 0.6767 - val_accuracy: 0.6180\n",
            "Epoch 2/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6644 - accuracy: 0.6159 - val_loss: 0.6553 - val_accuracy: 0.6973\n",
            "Epoch 3/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6408 - accuracy: 0.6623 - val_loss: 0.6345 - val_accuracy: 0.6973\n",
            "Epoch 4/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6299 - accuracy: 0.6724 - val_loss: 0.6266 - val_accuracy: 0.6263\n",
            "Epoch 5/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6090 - accuracy: 0.6921 - val_loss: 0.5994 - val_accuracy: 0.6952\n",
            "Epoch 6/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5798 - accuracy: 0.7262 - val_loss: 0.5801 - val_accuracy: 0.7370\n",
            "Epoch 7/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5791 - accuracy: 0.7098 - val_loss: 0.5676 - val_accuracy: 0.7474\n",
            "Epoch 8/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5680 - accuracy: 0.7277 - val_loss: 0.5539 - val_accuracy: 0.7495\n",
            "Epoch 9/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5643 - accuracy: 0.7145 - val_loss: 0.5394 - val_accuracy: 0.7495\n",
            "Epoch 10/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5551 - accuracy: 0.7157 - val_loss: 0.5360 - val_accuracy: 0.7557\n",
            "Epoch 11/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5447 - accuracy: 0.7254 - val_loss: 0.5239 - val_accuracy: 0.7432\n",
            "Epoch 12/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5429 - accuracy: 0.7281 - val_loss: 0.5203 - val_accuracy: 0.7474\n",
            "Epoch 13/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7611 - val_loss: 0.5127 - val_accuracy: 0.7495\n",
            "Epoch 14/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5448 - accuracy: 0.7402 - val_loss: 0.5099 - val_accuracy: 0.7599\n",
            "Epoch 15/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5364 - accuracy: 0.7492 - val_loss: 0.5256 - val_accuracy: 0.7537\n",
            "Epoch 16/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5546 - accuracy: 0.7394 - val_loss: 0.5060 - val_accuracy: 0.7578\n",
            "Epoch 17/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7581 - val_loss: 0.5029 - val_accuracy: 0.7557\n",
            "Epoch 18/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5247 - accuracy: 0.7640 - val_loss: 0.5029 - val_accuracy: 0.7578\n",
            "Epoch 19/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7603 - val_loss: 0.5009 - val_accuracy: 0.7516\n",
            "Epoch 20/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5209 - accuracy: 0.7640 - val_loss: 0.4999 - val_accuracy: 0.7516\n",
            "Epoch 21/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5169 - accuracy: 0.7586 - val_loss: 0.5074 - val_accuracy: 0.7578\n",
            "Epoch 22/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5458 - accuracy: 0.7394 - val_loss: 0.4987 - val_accuracy: 0.7495\n",
            "Epoch 23/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7750 - val_loss: 0.5014 - val_accuracy: 0.7578\n",
            "Epoch 24/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7575 - val_loss: 0.5002 - val_accuracy: 0.7557\n",
            "Epoch 25/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5132 - accuracy: 0.7591 - val_loss: 0.4978 - val_accuracy: 0.7495\n",
            "Epoch 26/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7595 - val_loss: 0.4994 - val_accuracy: 0.7537\n",
            "Epoch 27/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5162 - accuracy: 0.7434 - val_loss: 0.4973 - val_accuracy: 0.7516\n",
            "Epoch 28/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5162 - accuracy: 0.7569 - val_loss: 0.4968 - val_accuracy: 0.7537\n",
            "Epoch 29/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7612 - val_loss: 0.4993 - val_accuracy: 0.7578\n",
            "Epoch 30/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5155 - accuracy: 0.7510 - val_loss: 0.4967 - val_accuracy: 0.7495\n",
            "Epoch 31/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5253 - accuracy: 0.7423 - val_loss: 0.4964 - val_accuracy: 0.7537\n",
            "Epoch 32/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7496 - val_loss: 0.4985 - val_accuracy: 0.7537\n",
            "Epoch 33/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5021 - accuracy: 0.7658 - val_loss: 0.4962 - val_accuracy: 0.7537\n",
            "Epoch 34/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5001 - accuracy: 0.7619 - val_loss: 0.4965 - val_accuracy: 0.7474\n",
            "Epoch 35/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5499 - accuracy: 0.7269 - val_loss: 0.4962 - val_accuracy: 0.7495\n",
            "Epoch 36/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4890 - accuracy: 0.7608 - val_loss: 0.4975 - val_accuracy: 0.7537\n",
            "Epoch 37/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5167 - accuracy: 0.7453 - val_loss: 0.4969 - val_accuracy: 0.7495\n",
            "Epoch 38/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5104 - accuracy: 0.7504 - val_loss: 0.5152 - val_accuracy: 0.7495\n",
            "Epoch 39/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5207 - accuracy: 0.7398 - val_loss: 0.5071 - val_accuracy: 0.7495\n",
            "Epoch 40/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5284 - accuracy: 0.7473 - val_loss: 0.5030 - val_accuracy: 0.7557\n",
            "Epoch 41/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.7571 - val_loss: 0.5071 - val_accuracy: 0.7495\n",
            "Epoch 42/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5251 - accuracy: 0.7415 - val_loss: 0.5006 - val_accuracy: 0.7537\n",
            "Epoch 43/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7435 - val_loss: 0.4974 - val_accuracy: 0.7495\n",
            "Epoch 44/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7645 - val_loss: 0.5120 - val_accuracy: 0.7453\n",
            "Epoch 45/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4940 - accuracy: 0.7457 - val_loss: 0.5092 - val_accuracy: 0.7453\n",
            "Epoch 46/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7627 - val_loss: 0.4970 - val_accuracy: 0.7495\n",
            "Epoch 47/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5104 - accuracy: 0.7622 - val_loss: 0.4971 - val_accuracy: 0.7537\n",
            "Epoch 48/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5282 - accuracy: 0.7545 - val_loss: 0.4967 - val_accuracy: 0.7578\n",
            "Epoch 49/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4877 - accuracy: 0.7720 - val_loss: 0.4963 - val_accuracy: 0.7474\n",
            "Epoch 50/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5266 - accuracy: 0.7518 - val_loss: 0.5129 - val_accuracy: 0.7474\n",
            "Epoch 51/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5275 - accuracy: 0.7489 - val_loss: 0.4970 - val_accuracy: 0.7474\n",
            "Epoch 52/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4963 - accuracy: 0.7731 - val_loss: 0.4997 - val_accuracy: 0.7537\n",
            "Epoch 53/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5451 - accuracy: 0.7353 - val_loss: 0.5056 - val_accuracy: 0.7495\n",
            "Epoch 54/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4893 - accuracy: 0.7668 - val_loss: 0.4980 - val_accuracy: 0.7557\n",
            "Epoch 55/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.7796 - val_loss: 0.4983 - val_accuracy: 0.7620\n",
            "Epoch 56/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4967 - accuracy: 0.7828 - val_loss: 0.4997 - val_accuracy: 0.7411\n",
            "Epoch 57/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7589 - val_loss: 0.4969 - val_accuracy: 0.7537\n",
            "Epoch 58/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4970 - accuracy: 0.7723 - val_loss: 0.5001 - val_accuracy: 0.7411\n",
            "Epoch 59/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.7548 - val_loss: 0.4969 - val_accuracy: 0.7557\n",
            "Epoch 60/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5326 - accuracy: 0.7494 - val_loss: 0.5001 - val_accuracy: 0.7516\n",
            "Epoch 61/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4853 - accuracy: 0.7762 - val_loss: 0.4981 - val_accuracy: 0.7495\n",
            "Epoch 62/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4838 - accuracy: 0.7700 - val_loss: 0.4998 - val_accuracy: 0.7453\n",
            "Epoch 63/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5099 - accuracy: 0.7660 - val_loss: 0.4976 - val_accuracy: 0.7495\n",
            "Epoch 64/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4781 - accuracy: 0.7804 - val_loss: 0.4977 - val_accuracy: 0.7578\n",
            "Epoch 65/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7561 - val_loss: 0.4978 - val_accuracy: 0.7537\n",
            "Epoch 66/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4800 - accuracy: 0.7772 - val_loss: 0.5012 - val_accuracy: 0.7390\n",
            "Epoch 67/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5118 - accuracy: 0.7686 - val_loss: 0.4976 - val_accuracy: 0.7578\n",
            "Epoch 68/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4776 - accuracy: 0.7751 - val_loss: 0.5022 - val_accuracy: 0.7516\n",
            "Epoch 69/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7593 - val_loss: 0.4980 - val_accuracy: 0.7557\n",
            "Epoch 70/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5145 - accuracy: 0.7525 - val_loss: 0.4992 - val_accuracy: 0.7495\n",
            "Epoch 71/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5126 - accuracy: 0.7544 - val_loss: 0.5054 - val_accuracy: 0.7537\n",
            "Epoch 72/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.7454 - val_loss: 0.4990 - val_accuracy: 0.7599\n",
            "Epoch 73/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4917 - accuracy: 0.7764 - val_loss: 0.5137 - val_accuracy: 0.7453\n",
            "Epoch 74/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4876 - accuracy: 0.7609 - val_loss: 0.5009 - val_accuracy: 0.7578\n",
            "Epoch 75/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5330 - accuracy: 0.7403 - val_loss: 0.5041 - val_accuracy: 0.7495\n",
            "Epoch 76/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4867 - accuracy: 0.7768 - val_loss: 0.4991 - val_accuracy: 0.7599\n",
            "Epoch 77/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5009 - accuracy: 0.7594 - val_loss: 0.5004 - val_accuracy: 0.7641\n",
            "Epoch 78/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4875 - accuracy: 0.7708 - val_loss: 0.4999 - val_accuracy: 0.7620\n",
            "Epoch 79/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5292 - accuracy: 0.7402 - val_loss: 0.5063 - val_accuracy: 0.7495\n",
            "Epoch 80/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5293 - accuracy: 0.7521 - val_loss: 0.5000 - val_accuracy: 0.7516\n",
            "Epoch 81/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5210 - accuracy: 0.7569 - val_loss: 0.5150 - val_accuracy: 0.7495\n",
            "Epoch 82/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7604 - val_loss: 0.5002 - val_accuracy: 0.7578\n",
            "Epoch 83/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4867 - accuracy: 0.7497 - val_loss: 0.5012 - val_accuracy: 0.7516\n",
            "Epoch 84/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4571 - accuracy: 0.8117 - val_loss: 0.5014 - val_accuracy: 0.7537\n",
            "Epoch 85/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4826 - accuracy: 0.7711 - val_loss: 0.4996 - val_accuracy: 0.7620\n",
            "Epoch 86/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4852 - accuracy: 0.7715 - val_loss: 0.5008 - val_accuracy: 0.7578\n",
            "Epoch 87/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5118 - accuracy: 0.7527 - val_loss: 0.5006 - val_accuracy: 0.7516\n",
            "Epoch 88/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4851 - accuracy: 0.7788 - val_loss: 0.4998 - val_accuracy: 0.7641\n",
            "Epoch 89/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4766 - accuracy: 0.7512 - val_loss: 0.5005 - val_accuracy: 0.7557\n",
            "Epoch 90/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4812 - accuracy: 0.7780 - val_loss: 0.5004 - val_accuracy: 0.7557\n",
            "Epoch 91/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4954 - accuracy: 0.7586 - val_loss: 0.5074 - val_accuracy: 0.7495\n",
            "Epoch 92/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4852 - accuracy: 0.7734 - val_loss: 0.5139 - val_accuracy: 0.7411\n",
            "Epoch 93/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4689 - accuracy: 0.7931 - val_loss: 0.5024 - val_accuracy: 0.7620\n",
            "Epoch 94/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5098 - accuracy: 0.7672 - val_loss: 0.5079 - val_accuracy: 0.7495\n",
            "Epoch 95/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5273 - accuracy: 0.7487 - val_loss: 0.5080 - val_accuracy: 0.7516\n",
            "Epoch 96/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4695 - accuracy: 0.7834 - val_loss: 0.5025 - val_accuracy: 0.7599\n",
            "Epoch 97/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4821 - accuracy: 0.7811 - val_loss: 0.5012 - val_accuracy: 0.7537\n",
            "Epoch 98/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4754 - accuracy: 0.7740 - val_loss: 0.5019 - val_accuracy: 0.7578\n",
            "Epoch 99/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4890 - accuracy: 0.7828 - val_loss: 0.5021 - val_accuracy: 0.7620\n",
            "Epoch 100/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7479 - val_loss: 0.5066 - val_accuracy: 0.7516\n",
            "Epoch 101/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4751 - accuracy: 0.7910 - val_loss: 0.5036 - val_accuracy: 0.7557\n",
            "Epoch 102/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4903 - accuracy: 0.7805 - val_loss: 0.5132 - val_accuracy: 0.7432\n",
            "Epoch 103/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7625 - val_loss: 0.5026 - val_accuracy: 0.7599\n",
            "Epoch 104/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4740 - accuracy: 0.7646 - val_loss: 0.5105 - val_accuracy: 0.7537\n",
            "Epoch 105/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4957 - accuracy: 0.7630 - val_loss: 0.5030 - val_accuracy: 0.7620\n",
            "Epoch 106/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4955 - accuracy: 0.7598 - val_loss: 0.5029 - val_accuracy: 0.7537\n",
            "Epoch 107/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4994 - accuracy: 0.7504 - val_loss: 0.5075 - val_accuracy: 0.7537\n",
            "Epoch 108/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4754 - accuracy: 0.7786 - val_loss: 0.5033 - val_accuracy: 0.7620\n",
            "Epoch 109/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4912 - accuracy: 0.7650 - val_loss: 0.5174 - val_accuracy: 0.7537\n",
            "Epoch 110/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5226 - accuracy: 0.7496 - val_loss: 0.5175 - val_accuracy: 0.7432\n",
            "Epoch 111/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5195 - accuracy: 0.7287 - val_loss: 0.5037 - val_accuracy: 0.7557\n",
            "Epoch 112/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4900 - accuracy: 0.7713 - val_loss: 0.5023 - val_accuracy: 0.7641\n",
            "Epoch 113/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7767 - val_loss: 0.5091 - val_accuracy: 0.7516\n",
            "Epoch 114/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7480 - val_loss: 0.5124 - val_accuracy: 0.7516\n",
            "Epoch 115/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4697 - accuracy: 0.7879 - val_loss: 0.5035 - val_accuracy: 0.7599\n",
            "Epoch 116/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4772 - accuracy: 0.7576 - val_loss: 0.5047 - val_accuracy: 0.7599\n",
            "Epoch 117/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4915 - accuracy: 0.7726 - val_loss: 0.5135 - val_accuracy: 0.7578\n",
            "Epoch 118/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5158 - accuracy: 0.7527 - val_loss: 0.5085 - val_accuracy: 0.7537\n",
            "Epoch 119/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4849 - accuracy: 0.7709 - val_loss: 0.5067 - val_accuracy: 0.7599\n",
            "Epoch 120/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4922 - accuracy: 0.7637 - val_loss: 0.5047 - val_accuracy: 0.7599\n",
            "Epoch 121/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4928 - accuracy: 0.7593 - val_loss: 0.5043 - val_accuracy: 0.7620\n",
            "Epoch 122/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5014 - accuracy: 0.7662 - val_loss: 0.5079 - val_accuracy: 0.7537\n",
            "Epoch 123/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4918 - accuracy: 0.7625 - val_loss: 0.5049 - val_accuracy: 0.7620\n",
            "Epoch 124/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.7809 - val_loss: 0.5059 - val_accuracy: 0.7557\n",
            "Epoch 125/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5142 - accuracy: 0.7600 - val_loss: 0.5104 - val_accuracy: 0.7516\n",
            "Epoch 126/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4886 - accuracy: 0.7764 - val_loss: 0.5065 - val_accuracy: 0.7641\n",
            "Epoch 127/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.7871 - val_loss: 0.5084 - val_accuracy: 0.7557\n",
            "Epoch 128/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.7854 - val_loss: 0.5066 - val_accuracy: 0.7599\n",
            "Epoch 129/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5109 - accuracy: 0.7494 - val_loss: 0.5166 - val_accuracy: 0.7474\n",
            "Epoch 130/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4985 - accuracy: 0.7666 - val_loss: 0.5185 - val_accuracy: 0.7537\n",
            "Epoch 131/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4820 - accuracy: 0.7691 - val_loss: 0.5161 - val_accuracy: 0.7578\n",
            "Epoch 132/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4971 - accuracy: 0.7642 - val_loss: 0.5152 - val_accuracy: 0.7495\n",
            "Epoch 133/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4700 - accuracy: 0.7872 - val_loss: 0.5073 - val_accuracy: 0.7599\n",
            "Epoch 134/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4741 - accuracy: 0.7944 - val_loss: 0.5079 - val_accuracy: 0.7662\n",
            "Epoch 135/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.7922 - val_loss: 0.5107 - val_accuracy: 0.7557\n",
            "Epoch 136/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7899 - val_loss: 0.5078 - val_accuracy: 0.7599\n",
            "Epoch 137/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4888 - accuracy: 0.7639 - val_loss: 0.5257 - val_accuracy: 0.7453\n",
            "Epoch 138/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4820 - accuracy: 0.7845 - val_loss: 0.5081 - val_accuracy: 0.7578\n",
            "Epoch 139/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4733 - accuracy: 0.7768 - val_loss: 0.5124 - val_accuracy: 0.7578\n",
            "Epoch 140/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.7858 - val_loss: 0.5175 - val_accuracy: 0.7599\n",
            "Epoch 141/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4885 - accuracy: 0.7823 - val_loss: 0.5109 - val_accuracy: 0.7557\n",
            "Epoch 142/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4958 - accuracy: 0.7637 - val_loss: 0.5150 - val_accuracy: 0.7537\n",
            "Epoch 143/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5114 - accuracy: 0.7430 - val_loss: 0.5114 - val_accuracy: 0.7557\n",
            "Epoch 144/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.7765 - val_loss: 0.5079 - val_accuracy: 0.7599\n",
            "Epoch 145/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.7887 - val_loss: 0.5103 - val_accuracy: 0.7578\n",
            "Epoch 146/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.7755 - val_loss: 0.5167 - val_accuracy: 0.7516\n",
            "Epoch 147/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.7923 - val_loss: 0.5235 - val_accuracy: 0.7537\n",
            "Epoch 148/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4708 - accuracy: 0.7856 - val_loss: 0.5130 - val_accuracy: 0.7578\n",
            "Epoch 149/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4720 - accuracy: 0.7685 - val_loss: 0.5165 - val_accuracy: 0.7599\n",
            "Epoch 150/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4987 - accuracy: 0.7601 - val_loss: 0.5295 - val_accuracy: 0.7453\n",
            "Epoch 151/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4781 - accuracy: 0.7871 - val_loss: 0.5298 - val_accuracy: 0.7411\n",
            "Epoch 152/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7731 - val_loss: 0.5122 - val_accuracy: 0.7620\n",
            "Epoch 153/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.7706 - val_loss: 0.5139 - val_accuracy: 0.7474\n",
            "Epoch 154/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5022 - accuracy: 0.7638 - val_loss: 0.5142 - val_accuracy: 0.7516\n",
            "Epoch 155/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.7704 - val_loss: 0.5113 - val_accuracy: 0.7599\n",
            "Epoch 156/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5006 - accuracy: 0.7631 - val_loss: 0.5133 - val_accuracy: 0.7495\n",
            "Epoch 157/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4880 - accuracy: 0.7685 - val_loss: 0.5136 - val_accuracy: 0.7516\n",
            "Epoch 158/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.7888 - val_loss: 0.5148 - val_accuracy: 0.7537\n",
            "Epoch 159/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4871 - accuracy: 0.7666 - val_loss: 0.5120 - val_accuracy: 0.7641\n",
            "Epoch 160/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4699 - accuracy: 0.7867 - val_loss: 0.5140 - val_accuracy: 0.7474\n",
            "Epoch 161/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4911 - accuracy: 0.7519 - val_loss: 0.5138 - val_accuracy: 0.7474\n",
            "Epoch 162/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7619 - val_loss: 0.5119 - val_accuracy: 0.7578\n",
            "Epoch 163/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4715 - accuracy: 0.7793 - val_loss: 0.5129 - val_accuracy: 0.7557\n",
            "Epoch 164/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4835 - accuracy: 0.7825 - val_loss: 0.5220 - val_accuracy: 0.7557\n",
            "Epoch 165/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4993 - accuracy: 0.7532 - val_loss: 0.5143 - val_accuracy: 0.7516\n",
            "Epoch 166/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7723 - val_loss: 0.5220 - val_accuracy: 0.7474\n",
            "Epoch 167/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4724 - accuracy: 0.7755 - val_loss: 0.5163 - val_accuracy: 0.7578\n",
            "Epoch 168/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7625 - val_loss: 0.5227 - val_accuracy: 0.7557\n",
            "Epoch 169/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4896 - accuracy: 0.7771 - val_loss: 0.5270 - val_accuracy: 0.7557\n",
            "Epoch 170/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.7730 - val_loss: 0.5133 - val_accuracy: 0.7620\n",
            "Epoch 171/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4823 - accuracy: 0.7787 - val_loss: 0.5259 - val_accuracy: 0.7537\n",
            "Epoch 172/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.8006 - val_loss: 0.5139 - val_accuracy: 0.7557\n",
            "Epoch 173/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7924 - val_loss: 0.5168 - val_accuracy: 0.7474\n",
            "Epoch 174/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.7997 - val_loss: 0.5247 - val_accuracy: 0.7557\n",
            "Epoch 175/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4444 - accuracy: 0.7878 - val_loss: 0.5155 - val_accuracy: 0.7557\n",
            "Epoch 176/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4869 - accuracy: 0.7528 - val_loss: 0.5190 - val_accuracy: 0.7495\n",
            "Epoch 177/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4837 - accuracy: 0.7730 - val_loss: 0.5201 - val_accuracy: 0.7516\n",
            "Epoch 178/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4922 - accuracy: 0.7754 - val_loss: 0.5170 - val_accuracy: 0.7516\n",
            "Epoch 179/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.7825 - val_loss: 0.5235 - val_accuracy: 0.7537\n",
            "Epoch 180/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4814 - accuracy: 0.7831 - val_loss: 0.5191 - val_accuracy: 0.7495\n",
            "Epoch 181/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.7872 - val_loss: 0.5223 - val_accuracy: 0.7516\n",
            "Epoch 182/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4837 - accuracy: 0.7854 - val_loss: 0.5176 - val_accuracy: 0.7474\n",
            "Epoch 183/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.7739 - val_loss: 0.5170 - val_accuracy: 0.7516\n",
            "Epoch 184/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4888 - accuracy: 0.7630 - val_loss: 0.5164 - val_accuracy: 0.7641\n",
            "Epoch 185/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.7825 - val_loss: 0.5330 - val_accuracy: 0.7516\n",
            "Epoch 186/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4765 - accuracy: 0.7831 - val_loss: 0.5191 - val_accuracy: 0.7578\n",
            "Epoch 187/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.7714 - val_loss: 0.5186 - val_accuracy: 0.7453\n",
            "Epoch 188/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4893 - accuracy: 0.7667 - val_loss: 0.5168 - val_accuracy: 0.7432\n",
            "Epoch 189/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4743 - accuracy: 0.7742 - val_loss: 0.5409 - val_accuracy: 0.7453\n",
            "Epoch 190/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4871 - accuracy: 0.7719 - val_loss: 0.5300 - val_accuracy: 0.7453\n",
            "Epoch 191/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4771 - accuracy: 0.7649 - val_loss: 0.5179 - val_accuracy: 0.7620\n",
            "Epoch 192/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4748 - accuracy: 0.7796 - val_loss: 0.5230 - val_accuracy: 0.7516\n",
            "Epoch 193/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4715 - accuracy: 0.7708 - val_loss: 0.5181 - val_accuracy: 0.7599\n",
            "Epoch 194/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4804 - accuracy: 0.7700 - val_loss: 0.5228 - val_accuracy: 0.7495\n",
            "Epoch 195/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7595 - val_loss: 0.5274 - val_accuracy: 0.7578\n",
            "Epoch 196/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4723 - accuracy: 0.7789 - val_loss: 0.5243 - val_accuracy: 0.7390\n",
            "Epoch 197/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4795 - accuracy: 0.7807 - val_loss: 0.5234 - val_accuracy: 0.7537\n",
            "Epoch 198/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4860 - accuracy: 0.7622 - val_loss: 0.5205 - val_accuracy: 0.7599\n",
            "Epoch 199/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4558 - accuracy: 0.7931 - val_loss: 0.5190 - val_accuracy: 0.7557\n",
            "Epoch 200/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4885 - accuracy: 0.7748 - val_loss: 0.5221 - val_accuracy: 0.7390\n",
            "Epoch 201/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4808 - accuracy: 0.7811 - val_loss: 0.5213 - val_accuracy: 0.7537\n",
            "Epoch 202/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5006 - accuracy: 0.7704 - val_loss: 0.5235 - val_accuracy: 0.7328\n",
            "Epoch 203/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4774 - accuracy: 0.7827 - val_loss: 0.5234 - val_accuracy: 0.7432\n",
            "Epoch 204/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4900 - accuracy: 0.7524 - val_loss: 0.5209 - val_accuracy: 0.7599\n",
            "Epoch 205/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.7752 - val_loss: 0.5200 - val_accuracy: 0.7453\n",
            "Epoch 206/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4762 - accuracy: 0.7735 - val_loss: 0.5204 - val_accuracy: 0.7578\n",
            "Epoch 207/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4960 - accuracy: 0.7688 - val_loss: 0.5301 - val_accuracy: 0.7495\n",
            "Epoch 208/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4765 - accuracy: 0.7768 - val_loss: 0.5292 - val_accuracy: 0.7474\n",
            "Epoch 209/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.7917 - val_loss: 0.5209 - val_accuracy: 0.7557\n",
            "Epoch 210/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.8073 - val_loss: 0.5228 - val_accuracy: 0.7516\n",
            "Epoch 211/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.7826 - val_loss: 0.5234 - val_accuracy: 0.7578\n",
            "Epoch 212/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4830 - accuracy: 0.7776 - val_loss: 0.5254 - val_accuracy: 0.7516\n",
            "Epoch 213/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4835 - accuracy: 0.7712 - val_loss: 0.5461 - val_accuracy: 0.7370\n",
            "Epoch 214/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4699 - accuracy: 0.7725 - val_loss: 0.5226 - val_accuracy: 0.7620\n",
            "Epoch 215/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.7778 - val_loss: 0.5227 - val_accuracy: 0.7599\n",
            "Epoch 216/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4726 - accuracy: 0.7906 - val_loss: 0.5214 - val_accuracy: 0.7599\n",
            "Epoch 217/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4694 - accuracy: 0.7783 - val_loss: 0.5375 - val_accuracy: 0.7578\n",
            "Epoch 218/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4840 - accuracy: 0.7746 - val_loss: 0.5225 - val_accuracy: 0.7537\n",
            "Epoch 219/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4777 - accuracy: 0.7646 - val_loss: 0.5272 - val_accuracy: 0.7516\n",
            "Epoch 220/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.7535 - val_loss: 0.5237 - val_accuracy: 0.7557\n",
            "Epoch 221/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4692 - accuracy: 0.7820 - val_loss: 0.5236 - val_accuracy: 0.7557\n",
            "Epoch 222/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4706 - accuracy: 0.7687 - val_loss: 0.5216 - val_accuracy: 0.7495\n",
            "Epoch 223/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4905 - accuracy: 0.7590 - val_loss: 0.5312 - val_accuracy: 0.7578\n",
            "Epoch 224/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4694 - accuracy: 0.7816 - val_loss: 0.5240 - val_accuracy: 0.7453\n",
            "Epoch 225/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4801 - accuracy: 0.7642 - val_loss: 0.5252 - val_accuracy: 0.7495\n",
            "Epoch 226/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4985 - accuracy: 0.7617 - val_loss: 0.5238 - val_accuracy: 0.7537\n",
            "Epoch 227/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4711 - accuracy: 0.7857 - val_loss: 0.5239 - val_accuracy: 0.7474\n",
            "Epoch 228/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4950 - accuracy: 0.7731 - val_loss: 0.5360 - val_accuracy: 0.7599\n",
            "Epoch 229/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4894 - accuracy: 0.7681 - val_loss: 0.5358 - val_accuracy: 0.7474\n",
            "Epoch 230/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4965 - accuracy: 0.7711 - val_loss: 0.5377 - val_accuracy: 0.7620\n",
            "Epoch 231/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.7947 - val_loss: 0.5253 - val_accuracy: 0.7578\n",
            "Epoch 232/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4759 - accuracy: 0.7631 - val_loss: 0.5266 - val_accuracy: 0.7620\n",
            "Epoch 233/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4713 - accuracy: 0.7787 - val_loss: 0.5364 - val_accuracy: 0.7599\n",
            "Epoch 234/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4991 - accuracy: 0.7685 - val_loss: 0.5260 - val_accuracy: 0.7599\n",
            "Epoch 235/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7537 - val_loss: 0.5256 - val_accuracy: 0.7620\n",
            "Epoch 236/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4741 - accuracy: 0.7796 - val_loss: 0.5264 - val_accuracy: 0.7537\n",
            "Epoch 237/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.7759 - val_loss: 0.5244 - val_accuracy: 0.7620\n",
            "Epoch 238/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4760 - accuracy: 0.7779 - val_loss: 0.5282 - val_accuracy: 0.7516\n",
            "Epoch 239/300\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.4750 - accuracy: 0.7698 - val_loss: 0.5270 - val_accuracy: 0.7495\n",
            "Epoch 240/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4778 - accuracy: 0.7895 - val_loss: 0.5273 - val_accuracy: 0.7537\n",
            "Epoch 241/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4796 - accuracy: 0.7617 - val_loss: 0.5365 - val_accuracy: 0.7474\n",
            "Epoch 242/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4726 - accuracy: 0.7610 - val_loss: 0.5287 - val_accuracy: 0.7495\n",
            "Epoch 243/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4831 - accuracy: 0.7511 - val_loss: 0.5276 - val_accuracy: 0.7516\n",
            "Epoch 244/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4852 - accuracy: 0.7653 - val_loss: 0.5282 - val_accuracy: 0.7516\n",
            "Epoch 245/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4705 - accuracy: 0.7860 - val_loss: 0.5414 - val_accuracy: 0.7599\n",
            "Epoch 246/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.8053 - val_loss: 0.5275 - val_accuracy: 0.7620\n",
            "Epoch 247/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4705 - accuracy: 0.7952 - val_loss: 0.5254 - val_accuracy: 0.7578\n",
            "Epoch 248/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.7864 - val_loss: 0.5419 - val_accuracy: 0.7537\n",
            "Epoch 249/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4921 - accuracy: 0.7775 - val_loss: 0.5279 - val_accuracy: 0.7328\n",
            "Epoch 250/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4920 - accuracy: 0.7686 - val_loss: 0.5275 - val_accuracy: 0.7495\n",
            "Epoch 251/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4800 - accuracy: 0.7713 - val_loss: 0.5288 - val_accuracy: 0.7537\n",
            "Epoch 252/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4757 - accuracy: 0.7694 - val_loss: 0.5322 - val_accuracy: 0.7495\n",
            "Epoch 253/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4851 - accuracy: 0.7841 - val_loss: 0.5273 - val_accuracy: 0.7474\n",
            "Epoch 254/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4759 - accuracy: 0.7634 - val_loss: 0.5301 - val_accuracy: 0.7265\n",
            "Epoch 255/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4822 - accuracy: 0.7640 - val_loss: 0.5278 - val_accuracy: 0.7557\n",
            "Epoch 256/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.7897 - val_loss: 0.5305 - val_accuracy: 0.7474\n",
            "Epoch 257/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7894 - val_loss: 0.5304 - val_accuracy: 0.7599\n",
            "Epoch 258/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7635 - val_loss: 0.5369 - val_accuracy: 0.7495\n",
            "Epoch 259/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7853 - val_loss: 0.5469 - val_accuracy: 0.7411\n",
            "Epoch 260/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7587 - val_loss: 0.5285 - val_accuracy: 0.7474\n",
            "Epoch 261/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4813 - accuracy: 0.7797 - val_loss: 0.5360 - val_accuracy: 0.7516\n",
            "Epoch 262/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.7835 - val_loss: 0.5307 - val_accuracy: 0.7537\n",
            "Epoch 263/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4915 - accuracy: 0.7793 - val_loss: 0.5333 - val_accuracy: 0.7474\n",
            "Epoch 264/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.7835 - val_loss: 0.5295 - val_accuracy: 0.7495\n",
            "Epoch 265/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4693 - accuracy: 0.7747 - val_loss: 0.5351 - val_accuracy: 0.7495\n",
            "Epoch 266/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.7625 - val_loss: 0.5306 - val_accuracy: 0.7474\n",
            "Epoch 267/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7826 - val_loss: 0.5400 - val_accuracy: 0.7516\n",
            "Epoch 268/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4881 - accuracy: 0.7703 - val_loss: 0.5299 - val_accuracy: 0.7599\n",
            "Epoch 269/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4748 - accuracy: 0.7797 - val_loss: 0.5296 - val_accuracy: 0.7390\n",
            "Epoch 270/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4812 - accuracy: 0.7621 - val_loss: 0.5321 - val_accuracy: 0.7495\n",
            "Epoch 271/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.8031 - val_loss: 0.5298 - val_accuracy: 0.7370\n",
            "Epoch 272/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.7789 - val_loss: 0.5349 - val_accuracy: 0.7474\n",
            "Epoch 273/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.7950 - val_loss: 0.5296 - val_accuracy: 0.7432\n",
            "Epoch 274/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.7874 - val_loss: 0.5359 - val_accuracy: 0.7537\n",
            "Epoch 275/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.7827 - val_loss: 0.5686 - val_accuracy: 0.7203\n",
            "Epoch 276/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4798 - accuracy: 0.7800 - val_loss: 0.5305 - val_accuracy: 0.7516\n",
            "Epoch 277/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4908 - accuracy: 0.7610 - val_loss: 0.5287 - val_accuracy: 0.7390\n",
            "Epoch 278/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7745 - val_loss: 0.5308 - val_accuracy: 0.7328\n",
            "Epoch 279/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4858 - accuracy: 0.7636 - val_loss: 0.5365 - val_accuracy: 0.7495\n",
            "Epoch 280/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4820 - accuracy: 0.7666 - val_loss: 0.5360 - val_accuracy: 0.7537\n",
            "Epoch 281/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4961 - accuracy: 0.7663 - val_loss: 0.5430 - val_accuracy: 0.7641\n",
            "Epoch 282/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4753 - accuracy: 0.7741 - val_loss: 0.5310 - val_accuracy: 0.7453\n",
            "Epoch 283/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.7758 - val_loss: 0.5312 - val_accuracy: 0.7453\n",
            "Epoch 284/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4485 - accuracy: 0.7995 - val_loss: 0.5359 - val_accuracy: 0.7516\n",
            "Epoch 285/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4683 - accuracy: 0.7762 - val_loss: 0.5326 - val_accuracy: 0.7516\n",
            "Epoch 286/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4981 - accuracy: 0.7575 - val_loss: 0.5365 - val_accuracy: 0.7495\n",
            "Epoch 287/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4840 - accuracy: 0.7909 - val_loss: 0.5326 - val_accuracy: 0.7516\n",
            "Epoch 288/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4504 - accuracy: 0.8003 - val_loss: 0.5312 - val_accuracy: 0.7599\n",
            "Epoch 289/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7710 - val_loss: 0.5299 - val_accuracy: 0.7599\n",
            "Epoch 290/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5220 - accuracy: 0.7439 - val_loss: 0.5348 - val_accuracy: 0.7495\n",
            "Epoch 291/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4481 - accuracy: 0.7907 - val_loss: 0.5296 - val_accuracy: 0.7453\n",
            "Epoch 292/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.7893 - val_loss: 0.5303 - val_accuracy: 0.7599\n",
            "Epoch 293/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4885 - accuracy: 0.7733 - val_loss: 0.5324 - val_accuracy: 0.7537\n",
            "Epoch 294/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7862 - val_loss: 0.5475 - val_accuracy: 0.7495\n",
            "Epoch 295/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4730 - accuracy: 0.7853 - val_loss: 0.5387 - val_accuracy: 0.7557\n",
            "Epoch 296/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4915 - accuracy: 0.7629 - val_loss: 0.5354 - val_accuracy: 0.7474\n",
            "Epoch 297/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4704 - accuracy: 0.7875 - val_loss: 0.5334 - val_accuracy: 0.7474\n",
            "Epoch 298/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4561 - accuracy: 0.7854 - val_loss: 0.5339 - val_accuracy: 0.7495\n",
            "Epoch 299/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.7878 - val_loss: 0.5315 - val_accuracy: 0.7411\n",
            "Epoch 300/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.7757 - val_loss: 0.5299 - val_accuracy: 0.7370\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "2sxxZf6NPQ_G",
        "outputId": "2fec8469-37d1-4591-8b06-4283324ca381"
      },
      "source": [
        "plt.plot(history_2.history['accuracy'])\n",
        "plt.plot(history_2.history['val_accuracy'])\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training data', 'validation data'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydd5xdZZ3/38/tdXqflEkPKUBCEnoVNRFEBVTAsogKusKuuq7r6v6wu5a1rwVEQdQFFbFBKAFRekgCIb1OJmV6v70/vz+e0+6dO5MCk0Q5n9drXvfec55zznPPufP9PN8upJTYsGHDhg0bpXCc6AnYsGHDho2TEzZB2LBhw4aNsrAJwoYNGzZslIVNEDZs2LBhoyxsgrBhw4YNG2XhOtETeLVQV1cn29raTvQ0bNiwYePvChs2bBiQUtaX2/cPQxBtbW2sX7/+RE/Dhg0bNv6uIITYP94+28Rkw4YNGzbKwiYIGzZs2LBRFjZB2LBhw4aNsrAJwoYNGzZslIVNEDZs2LBhoyxsgrBhw4YNG2VhE4QNGzZs2CgLmyBs2CiH5DAkhk7c9Qf3gl2K/x8aqzd3MxBLTzwo2gPp6PGZUBnYBGHDRjn86Ra4/8YTc+3ul+H7S+H5H52Y69uYdMTTOf75Vy/ym/UHxx9UyMM358H/XXP8JlYCmyBs2CiHaC+MHjox1471qdcdD56Y69uYdMTTOQCGYpnxBx3SKkPsf/o4zKg8JpUghBArhRA7hRB7hBCfKrP/20KIjdrfLiHEiGXf14UQW4UQ24UQ3xNCiMmcqw0bRcgmITV6Yq6dz6rXWO+Jub6NSUcikwdgJJkdf9DO1eq1bt7EJ5tEU+SkEYQQwgn8AFgFLACuFUIssI6RUn5MSnm6lPJ04PvA/dqx5wDnAqcCi4DlwIWTNVcbNsYgdwIJIh1Rr/G+43/ttbfBHz8y8Zjda+Cuy5UJ5NVENgXfXgQ7Hxq771dvh62/P7bzPvpf8Nvr1fvnfnD471eKnQ/Bj85T8zu4Dr4xB746Tf19ZzHEB456SgZBJMoQxE/fqOa56xH1uaC0DR74GDzzXXPc419Qf79+N/z8iqOew5FgMjWIFcAeKWW7lDID3Au8ZYLx1wL3aO8l4AM8gBdwA/ZyysbxQzYJ2Tjkc8f/2joxpUaPv6N69xrY+fDEYw48Dx1PQbz/1b12tAtGD8Ifby7eLiXsfrQ8cRwJnv2+SS6718CW+6FQOPLj77kGejfDyH44tE4R96Kroe18GDkAQ+1HPaVkVieIEhOTlHDweXjk0zCwUxs8pLZvvg/2PmGO3fOYelaRTnC6j3oOR4LJJIhWwOqBOaRtGwMhxHRgBvAXACnlc8ATQLf294iUcnuZ424UQqwXQqzv73+Vf6w2XtvIJtSrvpo/nrBqLsfbzBTtVgJpIgGaiZljX01kU+o1UbIiz2nbB3a/svMnR1RUUDahyOhIkLNEGUV71HEuH1z2TTjnFrX9GKKMkuOZmPTfHYAsQM0sNe9Il/otJgbN/alR9QyiPRBuOuo5HAlOFif1NcB9Uso8gBBiNnAKMAVFKpcIIc4vPUhKebuUcpmUcll9fdly5jZe61h/J/TvOvrjskn1mhoxtx1Yq1afkw0rQRyJUNzw82P7juUQ7VaCKT2BeS2tEcSh9coUIqVyrD/1raNbmZdCJx5Q53zuByrc10oQh9Ootv0J9jxeft/gHpMYBsa5X/074YWfqPdD7cWRbNEeUxgLAZ6Q2j4eQeSzyrz14L+poIenvmUEICQySjMdSWTh6e8wcM+HiHZshFTJgmTaWYBUmguo0OudD9P50iPkk6OKzGO9EG6e4KYcOyaTIDqBqZbPU7Rt5XANpnkJ4G3A81LKmJQyBjwEnD0ps7Txj4tCAR74KPzoKH86hYIplKz/sE/9j/pnn2xYCWJ0gjBIUHP987/Ciz9/5dfNpc0V6kQ5ILpW9bevK1NIrBdevhce/zz0bTv261u1tZ5N6twb7jI1i0x0Yo0qn1PhyQ99svz+nk3mvR3YU37MX78Kqz+h7sXW38O2P6hVPFhW65ow9moEYSU2Kzo3KPPWujvg2e+p+3PfDYBpYsomI/DYZ6nbeQ9dD3xprN9rynL1enCtek0OwWOfZf/9n0MmtbGy8HepQawD5gghZgghPCgS+FPpICHEfKAaeM6y+QBwoRDCJYRwoxzUY0xMNmxMCP0ft3CUfgSdHKBkNb9L/YNOdgJdahTCLer94a6VjQOy2PRwrLAK34nOp99X3Yke7TZX5IOvwAyUtgja53+snW+PChjQMZFGdeA5pfEN7jE1KqtGs+8p8325eeYyyq4PKlEyHQWHC27ZAJ6wpkF0m8LYEx47byusWorur+nfAZhO6pqCer4p6Wb60LPF5rVwC1RN077b8+o1m0AO76dFDOIS5nf72tOTE1AxaQQhpcwBNwOPoIT7b6SUW4UQXxBCWF3u1wD3SlmkO94H7AU2Ay8DL0sp/zxZc7XxD4rxVnaliPYUC+KsRSDpBJFLK4ckqJWh/r4UufT4q9MjRToCla1KOFkF9cBuZbYY3GvaxnXhNBGRRLqVwDscoj3m+wk1iJL7Gu1RQhmUYO7dpkxBvUepTVif18v/p14HdpsaBExMQDsfAofmrNVDRDMW88++J7U3ojzR7H/a1GISg+p7ekLKnBRumkCD0K4hJXQ8oxzh+55U5irhVPtGNE0w3s+9Lxzg0LDyNTQK9Vx+mb8UXyFe7Iivmw2BWvW+60Vjs8glaRXFfpqUv2H8+/IKMKktR6WUq4HVJdtuLfn8uTLH5YGbJnNuNl4DsAqyTBw8wfLj7n0X1M2Ft2mZy1ZHoS4whtqVKg/KTODywsd3gLPkX+jX71YRN5/pBbfv2OadGoVAHfhrlMYCSmD/8GxY+d/Krr3yv2HZDaZQnWDFX7jnGqidg+PqOya+rtXprJ2vUJDkChKPy7KWLCXeSJcpcJ/7X/jrV2DRVbDld3DTk9B82pF867HE46+G4X3F15uIfPc/DdPPUfeq/Qk476PFJkJ9dd64UJ23FFbhnBiETAzpDZHO5vGFmxQJZmKmBuHyKkLS5733cfjlVeY5PCH1uxo9WGQq/NT9m6kJegBoQBHE/fnzud61Btd2i5GlZQnr+h0st55PuxduURxi7KwsG//zinGyOKlt2Hj1YXUeDk4gWEYOQMyyei6nQVhXnOmIMhnodmErdj+qXq3nO1qkRsFXoVaPuuAf2Q+FLHS+qExg+mpf/47J8Vf8sd59DOw5gn7tRRqEuu6Pn9zLqu8+WTyuVJD37zCFr06oW36nXiNHEemkr8Q/sg4++ARc+nllHuzfaY4Zz7kM6l4E66FpkWli0p/fzIvMcfXzxzqDpVQEUd2mPieGIB0lKv2s+PJj5IKN0LtF7dPNf6C0CJ3Atj8A7iC8f40i+ExMaQG+ShWKqqGCGENxFd7aJNRz2y8bGXTWmZrph5+Diz7NFx+3PJMFby37tfNSEKxpHP++vALYBGHjHxdW88J4tmsplXDNWLSGXDmC0AROpSXuYmeRcqxMPzqir4QgIkqoBGpMU49+Pn0eupA+nAZRyBMsRKlOHTp8Ylu0W62IHS6DcPb2xdnbHyebt9jyMyVRO7ptv3La2HMeBVHKVIy8cNEhWqF1KTRoebU9m9VrRevEJqZsEtx+qJ0N0S4eWL/LfH6nvtMcVzllrBbUsxlGD9I782r1WdMgInkvkVSOYWedOdbqEPaG1bMoFGDXw2RnXMJ/rvORmvl6tb92jnqW0rx/s4RJmo1ihJTDTxw/A1Qb23+8ucCzB2LsHrY8s9OvLfu1B6ikvjI0/n15BbAJwsbJhb7t8IOzXh1HsHWlq2sQ975LRcYYYyJqlZqNm9uKNAhtpdm/U9meW04Hlx+mnwe7ShLKdO0BxuYIHFoPPzxn4pj54f3wvSVqNT6GILTz6QIyHYGfrYJNv9HmOVqc1Hf3W+FLTfCXL+KkgJus0kJK8fCn1bjff5jMcBf5UJOpufztG9zQ/jF1WWvNoHQMhCY6wi3Qr8WPzH+Tep39enNs+1/hazPUNb4+0zARbe+OUChIdvREyGnkE4+NECn4eGy75iyvm61e9ZV702K1wr7j9ep8X2qC535oXiubAHcA6uYA8MATFp9C/XxznDcE+YwKo/1iPfm7rmBk0wOA4N7MuepUMeWDiEhlJuyhxjzeGlLqCSuy6X4Jot0851rBPS8c5Hn3mdp3mEvCUWza/JXnK1zieBGnQ9AohhkU6tw9UhGEdHj46mMdXP+zdSSzJrHI2jmUIu2ppldW01RxjObMw8AmCBsnF3o2K4FTTpgdLayrxFivWuXtfAg6LMXP9JW3VYOw+iBSo+q49idUTPqFn4K33wkzLlAag/U4q+O6VIPY/yz0bZ3Y1LX1fjMr11epfBD6/PTz6SviaDcceNaMugHTET24V803l6SwzWLTLtWichl46RdKY9r3JPs79rAzHtQIYgie+BILUxtwUDDLUufSytS17P3wtttM/0KwAS78D5VAdtUdsOrrav47VittZNGV6rscXMvu3iirvvsUy778GCu/8xQPbFLkl09FieMjmtKIzleltBndPNO0WK3ED70As1+nfEoHLMGP2RS4/RRqFLH4RveSiQ+b9/ODT8C77zejj/Y8roii4ykef/oZqGihPVtNTPpIR/ohE2Mk5wVgrf9Cds69ia/krmM/Vg0ipEh/50MgHNzWo679h/giWPV1fh1fwnOd2vfxVnBP9YdI4OVq55M0hr00iGG6C1UAdOXVa9IZBITh9/mvwGd5U/orDMuxWsKfp32SL2bfQ6NNEDZeE9CFszVy5Vihr9b91Uo4JQZA5ou1k4QmQDLlNAihBHLnBuVzmHeZsm/PW6WtbiUMWcxKiSFlZnF6xmoQuoCfyCa/w2Ky8mo+CL3MQun5RjWhWcaxbJi+GhYirGUgSglCj9ppXASxHoLpXg7mKpH+ajMxC6glYhKErpXVzobTrjGjbOatVBrP8g+AvwrOvElFYuXTSuN683eV+WpwN12j6tnqdvg9feqchVSUmPQT0yqdGsloeq2jxkXm3C/7lnIA66RYyKtruQN0OZspSMEMuhjoV6G4v9w4zJde8ili0aOPIippzkmBhWI/hVATA7E0wzJMLtoP6RgDWeVM3hb1sabpg9yeu5zn95m/n6j0sedQD+mtD5BsXsEzXcqhv3Z/hKFF7+O/VrcTIaAG+6r4SXYVD+eXc6HjZWp9kmbHCIdylQB05tXrUN4PQErLlYhNu5htso3eeJ6UM0xOmmJ7dWox6+R8Giu8TAZsgrBxfNC/C9befvhxOjFY/QClyOfgia+MNUNJqYqZDWvah65BVE1TY3VharXX6++tWoNOEME6JUB3PqhWsnMuNcfo6v7m35qZt4lBCNZqIZElGoR+7Wg3xAdVkbWcxWwT6y8SyiqSqVaZv9KRseeLlMk5fexzcP9N6j43LoapyxFYosdfvFuR0Ob71Lg1tyrhfeo7oZCjMddFV76KnK+mKCfiUucG2p76N3XM459XGw0hq83DalbSUAiplbasnaVqBdXMgIHdDMczeMlwV9Nv+br7J8T62uGJr+AZ2UscH7GUxVTmDZvPsWmxulV1p9OVr9BMcPrz056Z28f+0QKHZB1vcTxDcMsvALhzwxA/e2Yfz+0dZK/un7bcwzniENlAAwPRDMOEKCSGkJkogxpB7B9MMKCZ2V7Yp0gpns6xoTtLS6YD7+B2NoeUeerdZ06nezTFb9cfJJuXRKQiCOmr4MBQgscKZxAUac5kCw0M0yM1E1NBmZiGcoogcgX17E5prlD7IykiIswhp4pYSks3W3rTOATUhiaHICY1zNWGDQMv3wNPfwvOuB5cnvHH6YI6N0Gnrd4t8LevKcG/5N3m9sSQEnqFHJz/b6atvGIKDHeYq3drxI/+PhNXBCOEKWyqpishcghoPl1pIjpqNfv4M99V11j6XiWs/DUTaxDRHnjxLnjqmzDrEmg7T23vXA9IeMfdqqLqwreZ5pPE4NjzlasRteshFT3jDakVvEUAPpo/g9dHdiEe+bQSuLmMttK/UQlu1Eq6T1Yz1LKcxt5N4HDCUDsfd/2Wms4EDFaY90svM3HxZ9S4OWMJYm8qzBzgoKOVaaBIdXAPg/EMFzs2ctHI78EJ2/b3wt5tBIGYPNXUIICCJ2iuYgO15Be/k1tfbqTw8A6+E6gxSdUgiAD7BuKsL5zH+5yPUBHtRTp97B1SNY+u/cnzXOA4wN0edQ9z4VZc0U6cQhL1NRgaxNTEEKRjxPER8DjpGIjTVKnMOOs61D1Ys62XTNpNwKV+q9/c3URD2Ms1K6bys2f2cduT7QQ8TryBakhBxhUiV5Bs9iwE4NTCNrxkGJBKc+jVnNSj0l90H+drBNE1kmRv/myq65uZ3vcDIvjpi6ZprPDidExONwRbg7BxfKCbcA5X/E7/R89OoEEYdvkSoalH1+iO5UxM2Zv1laahQVhNTNq5ZF7Zo63XblqstJG+bcVOTgBPwIxokgXlO0gOqVV/uLmMBtFlzlmPt7eafPT3My6A961WQls33ySGjzwq6voH4F9fhqXvKYq2+Vj2n0lc8F8q/j/eD5d/Cz66CV7/hSKna6+sYm/rW+Gjm8i+R/kv6kWEQ8HFcMX3zet4NTv+1OXw7t+p6KESRN2qPtqOrDaPujkwuJeRWII3Ojcg/dUcDCxgQc5MqIvhI5rOEU/nmPOZ1fSmLYsJt5+Ny77K/ZmzWLtviDtfipKPDypi1xcWbj8dA3F+yDu5LfRhAEReaaWVfpVEF7MI4NHgTMt86xhKZBgijDfRjZB54tLPmTNqGIxn2NevfsMHhhL0RlJs74mQFOpcBQQbk/Usn1HDnIYQcxtDDMUzLJ1WjTugfAtZtxL0ddU1JKSXKXlF4MNS3cs+qcZFCNBWGzDmNb9J7f/dhkN8KXkVoQtvAX8VUZTze7L8D2AThI3jBT1K6HA9FgwNIqX+8bs3qc/dm7TPLxeHfna/bIZv6vZx/RrpmFpNB7SEM50gMjGloQzvL3Ya6ySmz6H5VM1nMWhG1FhRa9k2sFvNK1CjBO5op+oId2i95kPQBHz3y2ansIHd0PWS9n6Xlhxn0VL8WuRMrEcJ9fEKsvmqzPdWItPGZ6STOD6Gp1yitjtcMPtSnt0zwBM7+4qIpJdqHt3Wy59f7iLiqKYg1cq00zXFiA4CwBumayTJXc/sQ45TQC/mUaGhm1OKKLLVs6CQJd23l4udLyHmvJHulmLNIy79xFJZ1mzrJZuX7B5W5y4gwOlhrWb/7x5N0ZXx45Q5Ffmm+RN2D+XpGEzQVhtkuMVsIeN3O/nVB87ki29dRBxToHY6W4zv2JWvQkoYkSECGeX3iOHj3Nnqe+zoiTClWhHCC/uG2NEdxRtUq/+Ip4k0Hla01SCE4K1LlBloeVsNnpB6jmmn0rqmVPsZJkRzTnUsHEIRQK8WxRSRQdrqlPB3CKgLeakJenjxwAiVfjcXzatHBGoN09XZs2rL3v9XAzZB2Dg+0KN9DksQFg3i4Atw2/kqLPW281XRs9sugC33qTEH18JtF8KGO7VraAShaymZqDKFBGqVdmAlg8QQfPdUWP8zyxx1gtA1iFPNfWVCDGldqqJ3QAmpdERdq3aWIsR7r4M7LlVF4vT6Tj2bAAneSlVg7/aLoHMDuf5dxQIYlA8EoGsjANLqpLUipM1hzhtBCOLpHJmcWcBtmDAgGHE3wtQzYdbrwF/FdXes5X13roOQmWTVK6u569kObrnnJUYzMIha9bYXmhnxWbJ1PSF+t+EQn/vzNnoj5c2BB1zTyUvBYyPNZHIFNqXVfKbu/gVVxGD+m8jOuZysdJL1q+8ax0csneMPG9XqOq6t0NPSTX8sw7p9QwQ8Tsv3QhVjvHMlAL/fOkTHYJzptQEaGptJSC+DooZTp1SyqLWSd585DU+gwphjVybAAErI70mq8+kmH4C0I8BZM5UALkg4f049QY+TdR1D7OiJEKpQ5Oyrm87i1kouXaDu5dVLp3DalEpWLW4iWFlsOppS7WdYhqnPKoIYkSEqfC5i+Il6GjkoG2irVQRRFfDgdAhef0oj9WEvHzhvBl6XE2pnc0Cq5/62JZOTRQ02Qdg4XsgeIUHogjSXNguc7dds8Xv/ol71FXjPZkDCdq1M17gahLbCstYGKu05YJ1jNqFq/lsFdqnwBhXyevMLaqWuZ1UHalQJjA8/C+/6nZqfTkI+TfBUTYPZlxiE1r5lLSMHt9Plnlp8/sqp4HCT26FMUnu8p4ydAygS/I8OuOZXACz87CNcf+cLhgYxpJkwIsmsMge9/c6iw5N5B/mAEtB90tRghhMZY1X72EAlS77yN/Mgb4jeqHpWnSMWB78FW52nsDz9I7bnmtnRE2FzYQbDMsR1jjVkccOsS2iZtZBz0t/nuYZrAHBQoD+a5qnd2gq+oFb7KTzs6Imw8eAIly1upiboMb6XFftHCxwYTDCjLkhbbZAz0j/ivOT/GI5eIQTzp5uaWHfay6hT/T62RtWKfL80CbOxrpZZ9WZ4aVOFj6XTq3l0ay+9kTTVVer++Gpa+fMt59FapUigocLHH28+j7mNYcKVtca1AKZUBxiWIVxS60tNmNbqACD41pw7uT1/GTM0DUIvyfG1q09l3Wcu5ZbXab/Dq3/GZwqqGtH8JpPwXm3YBGHj+CBztCampLmS15PDdHNMqXDveFqd1/BB6AShaRC6qaZ/u+lctWY9l84xp+Lp8VWq1bVwQvWMseNdHmUSqp1Nfr9WbdNfo5y2jQthzqWkq+eaiXktS9TrvDcVaSS5A+uoExFeitcVn9/pgpqZuPpUJvEuzblZcJbYnL0hNQ+nm4IW+fLs3kEI1FHAyYhOEKmc8h2U1KT62sM76ClUk5QeMyQT2DeQMAiiXbYUt2LwhAzNoXOkOCS5ayTJx3+zkZ7RFEOYDtZ9Q2n+Ujgdp5DsCiwBb5i22gBnn7aA+/YqUdQgRhhOZMkXJEGPkxhayCceNneOMpzIMrUmwH0fOpuGxrEmt+6Eg0y+QFudMtMk8ZHExynNJpnccImpGXal3EahuxeH1X0d8k839k9vbsTvcdKsOajrwh6Wt9XQE1HfucWvNfyZoB9DdY06/8GEEvZTa/ym9gMMyxCtVer8e6NucrgME1NNYJyADk+QRz+5kuf/83XjXvfVgE0QNo4PJnJSH3gevr9MrfgNE1PKJAu9QFvZDmZCRS3tXmPRICxOam/Y1CDALN/Qu3XsqX7/IRUqqmfkgoq1r26bOPKqbi7OnPp+eZ2MNGwJnWN+aF2mXuetUufV5j+1X63Md+eVCeblgyOGXX802AZARAY46FLvU8ESk4LHFDZRS4jo3sEEw85aBjVhFE2Z3cusfoO7nu1gezxEt6wBzGiY9v4YPbKGvMNDKqCumQ1p1/aG6dOEZOdwcUDBQ1t6uP/FTp5rH2SmJuh6I2k6BhOsyat7sKda9f8SQvC5KxayL6+EaMLiH1g6vdrwF2SEh82HFPFXBz3MrA/hqxxbwTSFek7Ta0sdveYq+5QpdeSEclgfjHvIBZtJ4mHHqDJdeRtM8p41tdk4Hyh/wBWntXDB3HreuLCR1hrt3hvPcyyqa9U8OzSCmFIdMLQfKZxECdCiaR7dI0ltjB+nQ1AdHL+VaHOl34ismizYYa42jg8mMjHtfUJpCdHuYie1ThYTdTebukJpAzsfginLiq+hl2sOWIT23DeqTFydIC76NIQbVdOdgZ3QHoCamWZUzhu+VJxEVw7Tz4H1P1WXdlViXZ8/Er6Sp3IR3nH+abScewNUT4e2C1RS1+Xfht2P4d/5IHkpeC4zm1U9Ud7yg2e4+4YVtFb7eXSvhw+7oF0201eogKt+yrYd7Szb+mXzIl7TBDJk6XF82feeYkn+g8hAHWQ1DUKD3rBGxzdz76BSxKkNehjUEtj29sd4IH85l11xPf9buZx33PYcL77+15zpbgen29AgukaKCWJnjyLoVLbAjLqgEfXTMRjnUOEMPpO9gYYpZnv6mqCH7uB8Ppb4MI8Xlhjbl0yrJt6unkPe4WVXr9IQ9VW19Fkc+vr3QplxZtQFqQp4qAq4GU1mmdtYbI7Ku4O4MiMMFwLsn/9+fhtZAClBwOOksa5GNToG5k1rNs73fPsQdSEvbXVB7r5hhRqQWwyhaljynjFz0RFumcu/ZT7E49nTAWirC/KkUyMsfzXVDh9zGsN4XQ46tXtZ4XMzpyFUZN46EbA1CBvHBxM5qXUTUsaiQeRSEyfL6XX26+aqLN7da8ysWv0amWixDwLg9OvUa59GEKe9UzludUR7zKJvoGovtZ078XebbSbQxV1VPL17gPf8dC35gmRnzM93clezOnAFV9+5hfjC68DhUOdfdgPUzwNgvZzHpiEnB4bUfeqJpNjSOUq7VAJqr2wmls7C4qs5WFCmqJhHRQdlnOZKeShuOoxT2QLPFRbS41XmMasGMZwo7oW8XU7n+cICfvuhs3ngFpWbsbc/zgHZiG/hZUam7oFsFSx4C/mCpD+mm5iKn9OOHrPeVE3QQ0PYS+dIkkPDSTxuD7/KX0o4XGw3n14b5PeF84lgCsSl06qIaRpEwemlYzBhnBPA4a8iL4vj/5PSg8/toDGsjmurVb4Iv+bY1iG0MN0ofipb5rK9Qml6p0+tMhLUAAKhKuM8APWlCWkur8rtcYwvSj1uJ496LmEkr3IqQl4XN7xBLWZEoJYnP3kx162YRkOF12gkFPa5uP+fz+Fjrx9fMzkesAnitQAp4a9fG7/JzfGAEeZaxsSkVyjNJMxM6mxy4lwI3WlcN1fZ9NOjZrG8XFIlgqU1E5PPjEqhokWVsRjuUJ9DTaY5CSDWSywyTLwwVrXf2x/jBUuZBQN+M8w05gjzXPsAT+0eYCCWNlbXa7b1sn7/MLv7SqqIaqaJNfkzSGbzbNivSC6SzLKjJ8regiotvbfQYiSQdSaU4p+pULby0bwptIbipuD3u5VQ7BhMEPA4eWx7L1s6FXmOaJrGP509nX95nWlSqQ15maaZU9r7Y3hdDnxupxFr3xdVpDAYS5PXBKnVxJQvSG4df0MAACAASURBVHZaCKIq4KahwseG/cPkC5JztJBMXcjr0AWwPueAx8m8pjBxrViedPmM6+nHBn2eIls+QCAQYnpNEIeWOPbJlfO49c0LKIXLr/llCNJa7ccp1PjlbTV85GJL+LKmnV25dAr/ddkpTK0Zm+9xJNDnHPKqZ+erqNcmXEvI61KF+zRSczkEXpeDgMeF23liRbRNEK8F9G1XTVx+98ETN4fxNIhCwXQYZxMlJqby0TEATD8X5rwB5q5U78F0YoPKIi5ktYJvTpXp/I671b4aLTnKX62a+lidtrJAumsLz3ZjOHx1fGvNLj7x25fLTucrVZ/j/vx5xPNuo8ZQfzRtrK47BhVBlppjmHkhW7xL+FNerWDX7lOJe5Fklh3dEbbKNh7PL+HxwlKiqRz5guRAQglRZ1Urv8ufz57wCuN0w9q122oD3HThTGbUBfnIxbNIZPJs6YzwTz97AYBRTYNYtbiZD5xvOuDDXhdhrwuPy0FBQoOmOfjcTir9bno1v4NuXmqp9BV9p509UdI5swJpVcBDY4WXQxqJXHXGFJoqfCxsKdYgdH9BdUARc2OFj4awj6oqZR4ULtPWrtvlA14n9+UvYGNhlrFv+dxWzp9jOvvPmVXHxfPG+iocmgYRkcr+3z6gns+KGTUqgui9f1TZ7Jp/pz7s5QPnz0SIY8tYNgjCp1n1dbOnxfypk3DI5zrm67zasH0QrwXojmF5mH4Ak4VC3jQXlRJEtMskgky82MRUToOoblOr/8opKhsYlIbkDhaX7NabzFRozV2sWcBzV0L3RrM9pVWDAGpFlHbZTOX+YVbMMP+B+yIphi02fiv+Js/g9uxc7s3kDILY2x8zTAZGxI9ltb350CjX3L4Jh/hPZkwJ0ndolK1d6lmNahpEGg/vz/47ACKa5tTPPUJNNg1eCFbU8oncO7lZzuZs7Zy6/2D1v55PwOPio5cqDeUHTygSjmpaiG5iqgq4qfCZ2pK+8q4PKbPQGdNMO39jhddCEOr1jLYa/vxyF7t6o+wbiHPTLzYAysl6aDhJVcBtCD6f28GlpzTypsVjI350rSWTV6TcEFblI269agX8AoTHXLlXaz6IoMfFZ3PX8VbH03zHo8p+f+2dK1S5lMPBG6aAwB2oJOR1MaXaz1A8w5JpmjY486LiJkOvELrfJOzVCUIze5YjCO/JI5ZPnpnYmDzo0T2eE+TwKtfCM5tSpiVr4bxMvLiaq5Ugwi2KTFqWKIKw+hWEQIabENbKqgMaQVibu+iYtwr+9lWIq0qf5cpEtMsW9m/sZMWMGp7dM8BgPMNgLGOs4ktr3+jmn0Qmx7Bm5nn54Fh/i9Ve/9j2XuIagcxuCLGjJ6oS3FDlHLpHU3hdDmNF3t4fJ5Mv4NVCP12BKpa31fDg5m78Hie7e2McGk7gdTkMU42OP37kXO54eh9/frmLZCbPSFIRSZW/fHSW/n2WzygWYL2RNLt6o9z2pLrXN54/k2f2DPDRezdSE1Tawn+snM+mQ6Pc9WwHVX6PIfjmN1UUty61oDaoNJV0Lm9cCzBKejg9ikAqfKbZRU+YM0Jz3YEjIwdQ/wueELe/S2lfd7x3mWaKmxyROEaD0KPd/Nb7q+7ByUQQtonptYDUiHodryfzZMPaM0HXIDbcpbKIDzxv7ssmLIlyxSamRPOZqijegreoUhEliWvZgEpuKug/aV2DKBefrvcwmH+5ei0jVNoLzfx1hyKQ6+5Yyy33vGQ4ZQdiacOUo0N3AMfTeQY1R/GmQyNjzmslCKs/oy7kNZKsADZ3KiJd3mYKkIzWWCcmAmQ9VVA7i7ctaaW9P87XH97JHzd2sq5jmJqgZ4yJ4rSpVVx6ijK1HBhKMGLRIAD+3+UL+NCFpqlmNKn2r7BcvyHsozeS4g8vdbJ+/zDnza5jQUsF37j6VLZ1R3h6zwBXLp3ClUunGCUpqgJugpogn15brKlZsaytmnNm1fKNq1WOghG+qS1q3F51PqvvIqgJUr3kRDmiHxc1M3DUzuKM6UpDaqjwFWmLrzZKfRAE65X50xIeq5Ni2HfyEMTJMxMbkwc9uueEaRCa6Uc4TYLo3aJMXjseBKdXhX2moyUEYSZgfXVrBa0XPM5NC5fCzIuLHMMAGX8DHiDmrqUi26/6JEN5DUII+M9OFYFSAolAIKmatoB1+1McGjZJSs8xuPWPW9jbH+exj6taP1JKY8UdT+cM882WLvVdwz6XcaxuYsrkCrx0cNg4d3XAQ0uVj32aLVzvv7B0WhVP7ylODPzDLRfjrt0C7iBvSuX5/J+3ctbMWqr8bv6wscswwZRCz87dNxBnJJHB51YOaID3n1ecCHjG9Go27B8uCrNsrPDSF03TPZqiucLHLz+gor9ed0oj7zlrOr9cu98o+zC7QR3XUuUnqWlJr18wft9kn9vJ/33wLGLpHB6Xw3Ba605ij0+RQDmCiFo1iCPFxZ+BCz555ONfIaoNgtDNmj74mHqGOhpOQg3i5JmJjcmDbsbxHMU/0NGgUFBCdzz1XtcgQo1mFJNeF6l3syql3b2x2NyULdYghmWYu5/o5k3LE0ytKSYHgJSvgRAw7GrQCGKXIkTv2HIMQFHuQNFUfXUkkwkuPP0U1uzfapR2tmLjwRH6o2nD1JTM5tH92dFUzvBTpLIF6kIemiv9bNaih7Z1R/jAz9fzvnPbSFnaSdYGPUUahI4l2gq3KuA2Vv11YQ941WqzMuDgwX85n5ZKP3/Y2MkfNnYZq/9STNeEbsdgnJFEdlzzEsBd71tONJUzfBKghH2+INncOUpDSQXRz755Ae8+a7qRb3Dh3Hoe+/gFWsmLAGs+dgFzGsd5FhaEvC4e/egFtGoaiL6o8fmLS08AhmYSkZqQdR1F0pjTrf6OE/R5F2kHJb9N00l9/OZ1ONgmptcCdMFbyKtmO5+rhOd/rLZ9a6FqvqPjF1eqXr1HijW3wheq4dfvHrvv+R+rvsmaoE/4GlU4aj5XXOq6bq5a/VkJQi+1oTmS9YJqL2tmm2f3Dhi9jAHiXmU+6RVaBEsmOkZ72No1ylA8w46eCP3R8gXmYt4G9soWLpzXQNjnMprDWNEbSVOQKmJnS+doUYObrtFkUUmK+U0VRplpHY9t7+W+DapQ2zKNAApSGtm0OhwCzplVyw3nzuCtp6uVuRBjyy/Mqg/h9zgNc1RpXoKOSr+bmqCH/YNxRpJZw7xUDmGfe8x8dKG9py82poOZy+lgXpMp8IQQzG4IG++PhBx0tNUFzfBObxiEE59WNdWqHen+gqg4BhPTcYbhpJ7AfHQympgmlSCEECuFEDuFEHuEEJ8qs//bQoiN2t8uIcSIZd80IcSjQojtQohtQoi2yZzrPzT08tj5jFnx9OH/UNE/kUOq+Q4oTWDfk6p/8pGi80X12l0m/PPFn6t2nVom8ureSnOstZ5S3RxFEHHLNt1JPesSvhv+OMN1KrFoIJpm06ERrvvJWh7eavZI0EtL98hq065b4n+47HtPs/I7T/Kun6zlqw/tKJ7r+x+DDz/Lo23/zq3Z99FU6eO0KVVs7Ro/i/utP3yGy7//tNFCEzDCOXXMbwobBGENv/zbrn48Tgc3X6Ji7he2VBoahG5iqA978bqc3PrmBYbwrQl4cI0TGz+rXq2kr10xtex+UGamvX1x+iIpakMTlA8pA6uGM5k9CIrgcMK19+A+8/1Mrw0UkVDQqzQI4Qkp/9TRmJiOM2pCJT6IMgh5XUyvDRjlSU4GTBpVCSGcwA+A16N6cq0TQvxJSmmU1JRSfswy/hZgieUUdwNfllKuEUKEgAI2jg36yjyXLo4osnZti3SpTmiF7Dg1j8Y7t96RrSQBbGifarQDRm/ol/NtXO1AdT4DlbCWjqi+Cp4gI4PdVAHSW4nQnNTSE+LHI2fy9mUN7Orfz0Asw/Pt6vvsHzS/y6hLCd/hnEdFKQ3sMpzy//SzFwzbuJ7otbVrlBvvXs/TewZ4/3kz+Lc3LAdgkyzQGwzhdjqoD3uN/IVy0COOfrv+oLHtoJYJ3Vrlp3MkqZK9MkrDuHJpKz9+9xks+cIahuIZZtUHuWheAzu/tBKvy0k0rUxDs+qDvHxotEgI64KlboLWkkIIdn5pJe4JsnrnNYV54OUucgXJO5ePTyTlcEIIAlR5FOCxjzcYCW1gahAhnxtExUmtQdRpUVrhw5iP1nzsQlyT1B3uWDCZGsQKYI+Usl1KmQHuBd4ywfhrgXsAhBALAJeUcg2AlDImpZwga+o1jkwcHvrU+JVSNYLoGhxleMQSWWMtZbFztdF0xWhu8+LdsOfxia+tk086Bu1/Nfsz613TwNAWthQ0R+iO1QAcrNUS3OrmkHP5iQ2p62Y8VVqpjRSxgptkNs/Clgpqgl4GYmkj+ufQcBIpJb9Zd5ADGZV4NZD18KRQwp6Rg+QLkr/t6uex7WaPZVBmkjXbe0ll8/z82Q4jvLI3kqJBy2it9LsNQpkIv1prZqjrGoS+0j2luYIKTYOoDngIel1GNq7uiPW61Ep4RVsNn3vzAt58msrd0OcBZnhkXXjiVb/X5SzyG5TilKYwkVSORCZvdCo7UgS9LsMsdVwJQoPb6Sj6bjpphn0ulS1/EmsQU2v8/PeVi7msTA6IFR6XY8Lnd7wxmQTRChy0fD6kbRsDIcR0YAagFfxnLjAihLhfCPGSEOIbmkZSetyNQoj1Qoj1/f39r/L0/46w7ylY+yNlHioHLYppZ+cAf93SYW63RAnRt6O4b3KhoHwTa28b/7pSmj2KC1m4+y2w+hOQHFGEo0MnKFlL1lsNfVtJu0J8ZN85pOZeAXXzGM15qEFpGmlPFWSTyGyCaF4JgbbaIHUhD/3RNOs61PfpGkmytz/OJ3+3iZ9tzfPH/Dn8Jb2A6x+DHfWryK38mrF612sc6cgVJFLCBy+YSSSV44kd/cY43fZeFXAbWgIogXS41Z0ezfSGBY0sbq1kTmPISETTY/31aKK2ElOCy+ng+nNnUB9W46x2/vARaBBHAr2/MRxbH4GWSv+YuZ0o+NwOhNCIYsl7YMEVJ3pK40IIwbUrplE5gd/nZMTJ4qS+BrhPSiPV1wWcD3wCWA7MBK4vPUhKebuUcpmUcll9ff3xmuvJB72WUaJMnSAwBLSHHPmUxRRk1SDSEdO0JPMQ61V/E5mbMjHl16gsMVVs/q3yY4S1LOa4un4SL9FQGwA7w+ewSc5i67nfBZeHBF4CQq3WU64KkHlyiQg9CfUTDflc1Ie9rOsYYjSZxeUQdI4k6dDCQg+MpPnX7M1slW0UcPCLls9w3r0ZfvrUPqDYHOV2KiHvcghuvng2dSEPD23pJpXNs28gbqysS8NFmyt9hjag4+1nTDHe11ls+m9dohrIeF1OQ+DrYYx6NFEpQejQr1FkYvK9OgShazZCMKbC6ZFAd1SfCA2iFEIIgh6XMjFd+O9w2jUnekr/cJhMgugErJJjiratHK5BMy9pOARs1MxTOeAPwNJJmeXfA7Ip2HK/qlhaDno1VGsUkHFs0vA7eEUWaS1dHbWYXVKjpgYBqlubLKhtg3tN85MV+vWqVNG4lEdF5OTWfF6RzMK3aeOUiSmBlyFfGwAveFQMvd5sJiFNwZdwKMHlFnm6E0qYBz0u6kJeo2T1ihk1dI0kDR+BNWQUVIRRTyRlJKtZQz/PnlWHx+lgUWslYZ+bRa2V7O6NsacvRr4gma81l7FG+XzhLQv54buWGg5nr5YRfOVSkyB0odla5TfyCwCuOK2Fe288y9ivE8OM2vIEoV+j6Sh9EEeCCp+b1io/M8pUOD0S6H6IxvCJJwhQ2dThkyhv4B8Nk0kQ64A5QogZQggPigT+VDpICDEfqAaeKzm2SgihqwWXANtKj33NYMNdcN/74FdXK1NQKfSGOskyGoQlMshDFmnNah7eZ75PRYq1Bb3wXbxf9VZe/e9jz61rLFXTAPBllOnHlY3SSb1ZJjveTwYXOVwc8C8AXyV/zauMWT1xLFIwV9+jTrP+T7RgFmbTV+hup+CCufUkMnleOjg2Wxlge7fKt+i2RBgBnDe7jutWTOWG82bwvnPbAGW+6hiMG2WqddOLNTx1TkOYOY1hY3WvaxkLW00zTYOmKVi7l4FKAtP7GgNcNLeeS09p5LSplZTDvMYwb1jQyDmzzWOaKnxccVoLF8175Zry9ee08Z6zpx9+YBmsWtTEO5ZNocJ/cgjla5ZPZeWiMsmQNl4VTNpTllLmhBA3A48ATuBnUsqtQogvAOullDpZXAPcKy0trqSUeSHEJ4DHhaoZsAH4yWTN9aTHzgdVGJ8sqLaZDfOL9xsaRBmCiCktoeDw4CnkENaCdkMaQXhCpgbhr1Y+iy4tfBWpspKdZZyj2vVk1TSzD9np7+bWoTfyxz0ZNrqDanusn4RWP+ip8Cou+fhH2PettUDWqAQayanzZ6WTQ85WTtO/WlqtckNel7F6nlUfMqp/PluSZaxDr3FUShDfePupNFf6WbnIdBa21QZIZPI8vbsfr8thqSxqfmc9Nr3S70YIWNZWw1AiQ4XPzTmzanl276ARVXM42/7UmgB3/NOycfcHvS5uf2/xfpfTwfeuXTLOEUeHD14w85iPPXNmLWdayO5E4+NvmHeip/APjUldBkgpVwOrS7bdWvL5c+McuwY4tdy+1xSSw9DxDKy4Edb+2NQWjP0japUP5QlC0woy4Sl4hhMIa5ir0ROhgeGhfhxZqGw+Ddr/ZuY3lJyn+NrqelFfC7pILPiraS80MloYIC08qt1LvM9oHTmUzCHdAfqMhveKIEZyamXeKRrZ3J/nMu18AynliPS5nAZBzG8KG45ka+ObSr97TBZx6efSpDUwTT6rt/QwrzFs5BlYTUy6iafC56Im4OETb5jHhy9StYvufN9yRpNZo5LpvKOMDrJh42TFyeKktjEe9j6h7PmLroKKKaa2oEMvWSEcqo3m12fCy79W2dL7njT8CsngVDwih8PqmNZMTIVgA85slNRQp3I4B+vNSqc64v2Qz8LvPkD0nhvY0xc1fBDteTMBLOUKGyWlE7rZKDFIVGv8MhTPMBTPkNXKOusaxFBWCeBO1xTaR0x/wmDaScCtQjfrNBPO/OYK5jWFx5SmaKsN8G+vn1vkOLbC7RRjqpyCGVWUyRU401KwzVqKQncSv/fsNv5j1Xz8HpOwvC4nDWEfB4fUdyk1Mdmw8fcKmyBOdvRuVUXumk+HutlmxJIO/XPjIhg9oIT2729U27b9Sa38hZOkvxEvWZy6icnhMsxPSW89FSJJHaMq+3iq1oCm1Kw0sBu2/gHfzj/x6V8/r64lHGyPmwIxIYLEtMqmMamtwGWBmFTCfCieMXojNIS9dA4nyeQKRLJKcA+7m9hUME0gSTwEtNX77IYQfreTs2fW4nU5DZOLnlcQ9Lq45XVzjAqdpajwucs2YrESzVuXmJHYYZ8LPapV1yBWzKjhHcvKJ5hdf46y67eN43y2YePvDTZBnOwY3K2a5Lg8UDtHmZisxX4Gdith31omyMsTUBpEuIms8OIhi8glSEoPKWfYcGBHNKewU0ioaOanA1qLxnzG7P0M8NIvoZDFTZaGvmcoxAfBX80WS/BUXASNXIBY3iQYvXXkcDxDr2ZeOmN6NdF0jvX7h6gRykEc8zbSg2njTuI1hHNrlZ9tX3gjp02tMo7f8+VVXKElluk+gPEifcqZl4Ci0hXWTmcOh6DS78btFEbU0kS4+ZI57PvvN41bCsOGjb832L/kkw09W+CRz6hENVCEYPRfnqOK0P3ySrjvBlXCYnA3VM9QlVJLEe1R4anhJrK48ZKFTIIEXvrSLiP8dVCYK+5csJEfd5l9AQg3GW0X2fgrCNQySph/F7+isONBCNTyzEHTERwlaBSvi+ZNgRzDR3XAzVAiQ5/WjeyG82YQ9rn42K83UitU1FHKryJStrkXAuAibzSGAcZoAC6nwzAF6bV5xqsxVJrDYMVvbjqbB245b8z5qwIeQt4jbwF5srSKtGHj1YBNECcbnvtf9Td6UJHE0F5Vqwhg9qUw7WwKo52w5Xeq2Y5OIHqHtebTVSOcYL0yL0V7INxMVrjxkENkEyTxEsc0q3TnzXDLPllDfyHMbfJK5NV3wvIPwIVa3fzUCMxdyU/FlYwQIuauJzrvKjqGs2SFEsrDBZ8RQTSaM2Mg4tLPotZKUtkC9647SMjr4vSpVfz3lYvpjaT5n9w7GJrxZvbXXwzAPVM/y5Ous9lQmEvwMF2+dGfy4TSIiQhixYwaFrWODTut9LvNLmA2bLzGYBPEyYR8DnY9rN4P7lYkkUuZGkTtLDa87h7O6vq4+ty/wyQQnSBal8I1v4Lp5yhyiHZDuJkMbhxC4svHSEgvMcxEp4MZ04fQob3/7/TVdLauhPM/DmffrMxYAPNW8ePsKt6S+RI/OeWnPNHwXgCkVre/K2UKZ92vABDHx1VLp+ByCF46MMLKRU24nQ4uP7WFq8+YwgHZSOotPyEQVPb7YP10vln1X0QJEPBOnNBVZfQoVuPqw148LgctlcU9fsczMU2E5kof9a8wOc2Gjb9X2ARxMuHgWrP728Aes2eCpS3hgaE4fYUQOU+lKqSXz6j9fs1MVKuRSbhZ5TmkRiDcREaLaK4UMRJ4iWtO4wKC9qR6n8fB7phJHDu6o9z5zD4e3NILoSZweklPv9CoT7SjO8oL+wYJepy4/Mp2fyBuCuFHt/WScajzxfAztSbAhXNVotfbLM7gL79tEfd96GxaqvyGEG+t8hkdw45Yg9DG+9xO/vDP5/IRrZR2Y4UXp0NQeQzJXZ+/YiHfvebVyT+wYePvDbbufDLhgNaHwRNS0UkZ5bilzkwGiqXzgCAenkFlx1NqY8MpyqTkcJsRSOEmVUAPoGoamYMq2qmKGAOy0tAgMrjZF9Oa8shK9g2l8bkdpLIFdvREuOPpfbRU+rmsaRF4QoazGWBHT5SBeIbFUyoReaVBtMfMn9Sj23qJet3UihRx6SPkdfHPF8+mNuQpyiz2upws05rdGARR7TcJ4nAahHZMyDJuQUsF3aMq7DTkc3PTBTM5b3Zd2eMnQmnnNBs2XkuwCeJkQnxQ9Uiom6NMTN0bofUMCJrCNK5FCI0G26gc3Aj+GmhZohqrfLpLRTtBcbOcmReT3tQOQJWIc0A2GBpEUnrYNSrArZrttA/EmVUfIprK8dj2PkYSWUaTWSIf/DkVXhexEdVOc3ZDiD19Mfpjad515jREf5gcDtpHLBFWqCgkiBLDT9DrZF5TeNwwVIBpNUGcDsGchrBhGgocRoNoqPDhdztprSou96zX3g95nXxy5fxyh9qwYWMC2CamkwkJFTZK3VzY/5zqxjZvVdEQPUJo0KfV0pm7UpEDmOQAxe02Q/WkpBKyVUQ1J7VaGafwMJRXZNEnq9nWFaGtNsgZ06vZqNU5khI2HIyA02U0tdHbW2ZyBU5pqlDaBUE6S0pb5B3Kfq9rEIfDWTNrWPeZS5laEzDGH06DqPS7efZTl7CqpCaPXh7jZGoCb8PG3xNsgjjeePIbcMelxdv++jWV+ZwYVM7murmmeWjem4qG6jkGvd42tWF+8X4DIU1YLrwSgLRGEB6RJyF9LGhr0ba7mVobJuMK0ylrGYilmVLtZ4Ulo9jpEKzbN8SWzlHWa70Yllm0gPnNYQjUEHNWGPPT4fUr01Mc06cwEYQQRoP34BFqEADVQc+YRit61NKRXNeGDRtjYf/nHG/sewoOrVNd4LSWmDz5DfU6uEeRwxnXq32BWmhcWHS4bmLaFjqTlW+/C+ZdRlk0zId3/lKFxgIpaTqPE3g5Y+40OATS5eO9Z7fxQvpH/HCN6kjXUOEzNISWSh/1YS8vHRjhLzv6jIqnsxtCVPrdRFJZ5jSE4aL/5Pbep6GkQ6fDE4AEOHxhsxH9EUL3KQSPoSw12BqEDRuvFPZ/zvGGXjtpcC80a7UIfRVKexjZD9POgkANnHlT2cP1DmmRNGa/hfFwypuNt8mC+ahTwofLp8JZZzTVMuO8GfxlR4A+1gMq6mdWvergdkpzBfVhL6s3d5PI5I1zhH0uFjRX0BtNqb4CNTMYqR6B/cV9I1xe5Rf48Q0XTTzXMjCd1Mf2Mw15XHicjmMKb7Vhw4ZNEJOP7X+GSDeceaPSGiJaz6TB3aqLW/vfwBs2m+8EJi6lrKKYGGPKORx0HwRAzulHeLXcB5fyRVhDSRsrfAghuP29y6jyu3lyVz/3rjtYdL6Qz8UX37qQZMYsrHfWzFr+uLGYINyaiQlv6KjmC6+cIBwOwV3vW86cY+icZsOGDZsgJh8bfq6ikc680dQeQOU53HeDet9kqWrur2Ei6CamaCo74bhSJAuWpDVXtSmw3RpBWISw3i1s6TTlZ+iLpsecL+x101DSVexNi5r5z/s3F23z+bXIIs/RE4QZxXRsJiaAc44htNWGDRsKtpN6spEYVKWyk8Nm4ptwqgglHdaqqYEjI4ij1SASeVPI9nunmwLbpSKYrHb6hpKG9PPL9Dfwucf+dCoDbsPuf9oUVbbC7dP8LMegQegd2vSezjZs2Di+sDWIyYbeBnRgj6ZBCOVn2P2IOSZlaZt5GIIwKqWmxhJEPJ3jk/dt4lOr5jO1pjgnwOqDGPJPG1eDqAq4i/opq20emit9xFI5o9fDeEXpnvnUJYwmslQF3IwksvD8X9WOY9AgzphezcMfPf+wHdps2LAxObA1iMmG3uVtcDeMHFAJbG3nF4+JWZrzHMYHYZiYymgQG/YP8+Dmbj7yfy9qn4fI5ZWPIG7RIHK+WrNCq6u4XtF4zej/5XVz+H+XL5hwbqB6LkytCRDWXqmdo/4cR28mEkLY5GDDxgmETRCTiVxGOaJBmZcyMeWQvuhT8IndcOUdap8+Bo7AST2+BjGcUFnOmw6NcmAwwVU/es5wGltNTCGf29QgNILwuR04xFjzko5rV0zjqyZgDwAAIABJREFUHcvLN8qZEGfeCLesP/rjbNiwccJhm5gmE3rhPVAaRDapmvgIAaGGohIaBiZwUqdzeaNVZzkfRF/EdCb/YaOKltrVpzXiyZuPOuh1mSYft/JBCCEI+9w02rWHbNiwocEmiFcDv34PBOvg8m8Xb9dDV4VD5T34qopt8Z4S56/DNaEPIq6FuFYH3AwnsuQLEqcle7g3Ypa5eGGfMm11DKjMtZimQTydX6jMSZ4QOL2q9pOGr165mFkNE/sK7vngWTjsnjg2bLwmYBPEq4H+HTBapg+x7qCunALJEXC6IdREoSBVWQhrZM+y98Piq8E1fsSO7n9orPAxnMgSS+eKksB6o6pMRtdIkq1dKit6/6DqGjeUD/C1hq/z8wN1vM/rBIcD/ulPRaXEVy22FPgbB2fPmtgEZsOGjX8c2D6IVwPpmGrOUwpdg6iarvwPmQSb+rLM/PRqpJTKH6GjokU1+ZkAulmpSWuEU2pm6o2kaKnyUxfyMpxQeRIdg3EKBUk6V6Cn9kzSDj/VWoMdI2vbhg0bNspgUglCCLFSCLFTCLFHCPGpMvu/LYTYqP3tEkKMlOyvEEIcEkL872TO8xUjHYVYLxTybH7gB2z947fU9jEEEWPHoDITHRpOlpibymggJdA1iCbNT1DqqO6NpGiq8BX5EVLZAn3RNOlcnkq/m3s+eBbvPBZnsw0bNl5zmDSCEEI4gR8Aq4AFwLVCiKI4SSnlx6SUp0spTwe+D9xfcpovAk9O1hxfFUiphL8sQLyfxes/zcKXPg/5rBniWj1d7U8MKic1sK5jqCxBZHIFOkeSRZfIFyQHBhOGxqDnOAzETKe0lJLeSIrGCu8YR/O+gTjpXAGv28GKGTVGnwQbNmzYmAiTqUGsAPZIKdullBngXuAtE4y/FrhH/yCEOANoBB6dxDm+cmTigNYkJ9ptbj/wnCIId9A04+QzODS/w7qOIXC6jExm3Erof+/x3Zz71b8Y3dAA/vxyFxd84wm+/xdVqmNxq8pSthJJJJUjlS3QWOGjUQtVnaYRycGhBJlcAe9RVlO1YcPGaxuTKTFaAWuFt0PatjEQQkwHZgB/0T47gG8Cn5joAkKIG4UQ64UQ6/v7+1+VSR81MjHjbXq4i0Gp+RV2PqSc1IHaomilaEHZ/9dpfRUyTiXEb32og5t+sd5o0vPAyybZbO9WeRIb9g9z5dJWzppZixDQOawIoj+a5t13rAVUqW5dg5ijRST1a5qG133sNY1s2LDx2sPJsqS8BrhPSqnXk/5nYLWU8tBEB0kpb5dSLpNSLquvr5/0SZZF2iSI0b4DODRtQu57UmkUwbqiaKXRnCKIA4MJpJSM5NVqP+/y88jWXkaSKtlNz2MAODSSRAi48YKZfP6KhXhcDhrDPkODeL59kM2do7xxYSPnzKo1NYjaAEKYpiiv62R53DZs2Ph7wGRKjE7A6g2dom0rh2uwmJeAs4GbhRAdwP8A7xVCfHUyJvmKkYkabxODhwiimX0G96rs6drZRb6GoayKLM7kC4wmswxphHHVWSrcdGtXxHgd1AR7x0CcC+bU8+k3nWL4D1qqfHRpBLGjJ4LTIfjetUuoC3lp0DSIhrBq86lXY7U1CBs2bBwNJpMg1gFzhBAzhBAeFAn8qXSQEGI+UA08p2+TUr5LSjlNStmGMjPdLaUcEwV1UsCiQcjh/XhEnkOyDpFLqt4PdXOQHqsG4WZmnXJIr903xGhBCfPmOlWWWkporVJ+id+sP8SyLz3G1q4IM+qKo5xaqwOGBrGzJ8qs+iBelyKAZi0Mtj7spcLn5tCQyoWoshvn2LBh4ygwaQQhpcwBNwOPANuB30gptwohviCEuMIy9BrgXimlnKy5TCp0H4Rw4httB2BTYaaxu0O08nh7wvicxGsI+4c2dxOXmjCvrcbtVCnKy9tUH4avPbzDMA+11RZXZ22p8tE9kqJQkGzvjhYVtZvXGOZrVy1m1aImwj4XBzVfRVXAJggbNmwcOSbVKC2lXC2lnCulnCWl/LK27VYp5Z8sYz43kXYgpbxLSnnzZM7zFUHXICqnEEoqC5qVIH60RfCZ1R3G5zg+gyD+uqvfcFK7fCGmVqv3y2eMTV6bXqJBTKnyk8kXaB+I0zmSZJ6lZ4MQgncun0bQ6yLsczEUV36NKr8HGzZs2DhS2F7LVwrNB5Gvmk44ryKQOmQTEemnIAUPdQWJ4TeGJ6WXmfXK5DSSyOLUekPjDtCmkcApzRUES7qozaorrpE0RQth/fZjuwBY0Fy+LHaFJefB1iBs2LBxNLAJ4pVC0yC2xCqNTXF8tMtmuqglknORwKyvlMDHtJqAUfDOHagABLj9tNUqgphS5adF80Ncd+Y0fnPT2UwrMTGdN7uOU6dU8uCmbk6fWsV5c8q31tQ7vIFNEDZs2Dg62MX6Xik0H8SmWAWnaZvi0sdPcpcTEsr2L3EQkz5CIkUCL1UBNzVBLwOxNL3TLoPT5oIQXH5aM8lsjrqQl9ZqP7v7YsxpCLGijMnJ7XTwvWuW8I1Hd/Ifb5yPe5wkOD3qyeUQRW1FbdiwYeNwsCXGK0U6Bp4QPTnTRxDDz4OFs4zPsxtCpGMBQoUUSekl7HNRF/IwEEvja1sBp78NgKXTqlk6TTmodQ2irW78Gk1tdUF+cN3SCadX4TdbiY7XJtSGDRs2yuGwJiYhxJu1zGYb5ZCOgCdEZ9piAtIS4/ReDT+/YQVVVUrwx/ER9rmp+//t3Xt4VdW57/Hvm3tCIokJKLcKKm7wgiAUL3i3tmhV1KKgbrd2b2uleN3dPqI9FfDY057qbhUfWqtnY7XaIqJY7cbtrXhBxRIQuQuoKAGEELkFcs97/phzhZWwElYiK4uE3+d58rDmmGOu9Q4mrDdjzjHHyA0uOzUdvhoRGeoauezUVpEeRFcNcRWRVoqnBzEGeMjMngemufvKBMfUoXy99Wu6pOawqa4LhPeVUzLzsKpguGnJ1t307JqFhVN7V5DR0IMAOKKZBHDpkGBWkqbDW1srcg8iP0cjmESkdfaZINz9n83sEILJ9P5oZg48AfzF3Xe2fHTntmrTTtZ/WkK3FNjqe4aZpmcfQlF9HaccWUjJ1uzg0k5mHlWWSVZ6OumpKQzqnc+a0vJmf7PvlZ/N+HOO/sYxRnoQBbpBLSKtFNc9CHffYWYzgWzgduAy4E4zm+LujyQywGRxd/rdPZu7Rg5g3NlHNdp3+e/eo29RFzaUfs2DKetZV9+drR4OQ03NJD8vB0ur4d6Lo2Y3z8ilJiWr4Yv6X0/vx7+e3i/h7Tgk7EF01TMQItJK+0wQ4VPPPwSOBp4Chrv7ZjPLAZYTrOPQ6URmQH3g1ZV7JYiFX25j4ZfbeDbjPnqnbGExR7KNMEFk5nLPhQOprWvyYHiXIjIP6cZDlwxpj/AbRHoQGuIqIq0VTw/iB8Bv3b3Rwj3uvtvM/i0xYSXf2i3B9BiFuXueYdheUdPw/AJAHyulKiWb/1N1DVVkUJeWQ2pmHgNjPbR27s9Jr9zO8G7tu8RnpAehS0wi0lrxJIhJQMPiBGaWDRzm7mvd/c1EBZZsa7fsAmgYbfTV9kpO+eWbnH/sYQ11Dkmt5os+l1LySTDVuGcf2mjth0byDgt+2llhbiapKcbhXbP3XVlEJEo8CeI54LSo7bqw7NsJiegAsbYsSBC3VP8XfFrLXW8Ho41eX74JgIkXDaTL3yvI7LLnCWrrUtiwpOiB4tAuGfztltM5qlvuviuLiESJJ0GkhUuGAuDu1eH03Z1aJEGcv+tlalcexjurz2y0f2ivHKy+lqwwQaSnGikjboOUA2/NhZiXvERE9iGeB+BKo6fnNrNRwJbEhXRg+HzLbsBJp5ZtO8txh57hOgsA3TJrAMjNyweC5wzshB/AcZcmI1wRkf0ungRxE3CPmX1pZuuAu4AfJzas5HJ3vijbRQa1AOwsD+ZbOm/gnnsIh6YFnarsvK6kp5oW4xGRTmefCcLdP3X3U4BjgYHufpq7r0l8aMlTWVPP7uo60sMEUb6rnOz0VE45shCAvMw0MuuCS1ApmXl0z8vSMFIR6XTielDOzL4PHAdkRSZ8c/f7EhhXUm2vCC4f9cpLgRqo2L2bYw7Po8+hwUigorzMPSvJZeZy6lGFDaOdREQ6i3gelHsUyAHOAf4fMBr4R4LjSqpIguh9SBqUwe6K3Qzon0fP/Gxy2c2grHKoCIezZuTx4BUntvBuIiIdUzw9iNPcfZCZLXb3yWb2n8AriQ4smXZUBgmizyGpUAYZXs0RRTkUdslgVuYk+m8pgZe7B5UzNXxURDqneG5SV4Z/7jaznkAN0CNxISXf9t1BguiZFwxZzbQaeuVnYzW76W8lQaVdm4M/M5QgRKRziqcH8bKZ5QMPAAsBBx5PaFRJFrnE1DM3yJ+ZBAmCsk/3rqwehIh0Ui0miHChoDfdfRvwvJn9Dchy9+3tEl2SRC4xHR6VIAoLsmHd6qDCEafDF3OD181NrSEi0sG1eInJ3euBqVHbVa1JDmY20sw+MbM1ZjYhxv7fmtmi8GeVmW0Lyweb2QdmtszMFpvZmFa06RuL9CC6ZQcjtjKppnteFmxZDRgcEc48kpYFqVq1VUQ6p3i+3d40sx8AL7i777N2yMxSCZLL+UAJMN/MXnL35ZE67n5HVP1bgMhc2LuBf3H31eF9jwVm9mrYk0m4HRW15GamkZdeD0CG1QbLh25ZDfl94NBwHQfdfxCRTiyem9Q/Jpicr8rMdpjZTjPbEcdxw4E17v5ZOJfTdGBUC/WvAv4C4O6r3H11+HoDsBnoFsdn7hfbK2romp1OdkodEFxiAqBsNRT2h7zDg23dfxCRTiyeJ6nz3D3F3TPc/ZBwO57Z33oB66K2S8KyvZjZEUA/4O8x9g0HMoAYd4gTY3tFDXlZaWRZVIJwhy1roKg/5IWDuHT/QUQ6sXgelDszVnnTBYS+obHATHeva/LZPYA/AdeF90OaxnYjcCPAt771rf0WzI7KoAeRUh/Mt5RlNbBjA9TsgsKjo3oQShAi0nnFcw/izqjXWQSXjhYA5+7juPVAn6jt3mFZLGOB8dEFZnYI8N/Az9x9XqyD3P0x4DGAYcOGxX1/ZF92VNTwrUNzoC64tJRCPWxeEewsOgay8oMb1LrEJCKd2D4ThLtfHL1tZn2Ah+J47/lAfzPrR5AYxgJXN61kZgOAAuCDqLIMYBbwlLvPjOOz9qvtFTUckp0OtVV7CjctCf4s6g9mcOiR0KV7e4cmItJu2jJGswQYuK9K7l5rZjcDrwKpwDR3X2Zm9wHF7v5SWHUsML3JCKkrgTOBQjO7Piy73t0XtSHeVtsR3qSmrnpP4VdLg1FLkfsPV03XKCYR6dTiuQfxCMHT0xDc1B5M8ET1Prn7bGB2k7J7m2xPinHc08DT8XzG/lZdW8+u6rq9E8SmpVB4VNB7ACg4IhnhiYi0m3h6EMVRr2uBv7j7ewmKJ+nKdgWXlQpzM6A2KkGUroTjRycpKhGR9hdPgpgJVEZGGJlZqpnluPvuxIaWHFt2BkmhKDcTtlQ33tk15ihdEZFOKZ4H5d4EsqO2s4E3EhNO8m0JexBFuZmNLzEB5BQmISIRkeSIJ0FkuXt5ZCN8nZO4kJJry84gQXTLzYS6qsY7lSBE5CAST4LYZWYnRTbMbChQkbiQkmtLeXiJKS+j4TmIBtmHJiEiEZHkiOcexO3Ac2a2ATDgcKBdZ1dtT1vKq8jJSCUnI63xcxCgHoSIHFTieVBufvgw2z+FRZ+4e01Lx3RkW8qrgvsPu7+Gmib34XPUgxCRg8c+LzGZ2Xigi7svdfelQK6Z/STxoSXHlvIqundJhUeGwsd/abxTPQgROYjEcw/iR9HrMLj7VuBHiQspubbsrKZvdiVUfB0UpHfZszOra3KCEhFJgngSRKpZ5PHhhoWAMhIXUnJtKa/iiIyoRfOiZ2xNSW3/gEREkiSeBPE/wLNmdp6ZnUewqM8riQ0rCerrqP/TDxhQsZA+ac0kCBGRg0g8o5juIlhz4aZwezHBSKbOpXI7KZ++wbWp2+mXGzWBrRKEiByk4llRrh74EFhLsBbEucCKxIaVBOGIpbNSF3N0+pY95RldmjlARKRza7YHYWbHEKwTfRWwBXgWwN3PaZ/Q2ld1ZTkZQDZVsOz5PTvSMpMWk4hIMrV0iWkl8C5wkbuvATCzO9olqiTYtn0nDcv/7Iha+K6+DrofByd22mcDRURiailBXE6wmM8cM/sfYDrBk9Sd0s7yHXQHqjPyyajetmdH1U74yftJi0tEJFmavQfh7i+6+1hgADCHYMqN7mb2ezP7bnsF2F52le8EYFvfC4KCyHKi1eXNHCEi0rnFc5N6l7v/OVybujfwEcHIpk6lYleQIGr+6RJIy4Le3w52VClBiMjBqVVrUodPUT8W/nQqu3ftAiC3qA+M/xAqt8Mn/w3VO5McmYhIcrQqQXRmVRVBTyE3Lw8K+sKucKirehAicpCK50nqg0J1ZZAIUiPPPWTlh39q/iUROTipBxGqrQwuMZEerq6amgajfgd9Tk5eUCIiSaQEEaqrCtd+SI9afnvINckJRkTkAJDQS0xmNtLMPjGzNWY2Icb+35rZovBnlZlti9p3nZmtDn+uS2ScAHU1FdSQrhlbRURCCetBhNOCTwXOB0qA+Wb2krsvj9Rx9zui6t8CDAlfHwpMBIYBDiwIj92aqHip3k1taibpCfsAEZGOJZE9iOHAGnf/zN2rCZ7EHtVC/asIphIH+B7wurt/HSaF14GRiQq0vt6x2kpqU7L3XVlE5CCRyATRC1gXtV0Slu3FzI4A+gF/b82xZnajmRWbWXFpaWmbAy2vriWLKurTstr8HiIinc2BMsx1LDDT3etac5C7P+buw9x9WLdu3dr84TW19WRRTV2qehAiIhGJTBDrgT5R273DsljGsufyUmuP/cbq6p1sqqhL1dTeIiIRiUwQ84H+ZtbPzDIIksBLTSuZ2QCgAPggqvhV4LtmVmBmBcB3w7KEqK13sqya+jT1IEREIhI2isnda83sZoIv9lRgmrsvM7P7gGJ3jySLscB0d/eoY782s/9NkGQA7nP3rxMV654ehO5BiIhEJPRBOXefDcxuUnZvk+1JzRw7DZiWsOCi1NY72agHISIS7UC5SZ1UdfX1ZFk1rh6EiEgDJYjyzRS+NYHetkU9CBGRKEoQ6Tl0/eQ5ADxdCUJEJEIJIjOX8h6nAeB6UE5EpIESBLCt11kA5OwqSXIkIiIHDiUI4Ove5wFQkX9MkiMRETlwKEEAu3N68u3KqWw8/sfJDkVE5IChBAHU10MpBaSla7JvEZEIJQigtr4egNQUS3IkIiIHDiUIgqk2ANKUIEREGihBEEy1AepBiIhEU4Igugehvw4RkQh9I6IehIhILEoQBJP1ge5BiIhEU4IAauvUgxARaUoJgqh7EKlKECIiEUoQ6B6EiEgsShBoFJOISCz6RkQ9CBGRWJQg0CgmEZFYlCBQD0JEJBYlCKCuTnMxiYg0pQSBehAiIrEkNEGY2Ugz+8TM1pjZhGbqXGlmy81smZn9Oar812HZCjObYmYJ+/auq3dSU4wEfoSISIeTlqg3NrNUYCpwPlACzDezl9x9eVSd/sDdwAh332pm3cPy04ARwKCw6lzgLOCtRMRaGyYIERHZI5E9iOHAGnf/zN2rgenAqCZ1fgRMdfetAO6+OSx3IAvIADKBdGBTogKtq6/X/QcRkSYSmSB6AeuitkvCsmjHAMeY2XtmNs/MRgK4+wfAHGBj+POqu69o+gFmdqOZFZtZcWlpaZsDVQ9CRGRvyb5JnQb0B84GrgIeN7N8MzsaGAj0Jkgq55rZGU0PdvfH3H2Yuw/r1q1bm4Ooq3f1IEREmkhkglgP9Ina7h2WRSsBXnL3Gnf/HFhFkDAuA+a5e7m7lwOvAKcmKtCgB5HsXCkicmBJ5LfifKC/mfUzswxgLPBSkzovEvQeMLMigktOnwFfAmeZWZqZpRPcoN7rEtP+UlenHoSISFMJSxDuXgvcDLxK8OU+w92Xmdl9ZnZJWO1VoMzMlhPcc7jT3cuAmcCnwBLgY+Bjd385UbHqHoSIyN4SNswVwN1nA7OblN0b9dqBfw9/ouvUAT9OZGzR6urrtRaEiEgTCU0QHYV6ECLxq6mpoaSkhMrKymSHIq2QlZVF7969SU9Pj/sYJQg0ikmkNUpKSsjLy6Nv376afaCDcHfKysooKSmhX79+cR+noTtoFJNIa1RWVlJYWKjk0IGYGYWFha3u9elbEfUgRFpLyaHjacs5U4JA9yBERGJRgkBzMYl0JNu2beN3v/tdm4698MIL2bZtW4t17r33Xt544402vX9L/vjHP3LzzTe3WOett97i/fff3++f3VZKEEBtnXoQIh1FSwmitra2xWNnz55Nfn5+i3Xuu+8+vvOd77Q5vm/iQEsQGsVEcA8iM125UqS1Jr+8jOUbduzX9zy25yFMvPi4ZvdPmDCBTz/9lMGDB3P++efz/e9/n5///OcUFBSwcuVKVq1axaWXXsq6deuorKzktttu48YbbwSgb9++FBcXU15ezgUXXMDpp5/O+++/T69evfjrX/9KdnY2119/PRdddBGjR4+mb9++XHfddbz88svU1NTw3HPPMWDAAEpLS7n66qvZsGEDp556Kq+//joLFiygqKioUaxPPPEEv/zlL8nPz+fEE08kMzMTgJdffpn777+f6upqCgsLeeaZZ6ioqODRRx8lNTWVp59+mkceeYRt27btVe+www7br3/fLdG3IhrFJNKR/OpXv+Koo45i0aJFPPDAAwAsXLiQhx9+mFWrVgEwbdo0FixYQHFxMVOmTKGsrGyv91m9ejXjx49n2bJl5Ofn8/zzz8f8vKKiIhYuXMi4ceN48MEHAZg8eTLnnnsuy5YtY/To0Xz55Zd7Hbdx40YmTpzIe++9x9y5c1m+vGEpHE4//XTmzZvHRx99xNixY/n1r39N3759uemmm7jjjjtYtGgRZ5xxRsx67Uk9CDSKSaStWvpNvz0NHz680fj+KVOmMGvWLADWrVvH6tWrKSwsbHRMv379GDx4MABDhw5l7dq1Md/78ssvb6jzwgsvADB37tyG9x85ciQFBQV7Hffhhx9y9tlnE5lpesyYMQ0JrKSkhDFjxrBx40aqq6ubfTYh3nqJol+b0SgmkY6uS5cuDa/feust3njjDT744AM+/vhjhgwZEnP8f+RyD0Bqamqz9y8i9Vqq01q33HILN998M0uWLOEPf/hDs88nxFsvUZQg0CgmkY4kLy+PnTt3Nrt/+/btFBQUkJOTw8qVK5k3b95+j2HEiBHMmDEDgNdee42tW7fuVefkk0/m7bffpqysrOH+RXSMvXoF66c9+eSTDeVN29ZcvfaiBIF6ECIdSWFhISNGjOD444/nzjvv3Gv/yJEjqa2tZeDAgUyYMIFTTjllv8cwceJEXnvtNY4//niee+45Dj/8cPLy8hrV6dGjB5MmTeLUU09lxIgRDBw4sGHfpEmTuOKKKxg6dGijG9sXX3wxs2bNYvDgwbz77rvN1msvFkyo2vENGzbMi4uL23TsWQ/MYUiffB4aO2Q/RyXS+axYsaLRl93BqKqqitTUVNLS0vjggw8YN24cixYtSnZY+xTr3JnZAncfFqu+blITeQ5CnSkRic+XX37JlVdeSX19PRkZGTz++OPJDikhlCDQKCYRaZ3+/fvz0UcfJTuMhNOvzYT3ILRgkIhII0oQaBSTiEgsShBoFJOISCxKEOgehIhILEoQaC4mkc4uNzcXgA0bNjB69OiYdc4++2z2NVT+oYceYvfu3Q3b8Uwf3haReJvzTaY8bw19K6IehMjBomfPnsycObPNxzdNEPFMH54I7ZUgDvphru5One5BiLTNKxPgqyX79z0PPwEu+FWzuydMmECfPn0YP348EDyVnJuby0033cSoUaPYunUrNTU13H///YwaNarRsWvXruWiiy5i6dKlVFRU8MMf/pCPP/6YAQMGUFFR0VBv3LhxzJ8/n4qKCkaPHs3kyZOZMmUKGzZs4JxzzqGoqIg5c+Y0TB9eVFTEb37zG6ZNmwbADTfcwO23387atWubnVY82ueff87VV19NeXl5o5gj203b1HTK84kTJ+6z7W2R0B6EmY00s0/MbI2ZTWimzpVmttzMlpnZn6PKv2Vmr5nZinB/30TEWFcfPEmuHoRIxzBmzJiGeZAAZsyYwZgxY8jKymLWrFksXLiQOXPm8NOf/pSWZor4/e9/T05ODitWrGDy5MksWLCgYd8vfvELiouLWbx4MW+//TaLFy/m1ltvpWfPnsyZM4c5c+Y0eq8FCxbwxBNP8OGHHzJv3jwef/zxhuck4plW/LbbbmPcuHEsWbKEHj16NJQ316amU563tu3xSlgPwsxSganA+UAJMN/MXnL35VF1+gN3AyPcfauZdY96i6eAX7j762aWC9QnIs7aMEHoOQiRNmjhN/1EGTJkCJs3b2bDhg2UlpZSUFBAnz59qKmp4Z577uGdd94hJSWF9evXs2nTJg4//PCY7/POO+9w6623AjBo0CAGDRrUsG/GjBk89thj1NbWsnHjRpYvX95of1Nz587lsssua5hV9vLLL+fdd9/lkksuiWta8ffee68hcVx77bXcddddQHCFI1abmmquXnNtj1ciLzENB9a4+2cAZjYdGAUsj6rzI2Cqu28FcPfNYd1jgTR3fz0sL09UkOpBiHQ8V1xxBTNnzuSrr75izJgxADzzzDOUlpayYMEC0tPT6du3b5umx/7888958MEHmT9/PgUFBVx//fXfaJrtptOKR1/Kima293dQvG3aX21vKpGXmHoB66K2S8KyaMcAx5jZe2Y2z8xGRpVvM7MXzOwjM3sg7JE0YmY3mlmxmRWXlpa2KciGHoRGMYl0GGMhtNAYAAAIkUlEQVTGjGH69OnMnDmTK664Agimxu7evTvp6enMmTOHL774osX3OPPMM/nzn4Or2kuXLmXx4sUA7Nixgy5dutC1a1c2bdrEK6+80nBMc1ONn3HGGbz44ovs3r2bXbt2MWvWLM4444y42zNixAimT58OBF/2Ec21Kda04K1pe7yS/a2YBvQHzgauAh43s/yw/AzgP4BvA0cC1zc92N0fc/dh7j4ssmpTa6kHIdLxHHfccezcuZNevXo1XLO/5pprKC4u5oQTTuCpp55iwIABLb7HuHHjKC8vZ+DAgdx7770MHToUgBNPPJEhQ4YwYMAArr76akaMGNFwzI033sjIkSM555xzGr3XSSedxPXXX8/w4cM5+eSTueGGGxgyJP7ZoR9++GGmTp3KCSecwPr16xvKm2tT0ynPW9v2eCVsum8zOxWY5O7fC7fvBnD3X0bVeRT40N2fCLffBCYAqcD/dfezwvJrgVPcfXxzn9fW6b63V9RwzwtLuPLbfTjrmLYlGZGDiab77rhaO913InsQ84H+ZtbPzDKAscBLTeq8SNB7wMyKCC4tfRYem29mkW/sc2l872K/6ZqdztRrTlJyEBFpImEJwt1rgZuBV4EVwAx3X2Zm95nZJWG1V4EyM1sOzAHudPcyd68juLz0ppktAQzonBOui4gcoBL6oJy7zwZmNym7N+q1A/8e/jQ99nWg+XFlIpI07h5z1I0cuNpyOyHZN6lFpIPJysqirKxsvzyIJe3D3SkrKyMrK6tVxx30U22ISOv07t2bkpIS2jq0XJIjKyuL3r17t+oYJQgRaZX09HT69euX7DCkHegSk4iIxKQEISIiMSlBiIhITAl7krq9mVkp8E0mICkCtuyncJKts7Sls7QD1JYDldoCR7h7zCeFO02C+KbMrLi5x807ms7Sls7SDlBbDlRqS8t0iUlERGJSghARkZiUIPZ4LNkB7EedpS2dpR2gthyo1JYW6B6EiIjEpB6EiIjEpAQhIiIxHfQJwsxGmtknZrbGzCYkO57WMrO1ZrbEzBaZWXFYdqiZvW5mq8M/C5IdZyxmNs3MNpvZ0qiymLFbYEp4nhab2UnJi3xvzbRlkpmtD8/NIjO7MGrf3WFbPjGz7yUn6tjMrI+ZzTGz5Wa2zMxuC8s71LlpoR0d7ryYWZaZ/cPMPg7bMjks72dmH4YxPxsuzoaZZYbba8L9fdv0we5+0P4QLG36KcGa1xnAx8CxyY6rlW1YCxQ1Kfs1MCF8PYFg+dakxxoj9jOBk4Cl+4oduBB4hWDxqFMIlqpNehv20ZZJwH/EqHts+G8tE+gX/htMTXYbouLrAZwUvs4DVoUxd6hz00I7Otx5Cf9uc8PX6cCH4d/1DGBsWP4oMC58/RPg0fD1WODZtnzuwd6DGA6scffP3L0amA6MSnJM+8Mo4Mnw9ZPApUmMpVnu/g7wdZPi5mIfBTzlgXkES9L2aJ9I962ZtjRnFDDd3avc/XNgDcG/xQOCu29094Xh650EK0L2ooOdmxba0ZwD9ryEf7fl4WZ6+OMEyzHPDMubnpPIuZoJnGdtWOHpYE8QvYB1UdsltPwP6EDkwGtmtsDMbgzLDnP3jeHrr4DDkhNamzQXe0c9VzeHl12mRV3q6zBtCS9NDCH4jbXDnpsm7YAOeF7MLNXMFgGbgdcJejjbPFjeGRrH29CWcP92oLC1n3mwJ4jO4HR3Pwm4ABhvZmdG7/Sgj9khxzJ35NhDvweOAgYDG4H/TG44rWNmucDzwO3uviN6X0c6NzHa0SHPi7vXuftgoDdBz2ZAoj/zYE8Q64E+Udu9w7IOw93Xh39uBmYR/MPZFOnih39uTl6ErdZc7B3uXLn7pvA/dT3wOHsuVxzwbTGzdIIv1Wfc/YWwuMOdm1jt6MjnBcDdtwFzgFMJLudFFn6LjrehLeH+rkBZaz/rYE8Q84H+4UiADIKbOS8lOaa4mVkXM8uLvAa+CywlaMN1YbXrgL8mJ8I2aS72l4B/CUfMnAJsj7rccUBqch3+MoJzA0FbxoYjTfoB/YF/tHd8zQmvVf8XsMLdfxO1q0Odm+ba0RHPi5l1M7P88HU2cD7BPZU5wOiwWtNzEjlXo4G/h72+1kn23flk/xCMwFhFcD3vZ8mOp5WxH0kw6uJjYFkkfoJrjW8Cq4E3gEOTHWsz8f+FoItfQ3D99N+ai51gFMfU8DwtAYYlO/442vKnMNbF4X/YHlH1fxa25RPggmTH36QtpxNcPloMLAp/Luxo56aFdnS48wIMAj4KY14K3BuWH0mQxNYAzwGZYXlWuL0m3H9kWz5XU22IiEhMB/slJhERaYYShIiIxKQEISIiMSlBiIhITEoQIiISkxKEyAHAzM42s78lOw6RaEoQIiISkxKESCuY2T+H8/IvMrM/hBOolZvZb8N5+t80s25h3cFmNi+cFG5W1PoJR5vZG+Hc/gvN7Kjw7XPNbKaZrTSzZ9oy+6bI/qQEIRInMxsIjAFGeDBpWh1wDdAFKHb344C3gYnhIU8Bd7n7IIIndyPlzwBT3f1E4DSCJ7AhmG30doJ1CY4ERiS8USItSNt3FREJnQcMBeaHv9xnE0xYVw88G9Z5GnjBzLoC+e7+dlj+JPBcOHdWL3efBeDulQDh+/3D3UvC7UVAX2Bu4pslEpsShEj8DHjS3e9uVGj28yb12jp/TVXU6zr0/1OSTJeYROL3JjDazLpDwxrNRxD8P4rMqHk1MNfdtwNbzeyMsPxa4G0PVjYrMbNLw/fINLOcdm2FSJz0G4pInNx9uZn9L4IV/FIIZm4dD+wChof7NhPcp4BguuVHwwTwGfDDsPxa4A9mdl/4Hle0YzNE4qbZXEW+ITMrd/fcZMchsr/pEpOIiMSkHoSIiMSkHoSIiMSkBCEiIjEpQYiISExKECIiEpMShIiIxPT/ARl6huUIQGzXAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "UV9sxWmqPWdC",
        "outputId": "b5d27df9-9427-4e88-fd16-ae5754f6c616"
      },
      "source": [
        "plt.plot(history_2.history['loss'])\n",
        "plt.plot(history_2.history['val_loss'])\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training data', 'validation data'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cv9p1e5aQqKN",
        "outputId": "b1a32890-4bb6-4f55-9bbd-e1fac22cd804"
      },
      "source": [
        "P2 = model_2.predict(XTRAIN)\n",
        "accuracy_train = model_2.evaluate(XTRAIN, YTRAIN)\n",
        "\n",
        "print(accuracy_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4786 - accuracy: 0.7804\n",
            "[0.47857666015625, 0.7803571224212646]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c2MjXITQyst",
        "outputId": "2392815c-13a7-4db7-f558-aaf49e3e4ae1"
      },
      "source": [
        "P2 = model_2.predict(XVALID)\n",
        "accuracy_valid = model_2.evaluate(XVALID, YVALID)\n",
        "\n",
        "print(accuracy_valid)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15/15 [==============================] - 0s 2ms/step - loss: 0.4750 - accuracy: 0.7808\n",
            "[0.47503024339675903, 0.780793309211731]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJJuxJG4Q3qB"
      },
      "source": [
        "model_3 = Sequential()\n",
        "model_3.add(Dense(128, input_dim = len(XTRAIN[0, :]), activation='relu'))\n",
        "model_3.add(Dense(128, activation='relu'))\n",
        "model_3.add(Dense(128, activation='relu'))\n",
        "model_3.add(Dense(64, activation='relu'))\n",
        "model_3.add(Dense(64, activation='relu'))\n",
        "model_3.add(Dense(32, activation='relu'))\n",
        "model_3.add(Dense(16, activation='relu'))\n",
        "model_3.add(Dense(8, activation='relu'))\n",
        "model_3.add(Dense(4, activation='relu'))\n",
        "model_3.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0xJNbXwRKZk"
      },
      "source": [
        "model_3.compile(loss='binary_crossentropy', optimizer = 'rmsprop', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RO9XS6ERRGE",
        "outputId": "c6b53b69-6ef4-4679-e617-e1afbb3977f1"
      },
      "source": [
        "history_3 = model_3.fit(XTRAIN, YTRAIN, validation_data=(XVALID, YVALID), epochs = 256, batch_size=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/256\n",
            "112/112 [==============================] - 2s 4ms/step - loss: 0.6652 - accuracy: 0.5782 - val_loss: 0.5496 - val_accuracy: 0.7349\n",
            "Epoch 2/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.5633 - accuracy: 0.7164 - val_loss: 0.6250 - val_accuracy: 0.6806\n",
            "Epoch 3/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.5681 - accuracy: 0.7042 - val_loss: 0.5281 - val_accuracy: 0.7453\n",
            "Epoch 4/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.5500 - accuracy: 0.7239 - val_loss: 0.5290 - val_accuracy: 0.7641\n",
            "Epoch 5/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.5573 - accuracy: 0.7313 - val_loss: 0.5101 - val_accuracy: 0.7557\n",
            "Epoch 6/256\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7471 - val_loss: 0.5606 - val_accuracy: 0.7098\n",
            "Epoch 7/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.5235 - accuracy: 0.7573 - val_loss: 0.5115 - val_accuracy: 0.7599\n",
            "Epoch 8/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.4954 - accuracy: 0.7660 - val_loss: 0.5139 - val_accuracy: 0.7495\n",
            "Epoch 9/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.4924 - accuracy: 0.7814 - val_loss: 0.5129 - val_accuracy: 0.7578\n",
            "Epoch 10/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.5105 - accuracy: 0.7372 - val_loss: 0.5172 - val_accuracy: 0.7599\n",
            "Epoch 11/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.5238 - accuracy: 0.7496 - val_loss: 0.5103 - val_accuracy: 0.7516\n",
            "Epoch 12/256\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4980 - accuracy: 0.7631 - val_loss: 0.5054 - val_accuracy: 0.7537\n",
            "Epoch 13/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.5129 - accuracy: 0.7532 - val_loss: 0.5060 - val_accuracy: 0.7599\n",
            "Epoch 14/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.5169 - accuracy: 0.7449 - val_loss: 0.5333 - val_accuracy: 0.7599\n",
            "Epoch 15/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.4826 - accuracy: 0.7577 - val_loss: 0.5310 - val_accuracy: 0.7599\n",
            "Epoch 16/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.4881 - accuracy: 0.7747 - val_loss: 0.5717 - val_accuracy: 0.7620\n",
            "Epoch 17/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.4940 - accuracy: 0.7580 - val_loss: 0.5115 - val_accuracy: 0.7641\n",
            "Epoch 18/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.4724 - accuracy: 0.7827 - val_loss: 0.5159 - val_accuracy: 0.7578\n",
            "Epoch 19/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.4923 - accuracy: 0.7738 - val_loss: 0.5085 - val_accuracy: 0.7620\n",
            "Epoch 20/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.4471 - accuracy: 0.7793 - val_loss: 0.5134 - val_accuracy: 0.7474\n",
            "Epoch 21/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.4436 - accuracy: 0.7960 - val_loss: 0.5186 - val_accuracy: 0.7370\n",
            "Epoch 22/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.4639 - accuracy: 0.7798 - val_loss: 0.5147 - val_accuracy: 0.7704\n",
            "Epoch 23/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.4780 - accuracy: 0.7679 - val_loss: 0.5071 - val_accuracy: 0.7641\n",
            "Epoch 24/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.4696 - accuracy: 0.7821 - val_loss: 0.5285 - val_accuracy: 0.7620\n",
            "Epoch 25/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.4513 - accuracy: 0.7973 - val_loss: 0.5095 - val_accuracy: 0.7453\n",
            "Epoch 26/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.4260 - accuracy: 0.7991 - val_loss: 0.5134 - val_accuracy: 0.7599\n",
            "Epoch 27/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.4582 - accuracy: 0.7768 - val_loss: 0.5147 - val_accuracy: 0.7495\n",
            "Epoch 28/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.7785 - val_loss: 0.5232 - val_accuracy: 0.7516\n",
            "Epoch 29/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.4426 - accuracy: 0.7968 - val_loss: 0.5898 - val_accuracy: 0.7495\n",
            "Epoch 30/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.4319 - accuracy: 0.8073 - val_loss: 0.5376 - val_accuracy: 0.7474\n",
            "Epoch 31/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.4410 - accuracy: 0.8034 - val_loss: 0.5079 - val_accuracy: 0.7557\n",
            "Epoch 32/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.4420 - accuracy: 0.7831 - val_loss: 0.5494 - val_accuracy: 0.7474\n",
            "Epoch 33/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.4571 - accuracy: 0.7766 - val_loss: 0.5610 - val_accuracy: 0.7578\n",
            "Epoch 34/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.4152 - accuracy: 0.8003 - val_loss: 0.5426 - val_accuracy: 0.7620\n",
            "Epoch 35/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.4179 - accuracy: 0.7940 - val_loss: 0.5805 - val_accuracy: 0.7453\n",
            "Epoch 36/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.4432 - accuracy: 0.7840 - val_loss: 0.5194 - val_accuracy: 0.7453\n",
            "Epoch 37/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.4400 - accuracy: 0.7904 - val_loss: 0.5416 - val_accuracy: 0.7411\n",
            "Epoch 38/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3875 - accuracy: 0.8200 - val_loss: 0.5662 - val_accuracy: 0.7223\n",
            "Epoch 39/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3967 - accuracy: 0.8254 - val_loss: 0.6227 - val_accuracy: 0.7578\n",
            "Epoch 40/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.4343 - accuracy: 0.7920 - val_loss: 0.5239 - val_accuracy: 0.7349\n",
            "Epoch 41/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.4012 - accuracy: 0.8100 - val_loss: 0.5283 - val_accuracy: 0.7620\n",
            "Epoch 42/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.4040 - accuracy: 0.8126 - val_loss: 0.5530 - val_accuracy: 0.7453\n",
            "Epoch 43/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.4189 - accuracy: 0.8025 - val_loss: 0.5673 - val_accuracy: 0.7516\n",
            "Epoch 44/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3917 - accuracy: 0.8157 - val_loss: 0.5638 - val_accuracy: 0.7620\n",
            "Epoch 45/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.4431 - accuracy: 0.7873 - val_loss: 0.7148 - val_accuracy: 0.7474\n",
            "Epoch 46/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.4319 - accuracy: 0.7922 - val_loss: 0.5717 - val_accuracy: 0.7641\n",
            "Epoch 47/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3870 - accuracy: 0.8146 - val_loss: 0.5864 - val_accuracy: 0.7432\n",
            "Epoch 48/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3857 - accuracy: 0.8242 - val_loss: 0.5914 - val_accuracy: 0.7349\n",
            "Epoch 49/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3760 - accuracy: 0.8360 - val_loss: 0.5828 - val_accuracy: 0.7432\n",
            "Epoch 50/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3969 - accuracy: 0.8223 - val_loss: 0.5394 - val_accuracy: 0.7683\n",
            "Epoch 51/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3737 - accuracy: 0.8316 - val_loss: 0.5861 - val_accuracy: 0.7557\n",
            "Epoch 52/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3959 - accuracy: 0.8112 - val_loss: 0.5891 - val_accuracy: 0.7599\n",
            "Epoch 53/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3805 - accuracy: 0.8351 - val_loss: 0.6489 - val_accuracy: 0.7495\n",
            "Epoch 54/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.4112 - accuracy: 0.7993 - val_loss: 0.6153 - val_accuracy: 0.7578\n",
            "Epoch 55/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.4010 - accuracy: 0.8163 - val_loss: 0.5798 - val_accuracy: 0.7453\n",
            "Epoch 56/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3753 - accuracy: 0.8151 - val_loss: 0.5879 - val_accuracy: 0.7578\n",
            "Epoch 57/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3722 - accuracy: 0.8199 - val_loss: 0.5787 - val_accuracy: 0.7662\n",
            "Epoch 58/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3843 - accuracy: 0.8357 - val_loss: 0.5767 - val_accuracy: 0.7662\n",
            "Epoch 59/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3830 - accuracy: 0.8184 - val_loss: 0.8116 - val_accuracy: 0.7432\n",
            "Epoch 60/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.4237 - accuracy: 0.8257 - val_loss: 0.5743 - val_accuracy: 0.7474\n",
            "Epoch 61/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3681 - accuracy: 0.8253 - val_loss: 0.6815 - val_accuracy: 0.7119\n",
            "Epoch 62/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3739 - accuracy: 0.8344 - val_loss: 0.6629 - val_accuracy: 0.7599\n",
            "Epoch 63/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3661 - accuracy: 0.8391 - val_loss: 0.6345 - val_accuracy: 0.7265\n",
            "Epoch 64/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3464 - accuracy: 0.8403 - val_loss: 0.6143 - val_accuracy: 0.7557\n",
            "Epoch 65/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3899 - accuracy: 0.8033 - val_loss: 0.8151 - val_accuracy: 0.7704\n",
            "Epoch 66/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3514 - accuracy: 0.8562 - val_loss: 0.6053 - val_accuracy: 0.7724\n",
            "Epoch 67/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3461 - accuracy: 0.8528 - val_loss: 0.7845 - val_accuracy: 0.7704\n",
            "Epoch 68/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3432 - accuracy: 0.8486 - val_loss: 0.5876 - val_accuracy: 0.7557\n",
            "Epoch 69/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3749 - accuracy: 0.8256 - val_loss: 0.8492 - val_accuracy: 0.7724\n",
            "Epoch 70/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3631 - accuracy: 0.8563 - val_loss: 0.7567 - val_accuracy: 0.7411\n",
            "Epoch 71/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3676 - accuracy: 0.8463 - val_loss: 0.9063 - val_accuracy: 0.7203\n",
            "Epoch 72/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3895 - accuracy: 0.8284 - val_loss: 0.9112 - val_accuracy: 0.7557\n",
            "Epoch 73/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.4077 - accuracy: 0.8408 - val_loss: 0.5865 - val_accuracy: 0.7474\n",
            "Epoch 74/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3836 - accuracy: 0.8255 - val_loss: 0.7309 - val_accuracy: 0.6785\n",
            "Epoch 75/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3685 - accuracy: 0.8217 - val_loss: 0.6451 - val_accuracy: 0.7599\n",
            "Epoch 76/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3514 - accuracy: 0.8462 - val_loss: 0.7389 - val_accuracy: 0.7390\n",
            "Epoch 77/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3285 - accuracy: 0.8662 - val_loss: 0.9203 - val_accuracy: 0.7683\n",
            "Epoch 78/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3406 - accuracy: 0.8592 - val_loss: 0.7076 - val_accuracy: 0.7411\n",
            "Epoch 79/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3378 - accuracy: 0.8605 - val_loss: 0.7184 - val_accuracy: 0.7453\n",
            "Epoch 80/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3502 - accuracy: 0.8433 - val_loss: 0.7067 - val_accuracy: 0.7516\n",
            "Epoch 81/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3451 - accuracy: 0.8415 - val_loss: 0.6866 - val_accuracy: 0.7516\n",
            "Epoch 82/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3548 - accuracy: 0.8408 - val_loss: 0.8813 - val_accuracy: 0.7432\n",
            "Epoch 83/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3437 - accuracy: 0.8488 - val_loss: 0.8593 - val_accuracy: 0.7265\n",
            "Epoch 84/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3433 - accuracy: 0.8336 - val_loss: 0.7294 - val_accuracy: 0.7516\n",
            "Epoch 85/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3567 - accuracy: 0.8337 - val_loss: 0.6871 - val_accuracy: 0.7578\n",
            "Epoch 86/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3101 - accuracy: 0.8584 - val_loss: 0.6975 - val_accuracy: 0.7119\n",
            "Epoch 87/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3354 - accuracy: 0.8529 - val_loss: 0.8567 - val_accuracy: 0.7349\n",
            "Epoch 88/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3569 - accuracy: 0.8423 - val_loss: 0.8724 - val_accuracy: 0.7390\n",
            "Epoch 89/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3705 - accuracy: 0.8424 - val_loss: 0.8440 - val_accuracy: 0.7537\n",
            "Epoch 90/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3778 - accuracy: 0.8705 - val_loss: 0.8523 - val_accuracy: 0.7474\n",
            "Epoch 91/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3330 - accuracy: 0.8391 - val_loss: 0.8640 - val_accuracy: 0.7349\n",
            "Epoch 92/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3369 - accuracy: 0.8721 - val_loss: 0.7535 - val_accuracy: 0.7557\n",
            "Epoch 93/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3223 - accuracy: 0.8574 - val_loss: 0.8418 - val_accuracy: 0.7390\n",
            "Epoch 94/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.8590 - val_loss: 0.7414 - val_accuracy: 0.7557\n",
            "Epoch 95/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3129 - accuracy: 0.8564 - val_loss: 0.8975 - val_accuracy: 0.7495\n",
            "Epoch 96/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3212 - accuracy: 0.8693 - val_loss: 0.7050 - val_accuracy: 0.7411\n",
            "Epoch 97/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3116 - accuracy: 0.8562 - val_loss: 0.8247 - val_accuracy: 0.7474\n",
            "Epoch 98/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.5383 - accuracy: 0.8545 - val_loss: 0.6519 - val_accuracy: 0.7537\n",
            "Epoch 99/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3147 - accuracy: 0.8662 - val_loss: 0.8409 - val_accuracy: 0.7599\n",
            "Epoch 100/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3141 - accuracy: 0.8701 - val_loss: 0.8159 - val_accuracy: 0.7724\n",
            "Epoch 101/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3074 - accuracy: 0.8677 - val_loss: 0.8019 - val_accuracy: 0.7474\n",
            "Epoch 102/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3292 - accuracy: 0.8602 - val_loss: 0.8892 - val_accuracy: 0.7370\n",
            "Epoch 103/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3275 - accuracy: 0.8506 - val_loss: 0.8103 - val_accuracy: 0.7578\n",
            "Epoch 104/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3595 - accuracy: 0.8551 - val_loss: 0.7004 - val_accuracy: 0.7662\n",
            "Epoch 105/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3081 - accuracy: 0.8738 - val_loss: 0.7730 - val_accuracy: 0.7620\n",
            "Epoch 106/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3493 - accuracy: 0.8553 - val_loss: 0.7618 - val_accuracy: 0.7286\n",
            "Epoch 107/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2920 - accuracy: 0.8785 - val_loss: 0.7614 - val_accuracy: 0.7474\n",
            "Epoch 108/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3201 - accuracy: 0.8687 - val_loss: 0.7826 - val_accuracy: 0.7599\n",
            "Epoch 109/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3084 - accuracy: 0.8688 - val_loss: 0.8068 - val_accuracy: 0.7516\n",
            "Epoch 110/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3255 - accuracy: 0.8750 - val_loss: 0.6809 - val_accuracy: 0.7704\n",
            "Epoch 111/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3350 - accuracy: 0.8754 - val_loss: 0.8603 - val_accuracy: 0.7537\n",
            "Epoch 112/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3126 - accuracy: 0.8783 - val_loss: 0.9135 - val_accuracy: 0.7641\n",
            "Epoch 113/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2964 - accuracy: 0.8757 - val_loss: 0.8398 - val_accuracy: 0.7453\n",
            "Epoch 114/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3225 - accuracy: 0.8730 - val_loss: 0.8307 - val_accuracy: 0.7578\n",
            "Epoch 115/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2885 - accuracy: 0.8720 - val_loss: 0.9958 - val_accuracy: 0.7620\n",
            "Epoch 116/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2948 - accuracy: 0.8762 - val_loss: 0.7737 - val_accuracy: 0.7119\n",
            "Epoch 117/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3152 - accuracy: 0.8742 - val_loss: 0.9215 - val_accuracy: 0.7578\n",
            "Epoch 118/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3218 - accuracy: 0.8582 - val_loss: 0.9185 - val_accuracy: 0.7349\n",
            "Epoch 119/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2981 - accuracy: 0.8703 - val_loss: 1.1704 - val_accuracy: 0.7328\n",
            "Epoch 120/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2898 - accuracy: 0.8758 - val_loss: 0.8190 - val_accuracy: 0.7411\n",
            "Epoch 121/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3155 - accuracy: 0.8601 - val_loss: 1.2085 - val_accuracy: 0.7432\n",
            "Epoch 122/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2792 - accuracy: 0.8834 - val_loss: 1.0755 - val_accuracy: 0.7537\n",
            "Epoch 123/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2843 - accuracy: 0.8855 - val_loss: 0.7931 - val_accuracy: 0.7516\n",
            "Epoch 124/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3043 - accuracy: 0.8698 - val_loss: 1.1432 - val_accuracy: 0.6952\n",
            "Epoch 125/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3830 - accuracy: 0.8881 - val_loss: 0.8434 - val_accuracy: 0.7557\n",
            "Epoch 126/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2550 - accuracy: 0.8961 - val_loss: 0.9441 - val_accuracy: 0.7516\n",
            "Epoch 127/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2709 - accuracy: 0.8827 - val_loss: 0.9408 - val_accuracy: 0.7182\n",
            "Epoch 128/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2753 - accuracy: 0.8913 - val_loss: 0.8444 - val_accuracy: 0.7223\n",
            "Epoch 129/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2724 - accuracy: 0.8926 - val_loss: 0.9421 - val_accuracy: 0.7390\n",
            "Epoch 130/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2898 - accuracy: 0.8855 - val_loss: 0.9194 - val_accuracy: 0.7557\n",
            "Epoch 131/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2653 - accuracy: 0.8920 - val_loss: 0.9600 - val_accuracy: 0.7683\n",
            "Epoch 132/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2867 - accuracy: 0.8879 - val_loss: 0.8105 - val_accuracy: 0.7537\n",
            "Epoch 133/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2831 - accuracy: 0.8813 - val_loss: 1.0225 - val_accuracy: 0.7578\n",
            "Epoch 134/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2736 - accuracy: 0.8852 - val_loss: 1.1631 - val_accuracy: 0.7537\n",
            "Epoch 135/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2915 - accuracy: 0.8768 - val_loss: 1.0251 - val_accuracy: 0.7557\n",
            "Epoch 136/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2794 - accuracy: 0.8762 - val_loss: 1.1182 - val_accuracy: 0.7495\n",
            "Epoch 137/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2927 - accuracy: 0.8946 - val_loss: 1.3550 - val_accuracy: 0.7307\n",
            "Epoch 138/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3209 - accuracy: 0.8542 - val_loss: 0.8484 - val_accuracy: 0.7599\n",
            "Epoch 139/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2677 - accuracy: 0.8714 - val_loss: 1.4120 - val_accuracy: 0.7724\n",
            "Epoch 140/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3579 - accuracy: 0.8803 - val_loss: 0.9872 - val_accuracy: 0.7349\n",
            "Epoch 141/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2994 - accuracy: 0.8793 - val_loss: 0.9171 - val_accuracy: 0.7620\n",
            "Epoch 142/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2693 - accuracy: 0.8832 - val_loss: 0.9334 - val_accuracy: 0.7411\n",
            "Epoch 143/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2878 - accuracy: 0.8802 - val_loss: 1.1632 - val_accuracy: 0.7704\n",
            "Epoch 144/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2505 - accuracy: 0.8857 - val_loss: 1.7371 - val_accuracy: 0.7328\n",
            "Epoch 145/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3203 - accuracy: 0.8784 - val_loss: 1.0146 - val_accuracy: 0.7641\n",
            "Epoch 146/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2424 - accuracy: 0.8961 - val_loss: 0.9123 - val_accuracy: 0.7683\n",
            "Epoch 147/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2895 - accuracy: 0.8629 - val_loss: 1.2721 - val_accuracy: 0.7578\n",
            "Epoch 148/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2803 - accuracy: 0.8797 - val_loss: 1.0236 - val_accuracy: 0.7578\n",
            "Epoch 149/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3031 - accuracy: 0.8855 - val_loss: 1.0228 - val_accuracy: 0.7432\n",
            "Epoch 150/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2559 - accuracy: 0.9035 - val_loss: 0.9072 - val_accuracy: 0.7328\n",
            "Epoch 151/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2737 - accuracy: 0.8851 - val_loss: 0.9432 - val_accuracy: 0.7035\n",
            "Epoch 152/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2940 - accuracy: 0.8583 - val_loss: 1.2787 - val_accuracy: 0.7328\n",
            "Epoch 153/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2660 - accuracy: 0.8876 - val_loss: 1.0926 - val_accuracy: 0.7161\n",
            "Epoch 154/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2644 - accuracy: 0.8915 - val_loss: 0.8697 - val_accuracy: 0.7432\n",
            "Epoch 155/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2560 - accuracy: 0.8872 - val_loss: 1.6716 - val_accuracy: 0.7537\n",
            "Epoch 156/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2911 - accuracy: 0.8722 - val_loss: 1.2802 - val_accuracy: 0.7411\n",
            "Epoch 157/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2317 - accuracy: 0.9186 - val_loss: 1.7122 - val_accuracy: 0.7286\n",
            "Epoch 158/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2825 - accuracy: 0.8836 - val_loss: 1.2810 - val_accuracy: 0.7516\n",
            "Epoch 159/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2691 - accuracy: 0.8972 - val_loss: 1.4854 - val_accuracy: 0.7516\n",
            "Epoch 160/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3391 - accuracy: 0.8871 - val_loss: 1.3467 - val_accuracy: 0.7370\n",
            "Epoch 161/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2719 - accuracy: 0.8879 - val_loss: 1.9026 - val_accuracy: 0.7077\n",
            "Epoch 162/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3154 - accuracy: 0.8932 - val_loss: 1.2353 - val_accuracy: 0.7203\n",
            "Epoch 163/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2643 - accuracy: 0.8871 - val_loss: 1.4263 - val_accuracy: 0.7557\n",
            "Epoch 164/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2742 - accuracy: 0.8859 - val_loss: 1.3038 - val_accuracy: 0.7203\n",
            "Epoch 165/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2668 - accuracy: 0.8901 - val_loss: 1.5252 - val_accuracy: 0.7662\n",
            "Epoch 166/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2359 - accuracy: 0.9127 - val_loss: 1.3607 - val_accuracy: 0.7474\n",
            "Epoch 167/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2245 - accuracy: 0.9076 - val_loss: 1.4213 - val_accuracy: 0.7203\n",
            "Epoch 168/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2574 - accuracy: 0.8968 - val_loss: 1.1742 - val_accuracy: 0.7620\n",
            "Epoch 169/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2524 - accuracy: 0.8967 - val_loss: 1.4690 - val_accuracy: 0.7182\n",
            "Epoch 170/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2886 - accuracy: 0.9059 - val_loss: 1.4956 - val_accuracy: 0.7495\n",
            "Epoch 171/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2812 - accuracy: 0.8984 - val_loss: 0.9632 - val_accuracy: 0.7411\n",
            "Epoch 172/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2600 - accuracy: 0.9050 - val_loss: 1.2788 - val_accuracy: 0.7641\n",
            "Epoch 173/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2521 - accuracy: 0.8986 - val_loss: 1.5563 - val_accuracy: 0.7390\n",
            "Epoch 174/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2348 - accuracy: 0.8980 - val_loss: 1.3991 - val_accuracy: 0.7662\n",
            "Epoch 175/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2151 - accuracy: 0.9235 - val_loss: 1.0347 - val_accuracy: 0.7265\n",
            "Epoch 176/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2566 - accuracy: 0.8834 - val_loss: 1.5459 - val_accuracy: 0.7495\n",
            "Epoch 177/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2901 - accuracy: 0.8985 - val_loss: 1.1563 - val_accuracy: 0.7495\n",
            "Epoch 178/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2480 - accuracy: 0.9075 - val_loss: 1.2419 - val_accuracy: 0.7599\n",
            "Epoch 179/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2295 - accuracy: 0.9117 - val_loss: 1.2741 - val_accuracy: 0.7244\n",
            "Epoch 180/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2259 - accuracy: 0.9043 - val_loss: 1.7629 - val_accuracy: 0.7641\n",
            "Epoch 181/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2766 - accuracy: 0.9063 - val_loss: 1.2983 - val_accuracy: 0.7432\n",
            "Epoch 182/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2578 - accuracy: 0.8994 - val_loss: 1.9227 - val_accuracy: 0.7495\n",
            "Epoch 183/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2493 - accuracy: 0.9006 - val_loss: 1.0804 - val_accuracy: 0.7578\n",
            "Epoch 184/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2193 - accuracy: 0.9019 - val_loss: 1.2062 - val_accuracy: 0.7432\n",
            "Epoch 185/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2593 - accuracy: 0.8848 - val_loss: 2.4522 - val_accuracy: 0.7557\n",
            "Epoch 186/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2741 - accuracy: 0.8951 - val_loss: 2.2092 - val_accuracy: 0.7557\n",
            "Epoch 187/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2620 - accuracy: 0.8905 - val_loss: 1.7345 - val_accuracy: 0.7766\n",
            "Epoch 188/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2596 - accuracy: 0.9082 - val_loss: 2.5103 - val_accuracy: 0.7349\n",
            "Epoch 189/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3078 - accuracy: 0.8742 - val_loss: 1.2705 - val_accuracy: 0.7495\n",
            "Epoch 190/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2385 - accuracy: 0.8986 - val_loss: 1.4433 - val_accuracy: 0.7537\n",
            "Epoch 191/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2511 - accuracy: 0.9007 - val_loss: 1.8508 - val_accuracy: 0.7766\n",
            "Epoch 192/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2635 - accuracy: 0.9008 - val_loss: 1.7448 - val_accuracy: 0.7161\n",
            "Epoch 193/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2433 - accuracy: 0.8917 - val_loss: 1.3713 - val_accuracy: 0.7411\n",
            "Epoch 194/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3132 - accuracy: 0.9097 - val_loss: 1.5877 - val_accuracy: 0.7578\n",
            "Epoch 195/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2018 - accuracy: 0.9215 - val_loss: 2.7110 - val_accuracy: 0.7662\n",
            "Epoch 196/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2654 - accuracy: 0.8951 - val_loss: 2.3265 - val_accuracy: 0.7724\n",
            "Epoch 197/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2523 - accuracy: 0.9027 - val_loss: 1.5601 - val_accuracy: 0.7432\n",
            "Epoch 198/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2441 - accuracy: 0.8984 - val_loss: 1.3247 - val_accuracy: 0.7432\n",
            "Epoch 199/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2420 - accuracy: 0.8941 - val_loss: 1.8144 - val_accuracy: 0.7662\n",
            "Epoch 200/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3200 - accuracy: 0.8910 - val_loss: 1.9523 - val_accuracy: 0.7641\n",
            "Epoch 201/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2064 - accuracy: 0.9155 - val_loss: 1.9122 - val_accuracy: 0.7453\n",
            "Epoch 202/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2445 - accuracy: 0.9147 - val_loss: 2.1199 - val_accuracy: 0.7557\n",
            "Epoch 203/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2412 - accuracy: 0.9074 - val_loss: 1.3355 - val_accuracy: 0.7390\n",
            "Epoch 204/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.1974 - accuracy: 0.9173 - val_loss: 2.0715 - val_accuracy: 0.7620\n",
            "Epoch 205/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2509 - accuracy: 0.9057 - val_loss: 2.2062 - val_accuracy: 0.7265\n",
            "Epoch 206/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2474 - accuracy: 0.9011 - val_loss: 1.8735 - val_accuracy: 0.7557\n",
            "Epoch 207/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2270 - accuracy: 0.9172 - val_loss: 2.8656 - val_accuracy: 0.7704\n",
            "Epoch 208/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2407 - accuracy: 0.8971 - val_loss: 3.2514 - val_accuracy: 0.7620\n",
            "Epoch 209/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2705 - accuracy: 0.9013 - val_loss: 1.8431 - val_accuracy: 0.7474\n",
            "Epoch 210/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2572 - accuracy: 0.9056 - val_loss: 1.7450 - val_accuracy: 0.7599\n",
            "Epoch 211/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2175 - accuracy: 0.9075 - val_loss: 2.5746 - val_accuracy: 0.7620\n",
            "Epoch 212/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2332 - accuracy: 0.9034 - val_loss: 1.6002 - val_accuracy: 0.7578\n",
            "Epoch 213/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2356 - accuracy: 0.8993 - val_loss: 3.7430 - val_accuracy: 0.7265\n",
            "Epoch 214/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2539 - accuracy: 0.8868 - val_loss: 1.7109 - val_accuracy: 0.7516\n",
            "Epoch 215/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2297 - accuracy: 0.9075 - val_loss: 2.4810 - val_accuracy: 0.7578\n",
            "Epoch 216/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2855 - accuracy: 0.9044 - val_loss: 1.6923 - val_accuracy: 0.7578\n",
            "Epoch 217/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2651 - accuracy: 0.9216 - val_loss: 2.2326 - val_accuracy: 0.7662\n",
            "Epoch 218/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2113 - accuracy: 0.9144 - val_loss: 2.5611 - val_accuracy: 0.7704\n",
            "Epoch 219/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2695 - accuracy: 0.9092 - val_loss: 2.9726 - val_accuracy: 0.7724\n",
            "Epoch 220/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2150 - accuracy: 0.9209 - val_loss: 3.6218 - val_accuracy: 0.7620\n",
            "Epoch 221/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.9632 - accuracy: 0.9083 - val_loss: 3.2930 - val_accuracy: 0.7766\n",
            "Epoch 222/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3036 - accuracy: 0.9096 - val_loss: 2.4327 - val_accuracy: 0.7766\n",
            "Epoch 223/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2660 - accuracy: 0.9059 - val_loss: 4.8660 - val_accuracy: 0.7829\n",
            "Epoch 224/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3528 - accuracy: 0.8796 - val_loss: 6.3458 - val_accuracy: 0.7620\n",
            "Epoch 225/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3344 - accuracy: 0.8942 - val_loss: 3.3451 - val_accuracy: 0.7390\n",
            "Epoch 226/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2294 - accuracy: 0.9076 - val_loss: 3.4259 - val_accuracy: 0.7370\n",
            "Epoch 227/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2234 - accuracy: 0.9145 - val_loss: 5.0171 - val_accuracy: 0.7683\n",
            "Epoch 228/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2440 - accuracy: 0.8996 - val_loss: 4.3659 - val_accuracy: 0.7495\n",
            "Epoch 229/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2665 - accuracy: 0.9113 - val_loss: 3.1368 - val_accuracy: 0.7432\n",
            "Epoch 230/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2117 - accuracy: 0.9031 - val_loss: 4.3067 - val_accuracy: 0.7745\n",
            "Epoch 231/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2867 - accuracy: 0.9126 - val_loss: 2.8058 - val_accuracy: 0.7390\n",
            "Epoch 232/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2463 - accuracy: 0.9008 - val_loss: 2.4915 - val_accuracy: 0.7578\n",
            "Epoch 233/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2097 - accuracy: 0.9246 - val_loss: 1.9107 - val_accuracy: 0.7286\n",
            "Epoch 234/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2373 - accuracy: 0.9100 - val_loss: 2.0325 - val_accuracy: 0.7370\n",
            "Epoch 235/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2675 - accuracy: 0.9071 - val_loss: 4.2677 - val_accuracy: 0.7098\n",
            "Epoch 236/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2441 - accuracy: 0.9115 - val_loss: 1.5901 - val_accuracy: 0.7244\n",
            "Epoch 237/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2024 - accuracy: 0.9179 - val_loss: 1.7061 - val_accuracy: 0.7244\n",
            "Epoch 238/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2446 - accuracy: 0.9118 - val_loss: 4.4156 - val_accuracy: 0.7557\n",
            "Epoch 239/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2210 - accuracy: 0.9207 - val_loss: 3.7406 - val_accuracy: 0.7516\n",
            "Epoch 240/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2879 - accuracy: 0.9183 - val_loss: 3.6286 - val_accuracy: 0.7516\n",
            "Epoch 241/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.4152 - accuracy: 0.9174 - val_loss: 2.5160 - val_accuracy: 0.7035\n",
            "Epoch 242/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2409 - accuracy: 0.9117 - val_loss: 4.8586 - val_accuracy: 0.7850\n",
            "Epoch 243/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2963 - accuracy: 0.8761 - val_loss: 3.9241 - val_accuracy: 0.7453\n",
            "Epoch 244/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2829 - accuracy: 0.9062 - val_loss: 4.5126 - val_accuracy: 0.7140\n",
            "Epoch 245/256\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.2425 - accuracy: 0.9025 - val_loss: 4.5356 - val_accuracy: 0.7390\n",
            "Epoch 246/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.6662 - accuracy: 0.9093 - val_loss: 3.4100 - val_accuracy: 0.7516\n",
            "Epoch 247/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2077 - accuracy: 0.9248 - val_loss: 3.0565 - val_accuracy: 0.7537\n",
            "Epoch 248/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2705 - accuracy: 0.9177 - val_loss: 3.7221 - val_accuracy: 0.7390\n",
            "Epoch 249/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.1721 - accuracy: 0.9245 - val_loss: 4.7607 - val_accuracy: 0.7641\n",
            "Epoch 250/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2602 - accuracy: 0.9044 - val_loss: 3.4570 - val_accuracy: 0.7495\n",
            "Epoch 251/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2736 - accuracy: 0.8851 - val_loss: 2.1530 - val_accuracy: 0.6848\n",
            "Epoch 252/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2862 - accuracy: 0.8735 - val_loss: 4.2257 - val_accuracy: 0.7620\n",
            "Epoch 253/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.4476 - accuracy: 0.9232 - val_loss: 3.6875 - val_accuracy: 0.7453\n",
            "Epoch 254/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2253 - accuracy: 0.9109 - val_loss: 3.0651 - val_accuracy: 0.7662\n",
            "Epoch 255/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2315 - accuracy: 0.9114 - val_loss: 3.0117 - val_accuracy: 0.7557\n",
            "Epoch 256/256\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.1881 - accuracy: 0.9295 - val_loss: 2.5533 - val_accuracy: 0.7724\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "cc8aIHHdRqGM",
        "outputId": "7b6a9f1b-f542-44a3-d650-d95ddd430db0"
      },
      "source": [
        "plt.plot(history_3.history['accuracy'])\n",
        "plt.plot(history_3.history['val_accuracy'])\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training data', 'validation data'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "YZVrD08DRya1",
        "outputId": "826535b3-9e54-470e-f445-28497a979a51"
      },
      "source": [
        "plt.plot(history_3.history['loss'])\n",
        "plt.plot(history_3.history['val_loss'])\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training data', 'validation data'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtbfcCiyR8AE",
        "outputId": "e94da17b-0159-41da-8575-55f87ccb40fd"
      },
      "source": [
        "P3 = model_3.predict(XTRAIN)\n",
        "accuracy_train = model_3.evaluate(XTRAIN, YTRAIN)\n",
        "\n",
        "print(accuracy_train)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1577 - accuracy: 0.9330\n",
            "[0.15766297280788422, 0.9330357313156128]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "818fM6e4R14g",
        "outputId": "5404deb8-d174-4e0c-967e-feb6defb5789"
      },
      "source": [
        "P3 = model_3.predict(XVALID)\n",
        "accuracy_valid = model_3.evaluate(XVALID, YVALID)\n",
        "\n",
        "print(accuracy_valid)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15/15 [==============================] - 0s 1ms/step - loss: 2.5533 - accuracy: 0.7724\n",
            "[2.553287982940674, 0.7724425792694092]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wiuzjrmCZU7"
      },
      "source": [
        "model_4 = Sequential()\n",
        "model_4.add(Dense(1, input_dim = len(XTRAIN[0, :]), activation='linear'))\n",
        "model_4.compile(loss='binary_crossentropy', optimizer = 'rmsprop', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxY_kzd6YXml",
        "outputId": "6bf15bf9-bdbb-4be4-9306-d06e068f2cf2"
      },
      "source": [
        "history_4 = model_4.fit(XTRAIN, YTRAIN, validation_data=(XVALID, YVALID), epochs = 100, batch_size=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "112/112 [==============================] - 1s 3ms/step - loss: 3.9768 - accuracy: 0.4674 - val_loss: 2.9563 - val_accuracy: 0.4551\n",
            "Epoch 2/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 2.1341 - accuracy: 0.4959 - val_loss: 1.5512 - val_accuracy: 0.4489\n",
            "Epoch 3/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 1.3779 - accuracy: 0.4953 - val_loss: 1.3574 - val_accuracy: 0.4572\n",
            "Epoch 4/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 1.2580 - accuracy: 0.5109 - val_loss: 1.2323 - val_accuracy: 0.4718\n",
            "Epoch 5/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 1.0804 - accuracy: 0.4950 - val_loss: 1.1738 - val_accuracy: 0.4676\n",
            "Epoch 6/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 1.0455 - accuracy: 0.5321 - val_loss: 1.1013 - val_accuracy: 0.4885\n",
            "Epoch 7/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 1.0139 - accuracy: 0.5239 - val_loss: 1.0484 - val_accuracy: 0.4885\n",
            "Epoch 8/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.9213 - accuracy: 0.5531 - val_loss: 0.9980 - val_accuracy: 0.5115\n",
            "Epoch 9/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.8664 - accuracy: 0.5598 - val_loss: 0.9741 - val_accuracy: 0.5282\n",
            "Epoch 10/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.7988 - accuracy: 0.5850 - val_loss: 0.8842 - val_accuracy: 0.5240\n",
            "Epoch 11/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.7945 - accuracy: 0.5787 - val_loss: 0.8670 - val_accuracy: 0.5428\n",
            "Epoch 12/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.7737 - accuracy: 0.5798 - val_loss: 0.7835 - val_accuracy: 0.5595\n",
            "Epoch 13/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.7195 - accuracy: 0.6037 - val_loss: 0.7369 - val_accuracy: 0.5741\n",
            "Epoch 14/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6942 - accuracy: 0.6338 - val_loss: 0.7249 - val_accuracy: 0.5783\n",
            "Epoch 15/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6644 - accuracy: 0.6249 - val_loss: 0.7093 - val_accuracy: 0.5846\n",
            "Epoch 16/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6907 - accuracy: 0.6247 - val_loss: 0.6979 - val_accuracy: 0.5908\n",
            "Epoch 17/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6852 - accuracy: 0.6451 - val_loss: 0.6872 - val_accuracy: 0.6138\n",
            "Epoch 18/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6483 - accuracy: 0.6598 - val_loss: 0.6760 - val_accuracy: 0.6180\n",
            "Epoch 19/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6678 - accuracy: 0.6506 - val_loss: 0.6687 - val_accuracy: 0.6180\n",
            "Epoch 20/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6795 - accuracy: 0.6860 - val_loss: 0.6613 - val_accuracy: 0.6263\n",
            "Epoch 21/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6365 - accuracy: 0.6712 - val_loss: 0.6543 - val_accuracy: 0.6347\n",
            "Epoch 22/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6453 - accuracy: 0.6814 - val_loss: 0.6501 - val_accuracy: 0.6388\n",
            "Epoch 23/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6078 - accuracy: 0.6836 - val_loss: 0.6474 - val_accuracy: 0.6409\n",
            "Epoch 24/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6506 - accuracy: 0.6844 - val_loss: 0.6423 - val_accuracy: 0.6451\n",
            "Epoch 25/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6201 - accuracy: 0.6915 - val_loss: 0.6370 - val_accuracy: 0.6534\n",
            "Epoch 26/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6220 - accuracy: 0.6479 - val_loss: 0.6329 - val_accuracy: 0.6493\n",
            "Epoch 27/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6184 - accuracy: 0.6496 - val_loss: 0.6090 - val_accuracy: 0.6534\n",
            "Epoch 28/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6229 - accuracy: 0.6757 - val_loss: 0.6255 - val_accuracy: 0.6534\n",
            "Epoch 29/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6406 - accuracy: 0.7142 - val_loss: 0.6220 - val_accuracy: 0.6618\n",
            "Epoch 30/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6460 - accuracy: 0.7130 - val_loss: 0.5947 - val_accuracy: 0.6576\n",
            "Epoch 31/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6173 - accuracy: 0.6854 - val_loss: 0.5915 - val_accuracy: 0.6555\n",
            "Epoch 32/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5640 - accuracy: 0.7005 - val_loss: 0.5881 - val_accuracy: 0.6618\n",
            "Epoch 33/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6174 - accuracy: 0.6726 - val_loss: 0.5855 - val_accuracy: 0.6660\n",
            "Epoch 34/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5606 - accuracy: 0.7262 - val_loss: 0.5843 - val_accuracy: 0.6722\n",
            "Epoch 35/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6094 - accuracy: 0.6884 - val_loss: 0.5805 - val_accuracy: 0.6743\n",
            "Epoch 36/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6089 - accuracy: 0.7034 - val_loss: 0.5797 - val_accuracy: 0.6660\n",
            "Epoch 37/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5861 - accuracy: 0.7034 - val_loss: 0.5817 - val_accuracy: 0.6827\n",
            "Epoch 38/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6131 - accuracy: 0.7155 - val_loss: 0.5748 - val_accuracy: 0.6806\n",
            "Epoch 39/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5973 - accuracy: 0.6915 - val_loss: 0.5724 - val_accuracy: 0.6889\n",
            "Epoch 40/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5965 - accuracy: 0.7153 - val_loss: 0.5710 - val_accuracy: 0.6889\n",
            "Epoch 41/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6055 - accuracy: 0.7152 - val_loss: 0.5715 - val_accuracy: 0.6827\n",
            "Epoch 42/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5624 - accuracy: 0.7254 - val_loss: 0.5682 - val_accuracy: 0.6910\n",
            "Epoch 43/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6037 - accuracy: 0.7214 - val_loss: 0.5678 - val_accuracy: 0.6889\n",
            "Epoch 44/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6092 - accuracy: 0.7332 - val_loss: 0.5658 - val_accuracy: 0.6931\n",
            "Epoch 45/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6441 - accuracy: 0.6788 - val_loss: 0.5651 - val_accuracy: 0.6952\n",
            "Epoch 46/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6210 - accuracy: 0.6942 - val_loss: 0.5931 - val_accuracy: 0.7015\n",
            "Epoch 47/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6058 - accuracy: 0.6856 - val_loss: 0.5664 - val_accuracy: 0.7015\n",
            "Epoch 48/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6053 - accuracy: 0.7029 - val_loss: 0.5629 - val_accuracy: 0.6994\n",
            "Epoch 49/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6262 - accuracy: 0.7051 - val_loss: 0.5627 - val_accuracy: 0.7056\n",
            "Epoch 50/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6215 - accuracy: 0.7123 - val_loss: 0.5588 - val_accuracy: 0.7077\n",
            "Epoch 51/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6909 - accuracy: 0.7036 - val_loss: 0.5830 - val_accuracy: 0.7077\n",
            "Epoch 52/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5804 - accuracy: 0.7186 - val_loss: 0.5827 - val_accuracy: 0.7077\n",
            "Epoch 53/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5453 - accuracy: 0.7358 - val_loss: 0.5586 - val_accuracy: 0.7077\n",
            "Epoch 54/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5467 - accuracy: 0.7253 - val_loss: 0.5560 - val_accuracy: 0.7077\n",
            "Epoch 55/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5982 - accuracy: 0.7133 - val_loss: 0.5562 - val_accuracy: 0.7119\n",
            "Epoch 56/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5782 - accuracy: 0.7384 - val_loss: 0.5549 - val_accuracy: 0.7140\n",
            "Epoch 57/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5796 - accuracy: 0.7148 - val_loss: 0.5616 - val_accuracy: 0.7119\n",
            "Epoch 58/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5754 - accuracy: 0.6930 - val_loss: 0.5791 - val_accuracy: 0.7077\n",
            "Epoch 59/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6152 - accuracy: 0.7592 - val_loss: 0.5767 - val_accuracy: 0.7140\n",
            "Epoch 60/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5764 - accuracy: 0.7263 - val_loss: 0.5781 - val_accuracy: 0.7077\n",
            "Epoch 61/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5437 - accuracy: 0.7333 - val_loss: 0.5525 - val_accuracy: 0.7203\n",
            "Epoch 62/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5674 - accuracy: 0.7428 - val_loss: 0.5539 - val_accuracy: 0.7182\n",
            "Epoch 63/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5489 - accuracy: 0.7237 - val_loss: 0.5746 - val_accuracy: 0.7182\n",
            "Epoch 64/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5616 - accuracy: 0.7278 - val_loss: 0.5524 - val_accuracy: 0.7203\n",
            "Epoch 65/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5636 - accuracy: 0.7359 - val_loss: 0.5525 - val_accuracy: 0.7203\n",
            "Epoch 66/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6064 - accuracy: 0.7210 - val_loss: 0.5728 - val_accuracy: 0.7161\n",
            "Epoch 67/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5516 - accuracy: 0.7288 - val_loss: 0.5511 - val_accuracy: 0.7203\n",
            "Epoch 68/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6313 - accuracy: 0.7299 - val_loss: 0.5570 - val_accuracy: 0.7161\n",
            "Epoch 69/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5431 - accuracy: 0.7202 - val_loss: 0.5522 - val_accuracy: 0.7182\n",
            "Epoch 70/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5815 - accuracy: 0.7205 - val_loss: 0.5724 - val_accuracy: 0.7119\n",
            "Epoch 71/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5462 - accuracy: 0.7173 - val_loss: 0.5728 - val_accuracy: 0.7119\n",
            "Epoch 72/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5573 - accuracy: 0.7312 - val_loss: 0.5717 - val_accuracy: 0.7140\n",
            "Epoch 73/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5653 - accuracy: 0.7100 - val_loss: 0.5707 - val_accuracy: 0.7203\n",
            "Epoch 74/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6039 - accuracy: 0.7032 - val_loss: 0.5701 - val_accuracy: 0.7203\n",
            "Epoch 75/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5819 - accuracy: 0.7229 - val_loss: 0.5702 - val_accuracy: 0.7203\n",
            "Epoch 76/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5756 - accuracy: 0.7236 - val_loss: 0.5763 - val_accuracy: 0.7119\n",
            "Epoch 77/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6198 - accuracy: 0.7319 - val_loss: 0.5723 - val_accuracy: 0.7161\n",
            "Epoch 78/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6179 - accuracy: 0.7298 - val_loss: 0.5730 - val_accuracy: 0.7140\n",
            "Epoch 79/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6180 - accuracy: 0.7371 - val_loss: 0.5815 - val_accuracy: 0.7161\n",
            "Epoch 80/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6642 - accuracy: 0.7055 - val_loss: 0.5501 - val_accuracy: 0.7223\n",
            "Epoch 81/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6322 - accuracy: 0.7393 - val_loss: 0.5714 - val_accuracy: 0.7203\n",
            "Epoch 82/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5701 - accuracy: 0.7347 - val_loss: 0.5939 - val_accuracy: 0.7161\n",
            "Epoch 83/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5664 - accuracy: 0.7236 - val_loss: 0.5930 - val_accuracy: 0.7140\n",
            "Epoch 84/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6416 - accuracy: 0.7370 - val_loss: 0.5974 - val_accuracy: 0.7265\n",
            "Epoch 85/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5951 - accuracy: 0.7377 - val_loss: 0.5734 - val_accuracy: 0.7203\n",
            "Epoch 86/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6370 - accuracy: 0.7188 - val_loss: 0.5935 - val_accuracy: 0.7182\n",
            "Epoch 87/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6404 - accuracy: 0.7178 - val_loss: 0.5912 - val_accuracy: 0.7244\n",
            "Epoch 88/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5603 - accuracy: 0.7103 - val_loss: 0.5929 - val_accuracy: 0.7182\n",
            "Epoch 89/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5837 - accuracy: 0.7296 - val_loss: 0.5915 - val_accuracy: 0.7182\n",
            "Epoch 90/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5582 - accuracy: 0.7253 - val_loss: 0.5912 - val_accuracy: 0.7203\n",
            "Epoch 91/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5375 - accuracy: 0.7353 - val_loss: 0.5930 - val_accuracy: 0.7203\n",
            "Epoch 92/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6110 - accuracy: 0.7333 - val_loss: 0.5924 - val_accuracy: 0.7223\n",
            "Epoch 93/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5404 - accuracy: 0.7515 - val_loss: 0.5456 - val_accuracy: 0.7286\n",
            "Epoch 94/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5298 - accuracy: 0.7516 - val_loss: 0.5900 - val_accuracy: 0.7203\n",
            "Epoch 95/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5642 - accuracy: 0.7581 - val_loss: 0.5895 - val_accuracy: 0.7223\n",
            "Epoch 96/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5782 - accuracy: 0.7268 - val_loss: 0.5921 - val_accuracy: 0.7265\n",
            "Epoch 97/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5610 - accuracy: 0.7386 - val_loss: 0.5897 - val_accuracy: 0.7203\n",
            "Epoch 98/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6061 - accuracy: 0.7319 - val_loss: 0.5887 - val_accuracy: 0.7244\n",
            "Epoch 99/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6025 - accuracy: 0.7185 - val_loss: 0.5897 - val_accuracy: 0.7328\n",
            "Epoch 100/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5794 - accuracy: 0.7193 - val_loss: 0.5903 - val_accuracy: 0.7244\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "9e3ZQFaQY6Uz",
        "outputId": "37230c7f-8c62-416b-80a4-2aee8c0c8d19"
      },
      "source": [
        "plt.plot(history_4.history['accuracy'])\n",
        "plt.plot(history_4.history['val_accuracy'])\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training data', 'validation data'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "9QCMujxqZA1F",
        "outputId": "eed65f60-f36d-4f72-9dc2-d46667bf0cd0"
      },
      "source": [
        "plt.plot(history_4.history['loss'])\n",
        "plt.plot(history_4.history['val_loss'])\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training data', 'validation data'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1ylhblxKUIt",
        "outputId": "bdf5c3c0-31a4-4e6d-91c7-81257280cbfd"
      },
      "source": [
        "P4 = model_4.predict(XTRAIN)\n",
        "accuracy_train = model_4.evaluate(XTRAIN, YTRAIN)\n",
        " \n",
        "print(accuracy_train)\n",
        " \n",
        " \n",
        "P4 = model_4.predict(XVALID)\n",
        "accuracy_valid = model_4.evaluate(XVALID, YVALID)\n",
        " \n",
        "print(accuracy_valid)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "35/35 [==============================] - 0s 1ms/step - loss: 0.5557 - accuracy: 0.7491\n",
            "[0.5557336211204529, 0.7491071224212646]\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.5117 - accuracy: 0.7474\n",
            "[0.5117309093475342, 0.7473903894424438]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diItyUDnZa_2"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ebe2cZcacLJ"
      },
      "source": [
        "callback_a = ModelCheckpoint(filepath = \"model_5.hdf5\", monitor='val_loss', save_best_only = True, save_weights_only = True, verbose = 1)\n",
        "callback_b = EarlyStopping(monitor='val_loss', mode='min', patience=50, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPcd43OZdNZh"
      },
      "source": [
        "model_5 = Sequential()\n",
        "model_5.add(Dense(1, input_dim = len(XTRAIN[0, :]), activation='sigmoid'))\n",
        "model_5.compile(loss='binary_crossentropy', optimizer = 'rmsprop', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmqqYXi0aqaj",
        "outputId": "59528903-8d00-4e33-bf1e-5df7192b564a"
      },
      "source": [
        "history_5 = model_5.fit(XTRAIN, YTRAIN, validation_data=(XVALID, YVALID), epochs=1000, batch_size=10, callbacks = [callback_a, callback_b])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "112/112 [==============================] - 1s 3ms/step - loss: 0.6962 - accuracy: 0.4830 - val_loss: 0.6935 - val_accuracy: 0.4802\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.69353, saving model to model_5.hdf5\n",
            "Epoch 2/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6860 - accuracy: 0.5568 - val_loss: 0.6890 - val_accuracy: 0.5219\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.69353 to 0.68901, saving model to model_5.hdf5\n",
            "Epoch 3/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6817 - accuracy: 0.5740 - val_loss: 0.6841 - val_accuracy: 0.5491\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.68901 to 0.68412, saving model to model_5.hdf5\n",
            "Epoch 4/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6853 - accuracy: 0.5488 - val_loss: 0.6798 - val_accuracy: 0.5511\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.68412 to 0.67984, saving model to model_5.hdf5\n",
            "Epoch 5/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6734 - accuracy: 0.5725 - val_loss: 0.6755 - val_accuracy: 0.5574\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.67984 to 0.67549, saving model to model_5.hdf5\n",
            "Epoch 6/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6677 - accuracy: 0.6013 - val_loss: 0.6716 - val_accuracy: 0.5678\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.67549 to 0.67155, saving model to model_5.hdf5\n",
            "Epoch 7/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6592 - accuracy: 0.6182 - val_loss: 0.6679 - val_accuracy: 0.5887\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.67155 to 0.66789, saving model to model_5.hdf5\n",
            "Epoch 8/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6621 - accuracy: 0.6206 - val_loss: 0.6641 - val_accuracy: 0.6096\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.66789 to 0.66409, saving model to model_5.hdf5\n",
            "Epoch 9/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6602 - accuracy: 0.6174 - val_loss: 0.6602 - val_accuracy: 0.6180\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.66409 to 0.66024, saving model to model_5.hdf5\n",
            "Epoch 10/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6528 - accuracy: 0.6528 - val_loss: 0.6565 - val_accuracy: 0.6305\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.66024 to 0.65650, saving model to model_5.hdf5\n",
            "Epoch 11/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6555 - accuracy: 0.6489 - val_loss: 0.6525 - val_accuracy: 0.6514\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.65650 to 0.65251, saving model to model_5.hdf5\n",
            "Epoch 12/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6538 - accuracy: 0.6503 - val_loss: 0.6487 - val_accuracy: 0.6555\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.65251 to 0.64875, saving model to model_5.hdf5\n",
            "Epoch 13/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6464 - accuracy: 0.6551 - val_loss: 0.6456 - val_accuracy: 0.6639\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.64875 to 0.64559, saving model to model_5.hdf5\n",
            "Epoch 14/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6380 - accuracy: 0.6884 - val_loss: 0.6421 - val_accuracy: 0.6722\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.64559 to 0.64212, saving model to model_5.hdf5\n",
            "Epoch 15/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6420 - accuracy: 0.6737 - val_loss: 0.6390 - val_accuracy: 0.6806\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.64212 to 0.63897, saving model to model_5.hdf5\n",
            "Epoch 16/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6279 - accuracy: 0.6921 - val_loss: 0.6356 - val_accuracy: 0.6785\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.63897 to 0.63565, saving model to model_5.hdf5\n",
            "Epoch 17/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6360 - accuracy: 0.6881 - val_loss: 0.6331 - val_accuracy: 0.6806\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.63565 to 0.63306, saving model to model_5.hdf5\n",
            "Epoch 18/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6270 - accuracy: 0.6975 - val_loss: 0.6300 - val_accuracy: 0.6868\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.63306 to 0.63003, saving model to model_5.hdf5\n",
            "Epoch 19/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6282 - accuracy: 0.6945 - val_loss: 0.6273 - val_accuracy: 0.6973\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.63003 to 0.62725, saving model to model_5.hdf5\n",
            "Epoch 20/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6296 - accuracy: 0.6850 - val_loss: 0.6245 - val_accuracy: 0.6994\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.62725 to 0.62448, saving model to model_5.hdf5\n",
            "Epoch 21/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6226 - accuracy: 0.6934 - val_loss: 0.6218 - val_accuracy: 0.7056\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.62448 to 0.62181, saving model to model_5.hdf5\n",
            "Epoch 22/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6190 - accuracy: 0.6997 - val_loss: 0.6195 - val_accuracy: 0.7077\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.62181 to 0.61951, saving model to model_5.hdf5\n",
            "Epoch 23/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6179 - accuracy: 0.7141 - val_loss: 0.6171 - val_accuracy: 0.7119\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.61951 to 0.61713, saving model to model_5.hdf5\n",
            "Epoch 24/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6244 - accuracy: 0.6784 - val_loss: 0.6147 - val_accuracy: 0.7140\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.61713 to 0.61471, saving model to model_5.hdf5\n",
            "Epoch 25/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6104 - accuracy: 0.7139 - val_loss: 0.6122 - val_accuracy: 0.7223\n",
            "\n",
            "Epoch 00025: val_loss improved from 0.61471 to 0.61225, saving model to model_5.hdf5\n",
            "Epoch 26/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6100 - accuracy: 0.7157 - val_loss: 0.6099 - val_accuracy: 0.7161\n",
            "\n",
            "Epoch 00026: val_loss improved from 0.61225 to 0.60995, saving model to model_5.hdf5\n",
            "Epoch 27/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6105 - accuracy: 0.7049 - val_loss: 0.6079 - val_accuracy: 0.7161\n",
            "\n",
            "Epoch 00027: val_loss improved from 0.60995 to 0.60790, saving model to model_5.hdf5\n",
            "Epoch 28/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6043 - accuracy: 0.7199 - val_loss: 0.6058 - val_accuracy: 0.7161\n",
            "\n",
            "Epoch 00028: val_loss improved from 0.60790 to 0.60578, saving model to model_5.hdf5\n",
            "Epoch 29/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6054 - accuracy: 0.7080 - val_loss: 0.6039 - val_accuracy: 0.7161\n",
            "\n",
            "Epoch 00029: val_loss improved from 0.60578 to 0.60393, saving model to model_5.hdf5\n",
            "Epoch 30/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5977 - accuracy: 0.7169 - val_loss: 0.6020 - val_accuracy: 0.7161\n",
            "\n",
            "Epoch 00030: val_loss improved from 0.60393 to 0.60197, saving model to model_5.hdf5\n",
            "Epoch 31/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5947 - accuracy: 0.7345 - val_loss: 0.6002 - val_accuracy: 0.7140\n",
            "\n",
            "Epoch 00031: val_loss improved from 0.60197 to 0.60020, saving model to model_5.hdf5\n",
            "Epoch 32/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5855 - accuracy: 0.7337 - val_loss: 0.5982 - val_accuracy: 0.7119\n",
            "\n",
            "Epoch 00032: val_loss improved from 0.60020 to 0.59819, saving model to model_5.hdf5\n",
            "Epoch 33/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5971 - accuracy: 0.7222 - val_loss: 0.5962 - val_accuracy: 0.7119\n",
            "\n",
            "Epoch 00033: val_loss improved from 0.59819 to 0.59619, saving model to model_5.hdf5\n",
            "Epoch 34/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5948 - accuracy: 0.7280 - val_loss: 0.5943 - val_accuracy: 0.7140\n",
            "\n",
            "Epoch 00034: val_loss improved from 0.59619 to 0.59433, saving model to model_5.hdf5\n",
            "Epoch 35/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5997 - accuracy: 0.6962 - val_loss: 0.5926 - val_accuracy: 0.7140\n",
            "\n",
            "Epoch 00035: val_loss improved from 0.59433 to 0.59256, saving model to model_5.hdf5\n",
            "Epoch 36/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5946 - accuracy: 0.7197 - val_loss: 0.5908 - val_accuracy: 0.7223\n",
            "\n",
            "Epoch 00036: val_loss improved from 0.59256 to 0.59078, saving model to model_5.hdf5\n",
            "Epoch 37/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6029 - accuracy: 0.6917 - val_loss: 0.5893 - val_accuracy: 0.7223\n",
            "\n",
            "Epoch 00037: val_loss improved from 0.59078 to 0.58927, saving model to model_5.hdf5\n",
            "Epoch 38/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5770 - accuracy: 0.7481 - val_loss: 0.5875 - val_accuracy: 0.7265\n",
            "\n",
            "Epoch 00038: val_loss improved from 0.58927 to 0.58747, saving model to model_5.hdf5\n",
            "Epoch 39/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5931 - accuracy: 0.7156 - val_loss: 0.5860 - val_accuracy: 0.7223\n",
            "\n",
            "Epoch 00039: val_loss improved from 0.58747 to 0.58602, saving model to model_5.hdf5\n",
            "Epoch 40/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5763 - accuracy: 0.7426 - val_loss: 0.5845 - val_accuracy: 0.7182\n",
            "\n",
            "Epoch 00040: val_loss improved from 0.58602 to 0.58450, saving model to model_5.hdf5\n",
            "Epoch 41/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5716 - accuracy: 0.7463 - val_loss: 0.5829 - val_accuracy: 0.7223\n",
            "\n",
            "Epoch 00041: val_loss improved from 0.58450 to 0.58294, saving model to model_5.hdf5\n",
            "Epoch 42/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5793 - accuracy: 0.7421 - val_loss: 0.5815 - val_accuracy: 0.7244\n",
            "\n",
            "Epoch 00042: val_loss improved from 0.58294 to 0.58154, saving model to model_5.hdf5\n",
            "Epoch 43/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5692 - accuracy: 0.7676 - val_loss: 0.5801 - val_accuracy: 0.7244\n",
            "\n",
            "Epoch 00043: val_loss improved from 0.58154 to 0.58012, saving model to model_5.hdf5\n",
            "Epoch 44/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5636 - accuracy: 0.7539 - val_loss: 0.5789 - val_accuracy: 0.7223\n",
            "\n",
            "Epoch 00044: val_loss improved from 0.58012 to 0.57891, saving model to model_5.hdf5\n",
            "Epoch 45/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5687 - accuracy: 0.7501 - val_loss: 0.5776 - val_accuracy: 0.7203\n",
            "\n",
            "Epoch 00045: val_loss improved from 0.57891 to 0.57759, saving model to model_5.hdf5\n",
            "Epoch 46/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5780 - accuracy: 0.7348 - val_loss: 0.5763 - val_accuracy: 0.7203\n",
            "\n",
            "Epoch 00046: val_loss improved from 0.57759 to 0.57630, saving model to model_5.hdf5\n",
            "Epoch 47/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5670 - accuracy: 0.7433 - val_loss: 0.5749 - val_accuracy: 0.7161\n",
            "\n",
            "Epoch 00047: val_loss improved from 0.57630 to 0.57493, saving model to model_5.hdf5\n",
            "Epoch 48/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5700 - accuracy: 0.7318 - val_loss: 0.5738 - val_accuracy: 0.7203\n",
            "\n",
            "Epoch 00048: val_loss improved from 0.57493 to 0.57381, saving model to model_5.hdf5\n",
            "Epoch 49/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5674 - accuracy: 0.7318 - val_loss: 0.5726 - val_accuracy: 0.7161\n",
            "\n",
            "Epoch 00049: val_loss improved from 0.57381 to 0.57265, saving model to model_5.hdf5\n",
            "Epoch 50/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5678 - accuracy: 0.7426 - val_loss: 0.5716 - val_accuracy: 0.7223\n",
            "\n",
            "Epoch 00050: val_loss improved from 0.57265 to 0.57163, saving model to model_5.hdf5\n",
            "Epoch 51/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5646 - accuracy: 0.7472 - val_loss: 0.5705 - val_accuracy: 0.7161\n",
            "\n",
            "Epoch 00051: val_loss improved from 0.57163 to 0.57046, saving model to model_5.hdf5\n",
            "Epoch 52/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5736 - accuracy: 0.7295 - val_loss: 0.5694 - val_accuracy: 0.7161\n",
            "\n",
            "Epoch 00052: val_loss improved from 0.57046 to 0.56941, saving model to model_5.hdf5\n",
            "Epoch 53/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5767 - accuracy: 0.7287 - val_loss: 0.5684 - val_accuracy: 0.7161\n",
            "\n",
            "Epoch 00053: val_loss improved from 0.56941 to 0.56840, saving model to model_5.hdf5\n",
            "Epoch 54/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5710 - accuracy: 0.7477 - val_loss: 0.5674 - val_accuracy: 0.7182\n",
            "\n",
            "Epoch 00054: val_loss improved from 0.56840 to 0.56742, saving model to model_5.hdf5\n",
            "Epoch 55/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5636 - accuracy: 0.7351 - val_loss: 0.5663 - val_accuracy: 0.7182\n",
            "\n",
            "Epoch 00055: val_loss improved from 0.56742 to 0.56630, saving model to model_5.hdf5\n",
            "Epoch 56/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5776 - accuracy: 0.7321 - val_loss: 0.5653 - val_accuracy: 0.7140\n",
            "\n",
            "Epoch 00056: val_loss improved from 0.56630 to 0.56534, saving model to model_5.hdf5\n",
            "Epoch 57/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5682 - accuracy: 0.7370 - val_loss: 0.5643 - val_accuracy: 0.7161\n",
            "\n",
            "Epoch 00057: val_loss improved from 0.56534 to 0.56432, saving model to model_5.hdf5\n",
            "Epoch 58/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5690 - accuracy: 0.7205 - val_loss: 0.5633 - val_accuracy: 0.7182\n",
            "\n",
            "Epoch 00058: val_loss improved from 0.56432 to 0.56328, saving model to model_5.hdf5\n",
            "Epoch 59/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5615 - accuracy: 0.7487 - val_loss: 0.5623 - val_accuracy: 0.7182\n",
            "\n",
            "Epoch 00059: val_loss improved from 0.56328 to 0.56234, saving model to model_5.hdf5\n",
            "Epoch 60/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5700 - accuracy: 0.7188 - val_loss: 0.5615 - val_accuracy: 0.7223\n",
            "\n",
            "Epoch 00060: val_loss improved from 0.56234 to 0.56153, saving model to model_5.hdf5\n",
            "Epoch 61/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5682 - accuracy: 0.7323 - val_loss: 0.5607 - val_accuracy: 0.7244\n",
            "\n",
            "Epoch 00061: val_loss improved from 0.56153 to 0.56072, saving model to model_5.hdf5\n",
            "Epoch 62/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5626 - accuracy: 0.7499 - val_loss: 0.5598 - val_accuracy: 0.7286\n",
            "\n",
            "Epoch 00062: val_loss improved from 0.56072 to 0.55983, saving model to model_5.hdf5\n",
            "Epoch 63/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5667 - accuracy: 0.7339 - val_loss: 0.5591 - val_accuracy: 0.7286\n",
            "\n",
            "Epoch 00063: val_loss improved from 0.55983 to 0.55909, saving model to model_5.hdf5\n",
            "Epoch 64/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5493 - accuracy: 0.7426 - val_loss: 0.5583 - val_accuracy: 0.7244\n",
            "\n",
            "Epoch 00064: val_loss improved from 0.55909 to 0.55826, saving model to model_5.hdf5\n",
            "Epoch 65/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5709 - accuracy: 0.7374 - val_loss: 0.5576 - val_accuracy: 0.7265\n",
            "\n",
            "Epoch 00065: val_loss improved from 0.55826 to 0.55755, saving model to model_5.hdf5\n",
            "Epoch 66/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5677 - accuracy: 0.7298 - val_loss: 0.5568 - val_accuracy: 0.7286\n",
            "\n",
            "Epoch 00066: val_loss improved from 0.55755 to 0.55678, saving model to model_5.hdf5\n",
            "Epoch 67/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5500 - accuracy: 0.7181 - val_loss: 0.5560 - val_accuracy: 0.7286\n",
            "\n",
            "Epoch 00067: val_loss improved from 0.55678 to 0.55605, saving model to model_5.hdf5\n",
            "Epoch 68/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5546 - accuracy: 0.7300 - val_loss: 0.5554 - val_accuracy: 0.7265\n",
            "\n",
            "Epoch 00068: val_loss improved from 0.55605 to 0.55542, saving model to model_5.hdf5\n",
            "Epoch 69/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5637 - accuracy: 0.7432 - val_loss: 0.5546 - val_accuracy: 0.7286\n",
            "\n",
            "Epoch 00069: val_loss improved from 0.55542 to 0.55462, saving model to model_5.hdf5\n",
            "Epoch 70/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5542 - accuracy: 0.7458 - val_loss: 0.5539 - val_accuracy: 0.7286\n",
            "\n",
            "Epoch 00070: val_loss improved from 0.55462 to 0.55393, saving model to model_5.hdf5\n",
            "Epoch 71/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5504 - accuracy: 0.7328 - val_loss: 0.5533 - val_accuracy: 0.7349\n",
            "\n",
            "Epoch 00071: val_loss improved from 0.55393 to 0.55327, saving model to model_5.hdf5\n",
            "Epoch 72/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5550 - accuracy: 0.7312 - val_loss: 0.5527 - val_accuracy: 0.7349\n",
            "\n",
            "Epoch 00072: val_loss improved from 0.55327 to 0.55268, saving model to model_5.hdf5\n",
            "Epoch 73/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5511 - accuracy: 0.7439 - val_loss: 0.5522 - val_accuracy: 0.7265\n",
            "\n",
            "Epoch 00073: val_loss improved from 0.55268 to 0.55225, saving model to model_5.hdf5\n",
            "Epoch 74/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5611 - accuracy: 0.7288 - val_loss: 0.5517 - val_accuracy: 0.7286\n",
            "\n",
            "Epoch 00074: val_loss improved from 0.55225 to 0.55173, saving model to model_5.hdf5\n",
            "Epoch 75/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5459 - accuracy: 0.7431 - val_loss: 0.5512 - val_accuracy: 0.7265\n",
            "\n",
            "Epoch 00075: val_loss improved from 0.55173 to 0.55116, saving model to model_5.hdf5\n",
            "Epoch 76/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5772 - accuracy: 0.7051 - val_loss: 0.5505 - val_accuracy: 0.7328\n",
            "\n",
            "Epoch 00076: val_loss improved from 0.55116 to 0.55049, saving model to model_5.hdf5\n",
            "Epoch 77/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5512 - accuracy: 0.7309 - val_loss: 0.5500 - val_accuracy: 0.7307\n",
            "\n",
            "Epoch 00077: val_loss improved from 0.55049 to 0.54998, saving model to model_5.hdf5\n",
            "Epoch 78/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5591 - accuracy: 0.7189 - val_loss: 0.5495 - val_accuracy: 0.7307\n",
            "\n",
            "Epoch 00078: val_loss improved from 0.54998 to 0.54948, saving model to model_5.hdf5\n",
            "Epoch 79/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5370 - accuracy: 0.7466 - val_loss: 0.5489 - val_accuracy: 0.7328\n",
            "\n",
            "Epoch 00079: val_loss improved from 0.54948 to 0.54895, saving model to model_5.hdf5\n",
            "Epoch 80/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5515 - accuracy: 0.7403 - val_loss: 0.5483 - val_accuracy: 0.7328\n",
            "\n",
            "Epoch 00080: val_loss improved from 0.54895 to 0.54835, saving model to model_5.hdf5\n",
            "Epoch 81/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5420 - accuracy: 0.7336 - val_loss: 0.5478 - val_accuracy: 0.7328\n",
            "\n",
            "Epoch 00081: val_loss improved from 0.54835 to 0.54780, saving model to model_5.hdf5\n",
            "Epoch 82/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5470 - accuracy: 0.7374 - val_loss: 0.5473 - val_accuracy: 0.7328\n",
            "\n",
            "Epoch 00082: val_loss improved from 0.54780 to 0.54733, saving model to model_5.hdf5\n",
            "Epoch 83/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5426 - accuracy: 0.7511 - val_loss: 0.5469 - val_accuracy: 0.7307\n",
            "\n",
            "Epoch 00083: val_loss improved from 0.54733 to 0.54688, saving model to model_5.hdf5\n",
            "Epoch 84/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5475 - accuracy: 0.7407 - val_loss: 0.5463 - val_accuracy: 0.7349\n",
            "\n",
            "Epoch 00084: val_loss improved from 0.54688 to 0.54629, saving model to model_5.hdf5\n",
            "Epoch 85/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5584 - accuracy: 0.7305 - val_loss: 0.5458 - val_accuracy: 0.7349\n",
            "\n",
            "Epoch 00085: val_loss improved from 0.54629 to 0.54580, saving model to model_5.hdf5\n",
            "Epoch 86/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5444 - accuracy: 0.7544 - val_loss: 0.5454 - val_accuracy: 0.7349\n",
            "\n",
            "Epoch 00086: val_loss improved from 0.54580 to 0.54542, saving model to model_5.hdf5\n",
            "Epoch 87/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5471 - accuracy: 0.7378 - val_loss: 0.5450 - val_accuracy: 0.7328\n",
            "\n",
            "Epoch 00087: val_loss improved from 0.54542 to 0.54503, saving model to model_5.hdf5\n",
            "Epoch 88/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5408 - accuracy: 0.7436 - val_loss: 0.5445 - val_accuracy: 0.7349\n",
            "\n",
            "Epoch 00088: val_loss improved from 0.54503 to 0.54451, saving model to model_5.hdf5\n",
            "Epoch 89/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5249 - accuracy: 0.7704 - val_loss: 0.5441 - val_accuracy: 0.7349\n",
            "\n",
            "Epoch 00089: val_loss improved from 0.54451 to 0.54409, saving model to model_5.hdf5\n",
            "Epoch 90/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5402 - accuracy: 0.7332 - val_loss: 0.5436 - val_accuracy: 0.7349\n",
            "\n",
            "Epoch 00090: val_loss improved from 0.54409 to 0.54362, saving model to model_5.hdf5\n",
            "Epoch 91/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5604 - accuracy: 0.7125 - val_loss: 0.5432 - val_accuracy: 0.7390\n",
            "\n",
            "Epoch 00091: val_loss improved from 0.54362 to 0.54317, saving model to model_5.hdf5\n",
            "Epoch 92/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5473 - accuracy: 0.7395 - val_loss: 0.5429 - val_accuracy: 0.7349\n",
            "\n",
            "Epoch 00092: val_loss improved from 0.54317 to 0.54288, saving model to model_5.hdf5\n",
            "Epoch 93/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5315 - accuracy: 0.7641 - val_loss: 0.5425 - val_accuracy: 0.7349\n",
            "\n",
            "Epoch 00093: val_loss improved from 0.54288 to 0.54249, saving model to model_5.hdf5\n",
            "Epoch 94/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5527 - accuracy: 0.7245 - val_loss: 0.5421 - val_accuracy: 0.7370\n",
            "\n",
            "Epoch 00094: val_loss improved from 0.54249 to 0.54207, saving model to model_5.hdf5\n",
            "Epoch 95/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5315 - accuracy: 0.7553 - val_loss: 0.5417 - val_accuracy: 0.7370\n",
            "\n",
            "Epoch 00095: val_loss improved from 0.54207 to 0.54173, saving model to model_5.hdf5\n",
            "Epoch 96/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5430 - accuracy: 0.7455 - val_loss: 0.5414 - val_accuracy: 0.7370\n",
            "\n",
            "Epoch 00096: val_loss improved from 0.54173 to 0.54137, saving model to model_5.hdf5\n",
            "Epoch 97/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5327 - accuracy: 0.7464 - val_loss: 0.5410 - val_accuracy: 0.7370\n",
            "\n",
            "Epoch 00097: val_loss improved from 0.54137 to 0.54100, saving model to model_5.hdf5\n",
            "Epoch 98/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5599 - accuracy: 0.7145 - val_loss: 0.5407 - val_accuracy: 0.7370\n",
            "\n",
            "Epoch 00098: val_loss improved from 0.54100 to 0.54065, saving model to model_5.hdf5\n",
            "Epoch 99/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5321 - accuracy: 0.7490 - val_loss: 0.5403 - val_accuracy: 0.7370\n",
            "\n",
            "Epoch 00099: val_loss improved from 0.54065 to 0.54031, saving model to model_5.hdf5\n",
            "Epoch 100/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5358 - accuracy: 0.7283 - val_loss: 0.5400 - val_accuracy: 0.7370\n",
            "\n",
            "Epoch 00100: val_loss improved from 0.54031 to 0.53997, saving model to model_5.hdf5\n",
            "Epoch 101/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5418 - accuracy: 0.7489 - val_loss: 0.5396 - val_accuracy: 0.7370\n",
            "\n",
            "Epoch 00101: val_loss improved from 0.53997 to 0.53960, saving model to model_5.hdf5\n",
            "Epoch 102/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5297 - accuracy: 0.7497 - val_loss: 0.5393 - val_accuracy: 0.7370\n",
            "\n",
            "Epoch 00102: val_loss improved from 0.53960 to 0.53928, saving model to model_5.hdf5\n",
            "Epoch 103/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5312 - accuracy: 0.7512 - val_loss: 0.5391 - val_accuracy: 0.7370\n",
            "\n",
            "Epoch 00103: val_loss improved from 0.53928 to 0.53905, saving model to model_5.hdf5\n",
            "Epoch 104/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5447 - accuracy: 0.7422 - val_loss: 0.5387 - val_accuracy: 0.7370\n",
            "\n",
            "Epoch 00104: val_loss improved from 0.53905 to 0.53871, saving model to model_5.hdf5\n",
            "Epoch 105/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5277 - accuracy: 0.7584 - val_loss: 0.5384 - val_accuracy: 0.7370\n",
            "\n",
            "Epoch 00105: val_loss improved from 0.53871 to 0.53845, saving model to model_5.hdf5\n",
            "Epoch 106/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5276 - accuracy: 0.7463 - val_loss: 0.5382 - val_accuracy: 0.7370\n",
            "\n",
            "Epoch 00106: val_loss improved from 0.53845 to 0.53818, saving model to model_5.hdf5\n",
            "Epoch 107/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5125 - accuracy: 0.7704 - val_loss: 0.5378 - val_accuracy: 0.7370\n",
            "\n",
            "Epoch 00107: val_loss improved from 0.53818 to 0.53784, saving model to model_5.hdf5\n",
            "Epoch 108/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5387 - accuracy: 0.7245 - val_loss: 0.5375 - val_accuracy: 0.7370\n",
            "\n",
            "Epoch 00108: val_loss improved from 0.53784 to 0.53749, saving model to model_5.hdf5\n",
            "Epoch 109/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5287 - accuracy: 0.7412 - val_loss: 0.5371 - val_accuracy: 0.7370\n",
            "\n",
            "Epoch 00109: val_loss improved from 0.53749 to 0.53714, saving model to model_5.hdf5\n",
            "Epoch 110/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5184 - accuracy: 0.7581 - val_loss: 0.5369 - val_accuracy: 0.7370\n",
            "\n",
            "Epoch 00110: val_loss improved from 0.53714 to 0.53691, saving model to model_5.hdf5\n",
            "Epoch 111/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5440 - accuracy: 0.7235 - val_loss: 0.5368 - val_accuracy: 0.7370\n",
            "\n",
            "Epoch 00111: val_loss improved from 0.53691 to 0.53682, saving model to model_5.hdf5\n",
            "Epoch 112/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5362 - accuracy: 0.7409 - val_loss: 0.5364 - val_accuracy: 0.7370\n",
            "\n",
            "Epoch 00112: val_loss improved from 0.53682 to 0.53640, saving model to model_5.hdf5\n",
            "Epoch 113/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5262 - accuracy: 0.7414 - val_loss: 0.5362 - val_accuracy: 0.7370\n",
            "\n",
            "Epoch 00113: val_loss improved from 0.53640 to 0.53623, saving model to model_5.hdf5\n",
            "Epoch 114/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5375 - accuracy: 0.7320 - val_loss: 0.5361 - val_accuracy: 0.7370\n",
            "\n",
            "Epoch 00114: val_loss improved from 0.53623 to 0.53607, saving model to model_5.hdf5\n",
            "Epoch 115/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5347 - accuracy: 0.7339 - val_loss: 0.5358 - val_accuracy: 0.7370\n",
            "\n",
            "Epoch 00115: val_loss improved from 0.53607 to 0.53577, saving model to model_5.hdf5\n",
            "Epoch 116/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5471 - accuracy: 0.7208 - val_loss: 0.5354 - val_accuracy: 0.7370\n",
            "\n",
            "Epoch 00116: val_loss improved from 0.53577 to 0.53544, saving model to model_5.hdf5\n",
            "Epoch 117/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5391 - accuracy: 0.7426 - val_loss: 0.5351 - val_accuracy: 0.7370\n",
            "\n",
            "Epoch 00117: val_loss improved from 0.53544 to 0.53514, saving model to model_5.hdf5\n",
            "Epoch 118/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5468 - accuracy: 0.7293 - val_loss: 0.5349 - val_accuracy: 0.7370\n",
            "\n",
            "Epoch 00118: val_loss improved from 0.53514 to 0.53489, saving model to model_5.hdf5\n",
            "Epoch 119/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5352 - accuracy: 0.7455 - val_loss: 0.5347 - val_accuracy: 0.7328\n",
            "\n",
            "Epoch 00119: val_loss improved from 0.53489 to 0.53470, saving model to model_5.hdf5\n",
            "Epoch 120/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5164 - accuracy: 0.7594 - val_loss: 0.5345 - val_accuracy: 0.7328\n",
            "\n",
            "Epoch 00120: val_loss improved from 0.53470 to 0.53449, saving model to model_5.hdf5\n",
            "Epoch 121/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5377 - accuracy: 0.7526 - val_loss: 0.5342 - val_accuracy: 0.7328\n",
            "\n",
            "Epoch 00121: val_loss improved from 0.53449 to 0.53423, saving model to model_5.hdf5\n",
            "Epoch 122/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5527 - accuracy: 0.7251 - val_loss: 0.5341 - val_accuracy: 0.7390\n",
            "\n",
            "Epoch 00122: val_loss improved from 0.53423 to 0.53412, saving model to model_5.hdf5\n",
            "Epoch 123/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5313 - accuracy: 0.7388 - val_loss: 0.5338 - val_accuracy: 0.7328\n",
            "\n",
            "Epoch 00123: val_loss improved from 0.53412 to 0.53383, saving model to model_5.hdf5\n",
            "Epoch 124/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5314 - accuracy: 0.7281 - val_loss: 0.5336 - val_accuracy: 0.7370\n",
            "\n",
            "Epoch 00124: val_loss improved from 0.53383 to 0.53356, saving model to model_5.hdf5\n",
            "Epoch 125/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5320 - accuracy: 0.7358 - val_loss: 0.5333 - val_accuracy: 0.7370\n",
            "\n",
            "Epoch 00125: val_loss improved from 0.53356 to 0.53335, saving model to model_5.hdf5\n",
            "Epoch 126/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5234 - accuracy: 0.7533 - val_loss: 0.5332 - val_accuracy: 0.7328\n",
            "\n",
            "Epoch 00126: val_loss improved from 0.53335 to 0.53320, saving model to model_5.hdf5\n",
            "Epoch 127/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5225 - accuracy: 0.7469 - val_loss: 0.5330 - val_accuracy: 0.7370\n",
            "\n",
            "Epoch 00127: val_loss improved from 0.53320 to 0.53297, saving model to model_5.hdf5\n",
            "Epoch 128/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5276 - accuracy: 0.7487 - val_loss: 0.5329 - val_accuracy: 0.7328\n",
            "\n",
            "Epoch 00128: val_loss improved from 0.53297 to 0.53285, saving model to model_5.hdf5\n",
            "Epoch 129/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5292 - accuracy: 0.7465 - val_loss: 0.5327 - val_accuracy: 0.7370\n",
            "\n",
            "Epoch 00129: val_loss improved from 0.53285 to 0.53274, saving model to model_5.hdf5\n",
            "Epoch 130/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5263 - accuracy: 0.7305 - val_loss: 0.5324 - val_accuracy: 0.7370\n",
            "\n",
            "Epoch 00130: val_loss improved from 0.53274 to 0.53237, saving model to model_5.hdf5\n",
            "Epoch 131/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5614 - accuracy: 0.7181 - val_loss: 0.5322 - val_accuracy: 0.7328\n",
            "\n",
            "Epoch 00131: val_loss improved from 0.53237 to 0.53219, saving model to model_5.hdf5\n",
            "Epoch 132/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5430 - accuracy: 0.7367 - val_loss: 0.5320 - val_accuracy: 0.7370\n",
            "\n",
            "Epoch 00132: val_loss improved from 0.53219 to 0.53195, saving model to model_5.hdf5\n",
            "Epoch 133/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5354 - accuracy: 0.7549 - val_loss: 0.5318 - val_accuracy: 0.7328\n",
            "\n",
            "Epoch 00133: val_loss improved from 0.53195 to 0.53184, saving model to model_5.hdf5\n",
            "Epoch 134/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5344 - accuracy: 0.7318 - val_loss: 0.5317 - val_accuracy: 0.7370\n",
            "\n",
            "Epoch 00134: val_loss improved from 0.53184 to 0.53165, saving model to model_5.hdf5\n",
            "Epoch 135/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5167 - accuracy: 0.7462 - val_loss: 0.5314 - val_accuracy: 0.7370\n",
            "\n",
            "Epoch 00135: val_loss improved from 0.53165 to 0.53141, saving model to model_5.hdf5\n",
            "Epoch 136/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5219 - accuracy: 0.7582 - val_loss: 0.5313 - val_accuracy: 0.7370\n",
            "\n",
            "Epoch 00136: val_loss improved from 0.53141 to 0.53132, saving model to model_5.hdf5\n",
            "Epoch 137/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5503 - accuracy: 0.7175 - val_loss: 0.5311 - val_accuracy: 0.7370\n",
            "\n",
            "Epoch 00137: val_loss improved from 0.53132 to 0.53112, saving model to model_5.hdf5\n",
            "Epoch 138/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5460 - accuracy: 0.7292 - val_loss: 0.5311 - val_accuracy: 0.7349\n",
            "\n",
            "Epoch 00138: val_loss improved from 0.53112 to 0.53105, saving model to model_5.hdf5\n",
            "Epoch 139/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5470 - accuracy: 0.7116 - val_loss: 0.5308 - val_accuracy: 0.7370\n",
            "\n",
            "Epoch 00139: val_loss improved from 0.53105 to 0.53084, saving model to model_5.hdf5\n",
            "Epoch 140/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5249 - accuracy: 0.7360 - val_loss: 0.5309 - val_accuracy: 0.7390\n",
            "\n",
            "Epoch 00140: val_loss did not improve from 0.53084\n",
            "Epoch 141/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5403 - accuracy: 0.7220 - val_loss: 0.5307 - val_accuracy: 0.7370\n",
            "\n",
            "Epoch 00141: val_loss improved from 0.53084 to 0.53071, saving model to model_5.hdf5\n",
            "Epoch 142/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5127 - accuracy: 0.7465 - val_loss: 0.5304 - val_accuracy: 0.7390\n",
            "\n",
            "Epoch 00142: val_loss improved from 0.53071 to 0.53043, saving model to model_5.hdf5\n",
            "Epoch 143/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5483 - accuracy: 0.7192 - val_loss: 0.5303 - val_accuracy: 0.7370\n",
            "\n",
            "Epoch 00143: val_loss improved from 0.53043 to 0.53026, saving model to model_5.hdf5\n",
            "Epoch 144/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5251 - accuracy: 0.7381 - val_loss: 0.5302 - val_accuracy: 0.7390\n",
            "\n",
            "Epoch 00144: val_loss improved from 0.53026 to 0.53015, saving model to model_5.hdf5\n",
            "Epoch 145/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5286 - accuracy: 0.7518 - val_loss: 0.5300 - val_accuracy: 0.7370\n",
            "\n",
            "Epoch 00145: val_loss improved from 0.53015 to 0.52998, saving model to model_5.hdf5\n",
            "Epoch 146/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5285 - accuracy: 0.7490 - val_loss: 0.5298 - val_accuracy: 0.7370\n",
            "\n",
            "Epoch 00146: val_loss improved from 0.52998 to 0.52979, saving model to model_5.hdf5\n",
            "Epoch 147/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5311 - accuracy: 0.7520 - val_loss: 0.5298 - val_accuracy: 0.7390\n",
            "\n",
            "Epoch 00147: val_loss improved from 0.52979 to 0.52976, saving model to model_5.hdf5\n",
            "Epoch 148/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5304 - accuracy: 0.7479 - val_loss: 0.5296 - val_accuracy: 0.7370\n",
            "\n",
            "Epoch 00148: val_loss improved from 0.52976 to 0.52957, saving model to model_5.hdf5\n",
            "Epoch 149/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5272 - accuracy: 0.7330 - val_loss: 0.5294 - val_accuracy: 0.7349\n",
            "\n",
            "Epoch 00149: val_loss improved from 0.52957 to 0.52938, saving model to model_5.hdf5\n",
            "Epoch 150/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5404 - accuracy: 0.7356 - val_loss: 0.5293 - val_accuracy: 0.7370\n",
            "\n",
            "Epoch 00150: val_loss improved from 0.52938 to 0.52928, saving model to model_5.hdf5\n",
            "Epoch 151/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5153 - accuracy: 0.7600 - val_loss: 0.5293 - val_accuracy: 0.7390\n",
            "\n",
            "Epoch 00151: val_loss improved from 0.52928 to 0.52925, saving model to model_5.hdf5\n",
            "Epoch 152/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5421 - accuracy: 0.7320 - val_loss: 0.5293 - val_accuracy: 0.7370\n",
            "\n",
            "Epoch 00152: val_loss did not improve from 0.52925\n",
            "Epoch 153/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5232 - accuracy: 0.7539 - val_loss: 0.5290 - val_accuracy: 0.7349\n",
            "\n",
            "Epoch 00153: val_loss improved from 0.52925 to 0.52902, saving model to model_5.hdf5\n",
            "Epoch 154/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5123 - accuracy: 0.7484 - val_loss: 0.5289 - val_accuracy: 0.7349\n",
            "\n",
            "Epoch 00154: val_loss improved from 0.52902 to 0.52893, saving model to model_5.hdf5\n",
            "Epoch 155/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5378 - accuracy: 0.7412 - val_loss: 0.5288 - val_accuracy: 0.7349\n",
            "\n",
            "Epoch 00155: val_loss improved from 0.52893 to 0.52880, saving model to model_5.hdf5\n",
            "Epoch 156/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5243 - accuracy: 0.7504 - val_loss: 0.5286 - val_accuracy: 0.7390\n",
            "\n",
            "Epoch 00156: val_loss improved from 0.52880 to 0.52861, saving model to model_5.hdf5\n",
            "Epoch 157/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5378 - accuracy: 0.7223 - val_loss: 0.5285 - val_accuracy: 0.7390\n",
            "\n",
            "Epoch 00157: val_loss improved from 0.52861 to 0.52851, saving model to model_5.hdf5\n",
            "Epoch 158/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5375 - accuracy: 0.7344 - val_loss: 0.5284 - val_accuracy: 0.7390\n",
            "\n",
            "Epoch 00158: val_loss improved from 0.52851 to 0.52839, saving model to model_5.hdf5\n",
            "Epoch 159/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5282 - accuracy: 0.7432 - val_loss: 0.5283 - val_accuracy: 0.7349\n",
            "\n",
            "Epoch 00159: val_loss improved from 0.52839 to 0.52832, saving model to model_5.hdf5\n",
            "Epoch 160/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5459 - accuracy: 0.7293 - val_loss: 0.5281 - val_accuracy: 0.7390\n",
            "\n",
            "Epoch 00160: val_loss improved from 0.52832 to 0.52813, saving model to model_5.hdf5\n",
            "Epoch 161/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5216 - accuracy: 0.7444 - val_loss: 0.5280 - val_accuracy: 0.7390\n",
            "\n",
            "Epoch 00161: val_loss improved from 0.52813 to 0.52800, saving model to model_5.hdf5\n",
            "Epoch 162/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5431 - accuracy: 0.7222 - val_loss: 0.5279 - val_accuracy: 0.7370\n",
            "\n",
            "Epoch 00162: val_loss improved from 0.52800 to 0.52790, saving model to model_5.hdf5\n",
            "Epoch 163/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5219 - accuracy: 0.7619 - val_loss: 0.5278 - val_accuracy: 0.7370\n",
            "\n",
            "Epoch 00163: val_loss improved from 0.52790 to 0.52781, saving model to model_5.hdf5\n",
            "Epoch 164/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5406 - accuracy: 0.7329 - val_loss: 0.5277 - val_accuracy: 0.7370\n",
            "\n",
            "Epoch 00164: val_loss improved from 0.52781 to 0.52774, saving model to model_5.hdf5\n",
            "Epoch 165/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5366 - accuracy: 0.7286 - val_loss: 0.5276 - val_accuracy: 0.7390\n",
            "\n",
            "Epoch 00165: val_loss improved from 0.52774 to 0.52761, saving model to model_5.hdf5\n",
            "Epoch 166/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5135 - accuracy: 0.7550 - val_loss: 0.5276 - val_accuracy: 0.7370\n",
            "\n",
            "Epoch 00166: val_loss improved from 0.52761 to 0.52761, saving model to model_5.hdf5\n",
            "Epoch 167/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5399 - accuracy: 0.7394 - val_loss: 0.5275 - val_accuracy: 0.7370\n",
            "\n",
            "Epoch 00167: val_loss improved from 0.52761 to 0.52754, saving model to model_5.hdf5\n",
            "Epoch 168/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5190 - accuracy: 0.7430 - val_loss: 0.5274 - val_accuracy: 0.7390\n",
            "\n",
            "Epoch 00168: val_loss improved from 0.52754 to 0.52737, saving model to model_5.hdf5\n",
            "Epoch 169/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5210 - accuracy: 0.7466 - val_loss: 0.5272 - val_accuracy: 0.7411\n",
            "\n",
            "Epoch 00169: val_loss improved from 0.52737 to 0.52723, saving model to model_5.hdf5\n",
            "Epoch 170/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5237 - accuracy: 0.7497 - val_loss: 0.5272 - val_accuracy: 0.7370\n",
            "\n",
            "Epoch 00170: val_loss improved from 0.52723 to 0.52716, saving model to model_5.hdf5\n",
            "Epoch 171/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5280 - accuracy: 0.7475 - val_loss: 0.5270 - val_accuracy: 0.7432\n",
            "\n",
            "Epoch 00171: val_loss improved from 0.52716 to 0.52704, saving model to model_5.hdf5\n",
            "Epoch 172/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5245 - accuracy: 0.7414 - val_loss: 0.5270 - val_accuracy: 0.7370\n",
            "\n",
            "Epoch 00172: val_loss improved from 0.52704 to 0.52699, saving model to model_5.hdf5\n",
            "Epoch 173/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5258 - accuracy: 0.7324 - val_loss: 0.5269 - val_accuracy: 0.7370\n",
            "\n",
            "Epoch 00173: val_loss improved from 0.52699 to 0.52690, saving model to model_5.hdf5\n",
            "Epoch 174/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7649 - val_loss: 0.5268 - val_accuracy: 0.7432\n",
            "\n",
            "Epoch 00174: val_loss improved from 0.52690 to 0.52676, saving model to model_5.hdf5\n",
            "Epoch 175/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5277 - accuracy: 0.7445 - val_loss: 0.5267 - val_accuracy: 0.7411\n",
            "\n",
            "Epoch 00175: val_loss improved from 0.52676 to 0.52665, saving model to model_5.hdf5\n",
            "Epoch 176/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5350 - accuracy: 0.7408 - val_loss: 0.5266 - val_accuracy: 0.7432\n",
            "\n",
            "Epoch 00176: val_loss improved from 0.52665 to 0.52663, saving model to model_5.hdf5\n",
            "Epoch 177/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5152 - accuracy: 0.7647 - val_loss: 0.5266 - val_accuracy: 0.7432\n",
            "\n",
            "Epoch 00177: val_loss improved from 0.52663 to 0.52655, saving model to model_5.hdf5\n",
            "Epoch 178/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5568 - accuracy: 0.7194 - val_loss: 0.5265 - val_accuracy: 0.7349\n",
            "\n",
            "Epoch 00178: val_loss improved from 0.52655 to 0.52654, saving model to model_5.hdf5\n",
            "Epoch 179/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5297 - accuracy: 0.7375 - val_loss: 0.5264 - val_accuracy: 0.7432\n",
            "\n",
            "Epoch 00179: val_loss improved from 0.52654 to 0.52639, saving model to model_5.hdf5\n",
            "Epoch 180/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5202 - accuracy: 0.7418 - val_loss: 0.5263 - val_accuracy: 0.7370\n",
            "\n",
            "Epoch 00180: val_loss improved from 0.52639 to 0.52635, saving model to model_5.hdf5\n",
            "Epoch 181/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5303 - accuracy: 0.7382 - val_loss: 0.5263 - val_accuracy: 0.7370\n",
            "\n",
            "Epoch 00181: val_loss improved from 0.52635 to 0.52630, saving model to model_5.hdf5\n",
            "Epoch 182/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5139 - accuracy: 0.7515 - val_loss: 0.5262 - val_accuracy: 0.7432\n",
            "\n",
            "Epoch 00182: val_loss improved from 0.52630 to 0.52615, saving model to model_5.hdf5\n",
            "Epoch 183/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5219 - accuracy: 0.7574 - val_loss: 0.5261 - val_accuracy: 0.7432\n",
            "\n",
            "Epoch 00183: val_loss improved from 0.52615 to 0.52607, saving model to model_5.hdf5\n",
            "Epoch 184/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5419 - accuracy: 0.7282 - val_loss: 0.5260 - val_accuracy: 0.7432\n",
            "\n",
            "Epoch 00184: val_loss improved from 0.52607 to 0.52600, saving model to model_5.hdf5\n",
            "Epoch 185/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4909 - accuracy: 0.7684 - val_loss: 0.5259 - val_accuracy: 0.7411\n",
            "\n",
            "Epoch 00185: val_loss improved from 0.52600 to 0.52591, saving model to model_5.hdf5\n",
            "Epoch 186/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5125 - accuracy: 0.7485 - val_loss: 0.5259 - val_accuracy: 0.7432\n",
            "\n",
            "Epoch 00186: val_loss did not improve from 0.52591\n",
            "Epoch 187/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5247 - accuracy: 0.7448 - val_loss: 0.5259 - val_accuracy: 0.7370\n",
            "\n",
            "Epoch 00187: val_loss did not improve from 0.52591\n",
            "Epoch 188/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5409 - accuracy: 0.7222 - val_loss: 0.5258 - val_accuracy: 0.7370\n",
            "\n",
            "Epoch 00188: val_loss improved from 0.52591 to 0.52581, saving model to model_5.hdf5\n",
            "Epoch 189/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5193 - accuracy: 0.7530 - val_loss: 0.5257 - val_accuracy: 0.7432\n",
            "\n",
            "Epoch 00189: val_loss improved from 0.52581 to 0.52569, saving model to model_5.hdf5\n",
            "Epoch 190/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5300 - accuracy: 0.7483 - val_loss: 0.5256 - val_accuracy: 0.7432\n",
            "\n",
            "Epoch 00190: val_loss improved from 0.52569 to 0.52560, saving model to model_5.hdf5\n",
            "Epoch 191/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5372 - accuracy: 0.7354 - val_loss: 0.5256 - val_accuracy: 0.7411\n",
            "\n",
            "Epoch 00191: val_loss improved from 0.52560 to 0.52558, saving model to model_5.hdf5\n",
            "Epoch 192/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5242 - accuracy: 0.7407 - val_loss: 0.5255 - val_accuracy: 0.7411\n",
            "\n",
            "Epoch 00192: val_loss improved from 0.52558 to 0.52550, saving model to model_5.hdf5\n",
            "Epoch 193/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5004 - accuracy: 0.7551 - val_loss: 0.5254 - val_accuracy: 0.7411\n",
            "\n",
            "Epoch 00193: val_loss improved from 0.52550 to 0.52542, saving model to model_5.hdf5\n",
            "Epoch 194/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5331 - accuracy: 0.7375 - val_loss: 0.5254 - val_accuracy: 0.7370\n",
            "\n",
            "Epoch 00194: val_loss improved from 0.52542 to 0.52541, saving model to model_5.hdf5\n",
            "Epoch 195/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5228 - accuracy: 0.7452 - val_loss: 0.5253 - val_accuracy: 0.7370\n",
            "\n",
            "Epoch 00195: val_loss improved from 0.52541 to 0.52535, saving model to model_5.hdf5\n",
            "Epoch 196/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5308 - accuracy: 0.7373 - val_loss: 0.5253 - val_accuracy: 0.7370\n",
            "\n",
            "Epoch 00196: val_loss improved from 0.52535 to 0.52531, saving model to model_5.hdf5\n",
            "Epoch 197/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5347 - accuracy: 0.7413 - val_loss: 0.5252 - val_accuracy: 0.7370\n",
            "\n",
            "Epoch 00197: val_loss improved from 0.52531 to 0.52522, saving model to model_5.hdf5\n",
            "Epoch 198/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5343 - accuracy: 0.7341 - val_loss: 0.5252 - val_accuracy: 0.7370\n",
            "\n",
            "Epoch 00198: val_loss improved from 0.52522 to 0.52522, saving model to model_5.hdf5\n",
            "Epoch 199/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5265 - accuracy: 0.7493 - val_loss: 0.5250 - val_accuracy: 0.7411\n",
            "\n",
            "Epoch 00199: val_loss improved from 0.52522 to 0.52504, saving model to model_5.hdf5\n",
            "Epoch 200/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5202 - accuracy: 0.7598 - val_loss: 0.5250 - val_accuracy: 0.7411\n",
            "\n",
            "Epoch 00200: val_loss improved from 0.52504 to 0.52497, saving model to model_5.hdf5\n",
            "Epoch 201/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5000 - accuracy: 0.7762 - val_loss: 0.5249 - val_accuracy: 0.7411\n",
            "\n",
            "Epoch 00201: val_loss improved from 0.52497 to 0.52489, saving model to model_5.hdf5\n",
            "Epoch 202/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5206 - accuracy: 0.7560 - val_loss: 0.5248 - val_accuracy: 0.7411\n",
            "\n",
            "Epoch 00202: val_loss improved from 0.52489 to 0.52484, saving model to model_5.hdf5\n",
            "Epoch 203/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5344 - accuracy: 0.7256 - val_loss: 0.5248 - val_accuracy: 0.7411\n",
            "\n",
            "Epoch 00203: val_loss improved from 0.52484 to 0.52476, saving model to model_5.hdf5\n",
            "Epoch 204/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5214 - accuracy: 0.7472 - val_loss: 0.5248 - val_accuracy: 0.7411\n",
            "\n",
            "Epoch 00204: val_loss did not improve from 0.52476\n",
            "Epoch 205/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5137 - accuracy: 0.7571 - val_loss: 0.5247 - val_accuracy: 0.7411\n",
            "\n",
            "Epoch 00205: val_loss improved from 0.52476 to 0.52467, saving model to model_5.hdf5\n",
            "Epoch 206/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.7422 - val_loss: 0.5246 - val_accuracy: 0.7411\n",
            "\n",
            "Epoch 00206: val_loss improved from 0.52467 to 0.52458, saving model to model_5.hdf5\n",
            "Epoch 207/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5294 - accuracy: 0.7375 - val_loss: 0.5245 - val_accuracy: 0.7411\n",
            "\n",
            "Epoch 00207: val_loss improved from 0.52458 to 0.52451, saving model to model_5.hdf5\n",
            "Epoch 208/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5519 - accuracy: 0.7279 - val_loss: 0.5245 - val_accuracy: 0.7411\n",
            "\n",
            "Epoch 00208: val_loss improved from 0.52451 to 0.52448, saving model to model_5.hdf5\n",
            "Epoch 209/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5465 - accuracy: 0.7190 - val_loss: 0.5245 - val_accuracy: 0.7411\n",
            "\n",
            "Epoch 00209: val_loss improved from 0.52448 to 0.52445, saving model to model_5.hdf5\n",
            "Epoch 210/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5469 - accuracy: 0.7296 - val_loss: 0.5244 - val_accuracy: 0.7411\n",
            "\n",
            "Epoch 00210: val_loss improved from 0.52445 to 0.52443, saving model to model_5.hdf5\n",
            "Epoch 211/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5175 - accuracy: 0.7520 - val_loss: 0.5244 - val_accuracy: 0.7411\n",
            "\n",
            "Epoch 00211: val_loss improved from 0.52443 to 0.52439, saving model to model_5.hdf5\n",
            "Epoch 212/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5163 - accuracy: 0.7515 - val_loss: 0.5243 - val_accuracy: 0.7411\n",
            "\n",
            "Epoch 00212: val_loss improved from 0.52439 to 0.52431, saving model to model_5.hdf5\n",
            "Epoch 213/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5313 - accuracy: 0.7319 - val_loss: 0.5243 - val_accuracy: 0.7411\n",
            "\n",
            "Epoch 00213: val_loss improved from 0.52431 to 0.52425, saving model to model_5.hdf5\n",
            "Epoch 214/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5300 - accuracy: 0.7472 - val_loss: 0.5242 - val_accuracy: 0.7411\n",
            "\n",
            "Epoch 00214: val_loss improved from 0.52425 to 0.52421, saving model to model_5.hdf5\n",
            "Epoch 215/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5345 - accuracy: 0.7283 - val_loss: 0.5242 - val_accuracy: 0.7432\n",
            "\n",
            "Epoch 00215: val_loss improved from 0.52421 to 0.52418, saving model to model_5.hdf5\n",
            "Epoch 216/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5383 - accuracy: 0.7350 - val_loss: 0.5241 - val_accuracy: 0.7432\n",
            "\n",
            "Epoch 00216: val_loss improved from 0.52418 to 0.52412, saving model to model_5.hdf5\n",
            "Epoch 217/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5509 - accuracy: 0.7102 - val_loss: 0.5241 - val_accuracy: 0.7432\n",
            "\n",
            "Epoch 00217: val_loss improved from 0.52412 to 0.52409, saving model to model_5.hdf5\n",
            "Epoch 218/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5023 - accuracy: 0.7636 - val_loss: 0.5240 - val_accuracy: 0.7432\n",
            "\n",
            "Epoch 00218: val_loss improved from 0.52409 to 0.52404, saving model to model_5.hdf5\n",
            "Epoch 219/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5281 - accuracy: 0.7300 - val_loss: 0.5241 - val_accuracy: 0.7390\n",
            "\n",
            "Epoch 00219: val_loss did not improve from 0.52404\n",
            "Epoch 220/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5175 - accuracy: 0.7372 - val_loss: 0.5240 - val_accuracy: 0.7432\n",
            "\n",
            "Epoch 00220: val_loss improved from 0.52404 to 0.52398, saving model to model_5.hdf5\n",
            "Epoch 221/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5125 - accuracy: 0.7594 - val_loss: 0.5239 - val_accuracy: 0.7432\n",
            "\n",
            "Epoch 00221: val_loss improved from 0.52398 to 0.52390, saving model to model_5.hdf5\n",
            "Epoch 222/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5157 - accuracy: 0.7472 - val_loss: 0.5238 - val_accuracy: 0.7432\n",
            "\n",
            "Epoch 00222: val_loss improved from 0.52390 to 0.52378, saving model to model_5.hdf5\n",
            "Epoch 223/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5139 - accuracy: 0.7499 - val_loss: 0.5237 - val_accuracy: 0.7453\n",
            "\n",
            "Epoch 00223: val_loss improved from 0.52378 to 0.52369, saving model to model_5.hdf5\n",
            "Epoch 224/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5248 - accuracy: 0.7461 - val_loss: 0.5237 - val_accuracy: 0.7432\n",
            "\n",
            "Epoch 00224: val_loss did not improve from 0.52369\n",
            "Epoch 225/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5135 - accuracy: 0.7425 - val_loss: 0.5236 - val_accuracy: 0.7453\n",
            "\n",
            "Epoch 00225: val_loss improved from 0.52369 to 0.52364, saving model to model_5.hdf5\n",
            "Epoch 226/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5355 - accuracy: 0.7462 - val_loss: 0.5236 - val_accuracy: 0.7432\n",
            "\n",
            "Epoch 00226: val_loss improved from 0.52364 to 0.52363, saving model to model_5.hdf5\n",
            "Epoch 227/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7620 - val_loss: 0.5236 - val_accuracy: 0.7432\n",
            "\n",
            "Epoch 00227: val_loss improved from 0.52363 to 0.52360, saving model to model_5.hdf5\n",
            "Epoch 228/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5199 - accuracy: 0.7521 - val_loss: 0.5236 - val_accuracy: 0.7432\n",
            "\n",
            "Epoch 00228: val_loss improved from 0.52360 to 0.52359, saving model to model_5.hdf5\n",
            "Epoch 229/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5245 - accuracy: 0.7477 - val_loss: 0.5236 - val_accuracy: 0.7432\n",
            "\n",
            "Epoch 00229: val_loss improved from 0.52359 to 0.52355, saving model to model_5.hdf5\n",
            "Epoch 230/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5166 - accuracy: 0.7574 - val_loss: 0.5236 - val_accuracy: 0.7390\n",
            "\n",
            "Epoch 00230: val_loss did not improve from 0.52355\n",
            "Epoch 231/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5296 - accuracy: 0.7424 - val_loss: 0.5234 - val_accuracy: 0.7432\n",
            "\n",
            "Epoch 00231: val_loss improved from 0.52355 to 0.52341, saving model to model_5.hdf5\n",
            "Epoch 232/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5329 - accuracy: 0.7304 - val_loss: 0.5234 - val_accuracy: 0.7453\n",
            "\n",
            "Epoch 00232: val_loss improved from 0.52341 to 0.52336, saving model to model_5.hdf5\n",
            "Epoch 233/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5266 - accuracy: 0.7490 - val_loss: 0.5233 - val_accuracy: 0.7453\n",
            "\n",
            "Epoch 00233: val_loss improved from 0.52336 to 0.52328, saving model to model_5.hdf5\n",
            "Epoch 234/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5145 - accuracy: 0.7489 - val_loss: 0.5233 - val_accuracy: 0.7390\n",
            "\n",
            "Epoch 00234: val_loss did not improve from 0.52328\n",
            "Epoch 235/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5154 - accuracy: 0.7525 - val_loss: 0.5233 - val_accuracy: 0.7453\n",
            "\n",
            "Epoch 00235: val_loss improved from 0.52328 to 0.52327, saving model to model_5.hdf5\n",
            "Epoch 236/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4961 - accuracy: 0.7698 - val_loss: 0.5232 - val_accuracy: 0.7453\n",
            "\n",
            "Epoch 00236: val_loss improved from 0.52327 to 0.52319, saving model to model_5.hdf5\n",
            "Epoch 237/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5401 - accuracy: 0.7341 - val_loss: 0.5231 - val_accuracy: 0.7453\n",
            "\n",
            "Epoch 00237: val_loss improved from 0.52319 to 0.52314, saving model to model_5.hdf5\n",
            "Epoch 238/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5184 - accuracy: 0.7354 - val_loss: 0.5231 - val_accuracy: 0.7453\n",
            "\n",
            "Epoch 00238: val_loss improved from 0.52314 to 0.52308, saving model to model_5.hdf5\n",
            "Epoch 239/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5210 - accuracy: 0.7375 - val_loss: 0.5230 - val_accuracy: 0.7453\n",
            "\n",
            "Epoch 00239: val_loss improved from 0.52308 to 0.52304, saving model to model_5.hdf5\n",
            "Epoch 240/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5194 - accuracy: 0.7433 - val_loss: 0.5230 - val_accuracy: 0.7453\n",
            "\n",
            "Epoch 00240: val_loss improved from 0.52304 to 0.52304, saving model to model_5.hdf5\n",
            "Epoch 241/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5231 - accuracy: 0.7452 - val_loss: 0.5230 - val_accuracy: 0.7453\n",
            "\n",
            "Epoch 00241: val_loss improved from 0.52304 to 0.52299, saving model to model_5.hdf5\n",
            "Epoch 242/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5277 - accuracy: 0.7287 - val_loss: 0.5229 - val_accuracy: 0.7453\n",
            "\n",
            "Epoch 00242: val_loss improved from 0.52299 to 0.52295, saving model to model_5.hdf5\n",
            "Epoch 243/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5285 - accuracy: 0.7342 - val_loss: 0.5229 - val_accuracy: 0.7453\n",
            "\n",
            "Epoch 00243: val_loss improved from 0.52295 to 0.52290, saving model to model_5.hdf5\n",
            "Epoch 244/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4984 - accuracy: 0.7634 - val_loss: 0.5229 - val_accuracy: 0.7453\n",
            "\n",
            "Epoch 00244: val_loss improved from 0.52290 to 0.52287, saving model to model_5.hdf5\n",
            "Epoch 245/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7571 - val_loss: 0.5228 - val_accuracy: 0.7453\n",
            "\n",
            "Epoch 00245: val_loss improved from 0.52287 to 0.52284, saving model to model_5.hdf5\n",
            "Epoch 246/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5274 - accuracy: 0.7343 - val_loss: 0.5228 - val_accuracy: 0.7453\n",
            "\n",
            "Epoch 00246: val_loss improved from 0.52284 to 0.52279, saving model to model_5.hdf5\n",
            "Epoch 247/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5235 - accuracy: 0.7402 - val_loss: 0.5228 - val_accuracy: 0.7432\n",
            "\n",
            "Epoch 00247: val_loss did not improve from 0.52279\n",
            "Epoch 248/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5230 - accuracy: 0.7573 - val_loss: 0.5228 - val_accuracy: 0.7432\n",
            "\n",
            "Epoch 00248: val_loss improved from 0.52279 to 0.52279, saving model to model_5.hdf5\n",
            "Epoch 249/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5323 - accuracy: 0.7515 - val_loss: 0.5227 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00249: val_loss improved from 0.52279 to 0.52272, saving model to model_5.hdf5\n",
            "Epoch 250/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5135 - accuracy: 0.7583 - val_loss: 0.5227 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00250: val_loss improved from 0.52272 to 0.52267, saving model to model_5.hdf5\n",
            "Epoch 251/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5141 - accuracy: 0.7475 - val_loss: 0.5226 - val_accuracy: 0.7453\n",
            "\n",
            "Epoch 00251: val_loss improved from 0.52267 to 0.52262, saving model to model_5.hdf5\n",
            "Epoch 252/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4984 - accuracy: 0.7561 - val_loss: 0.5226 - val_accuracy: 0.7453\n",
            "\n",
            "Epoch 00252: val_loss improved from 0.52262 to 0.52258, saving model to model_5.hdf5\n",
            "Epoch 253/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5018 - accuracy: 0.7639 - val_loss: 0.5225 - val_accuracy: 0.7453\n",
            "\n",
            "Epoch 00253: val_loss improved from 0.52258 to 0.52254, saving model to model_5.hdf5\n",
            "Epoch 254/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5324 - accuracy: 0.7240 - val_loss: 0.5225 - val_accuracy: 0.7453\n",
            "\n",
            "Epoch 00254: val_loss improved from 0.52254 to 0.52246, saving model to model_5.hdf5\n",
            "Epoch 255/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5198 - accuracy: 0.7502 - val_loss: 0.5224 - val_accuracy: 0.7453\n",
            "\n",
            "Epoch 00255: val_loss improved from 0.52246 to 0.52244, saving model to model_5.hdf5\n",
            "Epoch 256/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5100 - accuracy: 0.7409 - val_loss: 0.5224 - val_accuracy: 0.7453\n",
            "\n",
            "Epoch 00256: val_loss improved from 0.52244 to 0.52242, saving model to model_5.hdf5\n",
            "Epoch 257/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5142 - accuracy: 0.7595 - val_loss: 0.5224 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00257: val_loss improved from 0.52242 to 0.52242, saving model to model_5.hdf5\n",
            "Epoch 258/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.7593 - val_loss: 0.5224 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00258: val_loss improved from 0.52242 to 0.52240, saving model to model_5.hdf5\n",
            "Epoch 259/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5214 - accuracy: 0.7396 - val_loss: 0.5223 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00259: val_loss improved from 0.52240 to 0.52234, saving model to model_5.hdf5\n",
            "Epoch 260/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5463 - accuracy: 0.7359 - val_loss: 0.5224 - val_accuracy: 0.7432\n",
            "\n",
            "Epoch 00260: val_loss did not improve from 0.52234\n",
            "Epoch 261/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4991 - accuracy: 0.7622 - val_loss: 0.5223 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00261: val_loss improved from 0.52234 to 0.52231, saving model to model_5.hdf5\n",
            "Epoch 262/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5271 - accuracy: 0.7384 - val_loss: 0.5223 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00262: val_loss improved from 0.52231 to 0.52227, saving model to model_5.hdf5\n",
            "Epoch 263/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5452 - accuracy: 0.7373 - val_loss: 0.5222 - val_accuracy: 0.7453\n",
            "\n",
            "Epoch 00263: val_loss improved from 0.52227 to 0.52215, saving model to model_5.hdf5\n",
            "Epoch 264/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4993 - accuracy: 0.7565 - val_loss: 0.5221 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00264: val_loss improved from 0.52215 to 0.52214, saving model to model_5.hdf5\n",
            "Epoch 265/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5314 - accuracy: 0.7488 - val_loss: 0.5221 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00265: val_loss improved from 0.52214 to 0.52213, saving model to model_5.hdf5\n",
            "Epoch 266/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5454 - accuracy: 0.7385 - val_loss: 0.5220 - val_accuracy: 0.7453\n",
            "\n",
            "Epoch 00266: val_loss improved from 0.52213 to 0.52205, saving model to model_5.hdf5\n",
            "Epoch 267/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5155 - accuracy: 0.7479 - val_loss: 0.5220 - val_accuracy: 0.7453\n",
            "\n",
            "Epoch 00267: val_loss improved from 0.52205 to 0.52202, saving model to model_5.hdf5\n",
            "Epoch 268/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5164 - accuracy: 0.7508 - val_loss: 0.5220 - val_accuracy: 0.7453\n",
            "\n",
            "Epoch 00268: val_loss improved from 0.52202 to 0.52196, saving model to model_5.hdf5\n",
            "Epoch 269/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5222 - accuracy: 0.7383 - val_loss: 0.5220 - val_accuracy: 0.7453\n",
            "\n",
            "Epoch 00269: val_loss improved from 0.52196 to 0.52195, saving model to model_5.hdf5\n",
            "Epoch 270/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5340 - accuracy: 0.7408 - val_loss: 0.5220 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00270: val_loss improved from 0.52195 to 0.52195, saving model to model_5.hdf5\n",
            "Epoch 271/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5231 - accuracy: 0.7324 - val_loss: 0.5219 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00271: val_loss improved from 0.52195 to 0.52194, saving model to model_5.hdf5\n",
            "Epoch 272/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5128 - accuracy: 0.7538 - val_loss: 0.5220 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00272: val_loss did not improve from 0.52194\n",
            "Epoch 273/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5445 - accuracy: 0.7266 - val_loss: 0.5220 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00273: val_loss did not improve from 0.52194\n",
            "Epoch 274/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.7578 - val_loss: 0.5219 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00274: val_loss improved from 0.52194 to 0.52193, saving model to model_5.hdf5\n",
            "Epoch 275/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5341 - accuracy: 0.7232 - val_loss: 0.5219 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00275: val_loss improved from 0.52193 to 0.52189, saving model to model_5.hdf5\n",
            "Epoch 276/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4928 - accuracy: 0.7582 - val_loss: 0.5219 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00276: val_loss improved from 0.52189 to 0.52186, saving model to model_5.hdf5\n",
            "Epoch 277/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5195 - accuracy: 0.7443 - val_loss: 0.5218 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00277: val_loss improved from 0.52186 to 0.52183, saving model to model_5.hdf5\n",
            "Epoch 278/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5190 - accuracy: 0.7529 - val_loss: 0.5218 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00278: val_loss improved from 0.52183 to 0.52179, saving model to model_5.hdf5\n",
            "Epoch 279/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5159 - accuracy: 0.7688 - val_loss: 0.5218 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00279: val_loss improved from 0.52179 to 0.52176, saving model to model_5.hdf5\n",
            "Epoch 280/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7623 - val_loss: 0.5217 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00280: val_loss improved from 0.52176 to 0.52171, saving model to model_5.hdf5\n",
            "Epoch 281/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5022 - accuracy: 0.7702 - val_loss: 0.5216 - val_accuracy: 0.7453\n",
            "\n",
            "Epoch 00281: val_loss improved from 0.52171 to 0.52165, saving model to model_5.hdf5\n",
            "Epoch 282/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7579 - val_loss: 0.5216 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00282: val_loss improved from 0.52165 to 0.52163, saving model to model_5.hdf5\n",
            "Epoch 283/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5424 - accuracy: 0.7172 - val_loss: 0.5216 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00283: val_loss improved from 0.52163 to 0.52157, saving model to model_5.hdf5\n",
            "Epoch 284/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5256 - accuracy: 0.7429 - val_loss: 0.5216 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00284: val_loss improved from 0.52157 to 0.52156, saving model to model_5.hdf5\n",
            "Epoch 285/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7473 - val_loss: 0.5216 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00285: val_loss did not improve from 0.52156\n",
            "Epoch 286/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5252 - accuracy: 0.7461 - val_loss: 0.5215 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00286: val_loss improved from 0.52156 to 0.52155, saving model to model_5.hdf5\n",
            "Epoch 287/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5017 - accuracy: 0.7563 - val_loss: 0.5215 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00287: val_loss improved from 0.52155 to 0.52154, saving model to model_5.hdf5\n",
            "Epoch 288/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4910 - accuracy: 0.7630 - val_loss: 0.5216 - val_accuracy: 0.7453\n",
            "\n",
            "Epoch 00288: val_loss did not improve from 0.52154\n",
            "Epoch 289/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5283 - accuracy: 0.7431 - val_loss: 0.5215 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00289: val_loss improved from 0.52154 to 0.52149, saving model to model_5.hdf5\n",
            "Epoch 290/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5165 - accuracy: 0.7526 - val_loss: 0.5215 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00290: val_loss improved from 0.52149 to 0.52148, saving model to model_5.hdf5\n",
            "Epoch 291/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5241 - accuracy: 0.7447 - val_loss: 0.5215 - val_accuracy: 0.7453\n",
            "\n",
            "Epoch 00291: val_loss did not improve from 0.52148\n",
            "Epoch 292/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5414 - accuracy: 0.7226 - val_loss: 0.5215 - val_accuracy: 0.7495\n",
            "\n",
            "Epoch 00292: val_loss improved from 0.52148 to 0.52148, saving model to model_5.hdf5\n",
            "Epoch 293/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5206 - accuracy: 0.7411 - val_loss: 0.5215 - val_accuracy: 0.7453\n",
            "\n",
            "Epoch 00293: val_loss did not improve from 0.52148\n",
            "Epoch 294/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7423 - val_loss: 0.5215 - val_accuracy: 0.7453\n",
            "\n",
            "Epoch 00294: val_loss improved from 0.52148 to 0.52147, saving model to model_5.hdf5\n",
            "Epoch 295/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5132 - accuracy: 0.7474 - val_loss: 0.5214 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00295: val_loss improved from 0.52147 to 0.52136, saving model to model_5.hdf5\n",
            "Epoch 296/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5205 - accuracy: 0.7452 - val_loss: 0.5213 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00296: val_loss improved from 0.52136 to 0.52133, saving model to model_5.hdf5\n",
            "Epoch 297/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5270 - accuracy: 0.7284 - val_loss: 0.5213 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00297: val_loss improved from 0.52133 to 0.52132, saving model to model_5.hdf5\n",
            "Epoch 298/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5262 - accuracy: 0.7261 - val_loss: 0.5213 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00298: val_loss improved from 0.52132 to 0.52131, saving model to model_5.hdf5\n",
            "Epoch 299/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5423 - accuracy: 0.7430 - val_loss: 0.5213 - val_accuracy: 0.7495\n",
            "\n",
            "Epoch 00299: val_loss did not improve from 0.52131\n",
            "Epoch 300/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5093 - accuracy: 0.7562 - val_loss: 0.5213 - val_accuracy: 0.7495\n",
            "\n",
            "Epoch 00300: val_loss improved from 0.52131 to 0.52128, saving model to model_5.hdf5\n",
            "Epoch 301/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5221 - accuracy: 0.7474 - val_loss: 0.5213 - val_accuracy: 0.7495\n",
            "\n",
            "Epoch 00301: val_loss improved from 0.52128 to 0.52126, saving model to model_5.hdf5\n",
            "Epoch 302/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5395 - accuracy: 0.7309 - val_loss: 0.5212 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00302: val_loss improved from 0.52126 to 0.52121, saving model to model_5.hdf5\n",
            "Epoch 303/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5295 - accuracy: 0.7391 - val_loss: 0.5212 - val_accuracy: 0.7453\n",
            "\n",
            "Epoch 00303: val_loss improved from 0.52121 to 0.52119, saving model to model_5.hdf5\n",
            "Epoch 304/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5000 - accuracy: 0.7549 - val_loss: 0.5211 - val_accuracy: 0.7453\n",
            "\n",
            "Epoch 00304: val_loss improved from 0.52119 to 0.52114, saving model to model_5.hdf5\n",
            "Epoch 305/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5308 - accuracy: 0.7338 - val_loss: 0.5211 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00305: val_loss improved from 0.52114 to 0.52113, saving model to model_5.hdf5\n",
            "Epoch 306/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4923 - accuracy: 0.7697 - val_loss: 0.5211 - val_accuracy: 0.7453\n",
            "\n",
            "Epoch 00306: val_loss improved from 0.52113 to 0.52111, saving model to model_5.hdf5\n",
            "Epoch 307/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5250 - accuracy: 0.7446 - val_loss: 0.5211 - val_accuracy: 0.7495\n",
            "\n",
            "Epoch 00307: val_loss did not improve from 0.52111\n",
            "Epoch 308/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5323 - accuracy: 0.7524 - val_loss: 0.5211 - val_accuracy: 0.7495\n",
            "\n",
            "Epoch 00308: val_loss did not improve from 0.52111\n",
            "Epoch 309/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5314 - accuracy: 0.7482 - val_loss: 0.5211 - val_accuracy: 0.7495\n",
            "\n",
            "Epoch 00309: val_loss improved from 0.52111 to 0.52108, saving model to model_5.hdf5\n",
            "Epoch 310/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5286 - accuracy: 0.7416 - val_loss: 0.5211 - val_accuracy: 0.7495\n",
            "\n",
            "Epoch 00310: val_loss improved from 0.52108 to 0.52107, saving model to model_5.hdf5\n",
            "Epoch 311/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5198 - accuracy: 0.7382 - val_loss: 0.5211 - val_accuracy: 0.7495\n",
            "\n",
            "Epoch 00311: val_loss did not improve from 0.52107\n",
            "Epoch 312/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5279 - accuracy: 0.7386 - val_loss: 0.5210 - val_accuracy: 0.7453\n",
            "\n",
            "Epoch 00312: val_loss improved from 0.52107 to 0.52100, saving model to model_5.hdf5\n",
            "Epoch 313/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7647 - val_loss: 0.5210 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00313: val_loss did not improve from 0.52100\n",
            "Epoch 314/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5119 - accuracy: 0.7559 - val_loss: 0.5210 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00314: val_loss improved from 0.52100 to 0.52098, saving model to model_5.hdf5\n",
            "Epoch 315/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5188 - accuracy: 0.7444 - val_loss: 0.5209 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00315: val_loss improved from 0.52098 to 0.52094, saving model to model_5.hdf5\n",
            "Epoch 316/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5193 - accuracy: 0.7402 - val_loss: 0.5209 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00316: val_loss improved from 0.52094 to 0.52092, saving model to model_5.hdf5\n",
            "Epoch 317/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5132 - accuracy: 0.7577 - val_loss: 0.5209 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00317: val_loss improved from 0.52092 to 0.52091, saving model to model_5.hdf5\n",
            "Epoch 318/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5103 - accuracy: 0.7510 - val_loss: 0.5209 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00318: val_loss improved from 0.52091 to 0.52087, saving model to model_5.hdf5\n",
            "Epoch 319/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5240 - accuracy: 0.7548 - val_loss: 0.5209 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00319: val_loss did not improve from 0.52087\n",
            "Epoch 320/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5002 - accuracy: 0.7522 - val_loss: 0.5209 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00320: val_loss did not improve from 0.52087\n",
            "Epoch 321/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5243 - accuracy: 0.7332 - val_loss: 0.5209 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00321: val_loss did not improve from 0.52087\n",
            "Epoch 322/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5194 - accuracy: 0.7475 - val_loss: 0.5209 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00322: val_loss did not improve from 0.52087\n",
            "Epoch 323/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5321 - accuracy: 0.7454 - val_loss: 0.5209 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00323: val_loss improved from 0.52087 to 0.52085, saving model to model_5.hdf5\n",
            "Epoch 324/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5348 - accuracy: 0.7413 - val_loss: 0.5209 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00324: val_loss did not improve from 0.52085\n",
            "Epoch 325/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.7400 - val_loss: 0.5209 - val_accuracy: 0.7453\n",
            "\n",
            "Epoch 00325: val_loss did not improve from 0.52085\n",
            "Epoch 326/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5302 - accuracy: 0.7306 - val_loss: 0.5208 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00326: val_loss improved from 0.52085 to 0.52082, saving model to model_5.hdf5\n",
            "Epoch 327/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5170 - accuracy: 0.7441 - val_loss: 0.5208 - val_accuracy: 0.7495\n",
            "\n",
            "Epoch 00327: val_loss did not improve from 0.52082\n",
            "Epoch 328/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5430 - accuracy: 0.7361 - val_loss: 0.5208 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00328: val_loss improved from 0.52082 to 0.52079, saving model to model_5.hdf5\n",
            "Epoch 329/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5012 - accuracy: 0.7759 - val_loss: 0.5208 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00329: val_loss did not improve from 0.52079\n",
            "Epoch 330/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5222 - accuracy: 0.7543 - val_loss: 0.5208 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00330: val_loss improved from 0.52079 to 0.52078, saving model to model_5.hdf5\n",
            "Epoch 331/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5348 - accuracy: 0.7419 - val_loss: 0.5208 - val_accuracy: 0.7495\n",
            "\n",
            "Epoch 00331: val_loss improved from 0.52078 to 0.52077, saving model to model_5.hdf5\n",
            "Epoch 332/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5548 - accuracy: 0.7144 - val_loss: 0.5207 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00332: val_loss improved from 0.52077 to 0.52072, saving model to model_5.hdf5\n",
            "Epoch 333/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5212 - accuracy: 0.7480 - val_loss: 0.5206 - val_accuracy: 0.7453\n",
            "\n",
            "Epoch 00333: val_loss improved from 0.52072 to 0.52065, saving model to model_5.hdf5\n",
            "Epoch 334/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5227 - accuracy: 0.7471 - val_loss: 0.5206 - val_accuracy: 0.7453\n",
            "\n",
            "Epoch 00334: val_loss improved from 0.52065 to 0.52063, saving model to model_5.hdf5\n",
            "Epoch 335/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5394 - accuracy: 0.7320 - val_loss: 0.5206 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00335: val_loss did not improve from 0.52063\n",
            "Epoch 336/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5346 - accuracy: 0.7325 - val_loss: 0.5206 - val_accuracy: 0.7453\n",
            "\n",
            "Epoch 00336: val_loss improved from 0.52063 to 0.52060, saving model to model_5.hdf5\n",
            "Epoch 337/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5164 - accuracy: 0.7454 - val_loss: 0.5206 - val_accuracy: 0.7495\n",
            "\n",
            "Epoch 00337: val_loss improved from 0.52060 to 0.52058, saving model to model_5.hdf5\n",
            "Epoch 338/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5127 - accuracy: 0.7578 - val_loss: 0.5206 - val_accuracy: 0.7495\n",
            "\n",
            "Epoch 00338: val_loss did not improve from 0.52058\n",
            "Epoch 339/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5204 - accuracy: 0.7573 - val_loss: 0.5205 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00339: val_loss improved from 0.52058 to 0.52055, saving model to model_5.hdf5\n",
            "Epoch 340/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7666 - val_loss: 0.5205 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00340: val_loss improved from 0.52055 to 0.52054, saving model to model_5.hdf5\n",
            "Epoch 341/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5277 - accuracy: 0.7466 - val_loss: 0.5205 - val_accuracy: 0.7495\n",
            "\n",
            "Epoch 00341: val_loss improved from 0.52054 to 0.52053, saving model to model_5.hdf5\n",
            "Epoch 342/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5339 - accuracy: 0.7386 - val_loss: 0.5205 - val_accuracy: 0.7495\n",
            "\n",
            "Epoch 00342: val_loss improved from 0.52053 to 0.52050, saving model to model_5.hdf5\n",
            "Epoch 343/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4912 - accuracy: 0.7666 - val_loss: 0.5205 - val_accuracy: 0.7495\n",
            "\n",
            "Epoch 00343: val_loss did not improve from 0.52050\n",
            "Epoch 344/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5250 - accuracy: 0.7488 - val_loss: 0.5205 - val_accuracy: 0.7495\n",
            "\n",
            "Epoch 00344: val_loss did not improve from 0.52050\n",
            "Epoch 345/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5246 - accuracy: 0.7495 - val_loss: 0.5204 - val_accuracy: 0.7453\n",
            "\n",
            "Epoch 00345: val_loss improved from 0.52050 to 0.52044, saving model to model_5.hdf5\n",
            "Epoch 346/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7526 - val_loss: 0.5205 - val_accuracy: 0.7453\n",
            "\n",
            "Epoch 00346: val_loss did not improve from 0.52044\n",
            "Epoch 347/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5273 - accuracy: 0.7318 - val_loss: 0.5204 - val_accuracy: 0.7453\n",
            "\n",
            "Epoch 00347: val_loss improved from 0.52044 to 0.52044, saving model to model_5.hdf5\n",
            "Epoch 348/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5302 - accuracy: 0.7345 - val_loss: 0.5205 - val_accuracy: 0.7537\n",
            "\n",
            "Epoch 00348: val_loss did not improve from 0.52044\n",
            "Epoch 349/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5287 - accuracy: 0.7332 - val_loss: 0.5204 - val_accuracy: 0.7453\n",
            "\n",
            "Epoch 00349: val_loss improved from 0.52044 to 0.52041, saving model to model_5.hdf5\n",
            "Epoch 350/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5123 - accuracy: 0.7424 - val_loss: 0.5204 - val_accuracy: 0.7495\n",
            "\n",
            "Epoch 00350: val_loss did not improve from 0.52041\n",
            "Epoch 351/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5395 - accuracy: 0.7326 - val_loss: 0.5204 - val_accuracy: 0.7495\n",
            "\n",
            "Epoch 00351: val_loss improved from 0.52041 to 0.52040, saving model to model_5.hdf5\n",
            "Epoch 352/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5008 - accuracy: 0.7558 - val_loss: 0.5204 - val_accuracy: 0.7537\n",
            "\n",
            "Epoch 00352: val_loss did not improve from 0.52040\n",
            "Epoch 353/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5344 - accuracy: 0.7262 - val_loss: 0.5204 - val_accuracy: 0.7537\n",
            "\n",
            "Epoch 00353: val_loss improved from 0.52040 to 0.52035, saving model to model_5.hdf5\n",
            "Epoch 354/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5166 - accuracy: 0.7576 - val_loss: 0.5203 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00354: val_loss improved from 0.52035 to 0.52031, saving model to model_5.hdf5\n",
            "Epoch 355/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4755 - accuracy: 0.7872 - val_loss: 0.5203 - val_accuracy: 0.7537\n",
            "\n",
            "Epoch 00355: val_loss did not improve from 0.52031\n",
            "Epoch 356/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5145 - accuracy: 0.7538 - val_loss: 0.5203 - val_accuracy: 0.7537\n",
            "\n",
            "Epoch 00356: val_loss did not improve from 0.52031\n",
            "Epoch 357/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4993 - accuracy: 0.7593 - val_loss: 0.5203 - val_accuracy: 0.7537\n",
            "\n",
            "Epoch 00357: val_loss did not improve from 0.52031\n",
            "Epoch 358/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4960 - accuracy: 0.7631 - val_loss: 0.5203 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00358: val_loss improved from 0.52031 to 0.52030, saving model to model_5.hdf5\n",
            "Epoch 359/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7585 - val_loss: 0.5203 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00359: val_loss improved from 0.52030 to 0.52028, saving model to model_5.hdf5\n",
            "Epoch 360/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5174 - accuracy: 0.7558 - val_loss: 0.5202 - val_accuracy: 0.7432\n",
            "\n",
            "Epoch 00360: val_loss improved from 0.52028 to 0.52024, saving model to model_5.hdf5\n",
            "Epoch 361/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5212 - accuracy: 0.7546 - val_loss: 0.5203 - val_accuracy: 0.7537\n",
            "\n",
            "Epoch 00361: val_loss did not improve from 0.52024\n",
            "Epoch 362/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5470 - accuracy: 0.7163 - val_loss: 0.5203 - val_accuracy: 0.7537\n",
            "\n",
            "Epoch 00362: val_loss did not improve from 0.52024\n",
            "Epoch 363/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5245 - accuracy: 0.7350 - val_loss: 0.5202 - val_accuracy: 0.7537\n",
            "\n",
            "Epoch 00363: val_loss improved from 0.52024 to 0.52020, saving model to model_5.hdf5\n",
            "Epoch 364/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5457 - accuracy: 0.7284 - val_loss: 0.5202 - val_accuracy: 0.7495\n",
            "\n",
            "Epoch 00364: val_loss improved from 0.52020 to 0.52016, saving model to model_5.hdf5\n",
            "Epoch 365/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5213 - accuracy: 0.7382 - val_loss: 0.5201 - val_accuracy: 0.7432\n",
            "\n",
            "Epoch 00365: val_loss improved from 0.52016 to 0.52014, saving model to model_5.hdf5\n",
            "Epoch 366/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5327 - accuracy: 0.7418 - val_loss: 0.5202 - val_accuracy: 0.7495\n",
            "\n",
            "Epoch 00366: val_loss did not improve from 0.52014\n",
            "Epoch 367/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5403 - accuracy: 0.7315 - val_loss: 0.5201 - val_accuracy: 0.7495\n",
            "\n",
            "Epoch 00367: val_loss improved from 0.52014 to 0.52014, saving model to model_5.hdf5\n",
            "Epoch 368/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5346 - accuracy: 0.7366 - val_loss: 0.5201 - val_accuracy: 0.7453\n",
            "\n",
            "Epoch 00368: val_loss improved from 0.52014 to 0.52011, saving model to model_5.hdf5\n",
            "Epoch 369/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5161 - accuracy: 0.7452 - val_loss: 0.5201 - val_accuracy: 0.7453\n",
            "\n",
            "Epoch 00369: val_loss improved from 0.52011 to 0.52009, saving model to model_5.hdf5\n",
            "Epoch 370/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5134 - accuracy: 0.7599 - val_loss: 0.5201 - val_accuracy: 0.7495\n",
            "\n",
            "Epoch 00370: val_loss improved from 0.52009 to 0.52008, saving model to model_5.hdf5\n",
            "Epoch 371/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5473 - accuracy: 0.7286 - val_loss: 0.5201 - val_accuracy: 0.7453\n",
            "\n",
            "Epoch 00371: val_loss improved from 0.52008 to 0.52005, saving model to model_5.hdf5\n",
            "Epoch 372/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7626 - val_loss: 0.5201 - val_accuracy: 0.7495\n",
            "\n",
            "Epoch 00372: val_loss did not improve from 0.52005\n",
            "Epoch 373/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5150 - accuracy: 0.7406 - val_loss: 0.5201 - val_accuracy: 0.7516\n",
            "\n",
            "Epoch 00373: val_loss did not improve from 0.52005\n",
            "Epoch 374/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5247 - accuracy: 0.7455 - val_loss: 0.5201 - val_accuracy: 0.7516\n",
            "\n",
            "Epoch 00374: val_loss did not improve from 0.52005\n",
            "Epoch 375/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4935 - accuracy: 0.7680 - val_loss: 0.5200 - val_accuracy: 0.7495\n",
            "\n",
            "Epoch 00375: val_loss improved from 0.52005 to 0.52004, saving model to model_5.hdf5\n",
            "Epoch 376/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5370 - accuracy: 0.7352 - val_loss: 0.5201 - val_accuracy: 0.7516\n",
            "\n",
            "Epoch 00376: val_loss did not improve from 0.52004\n",
            "Epoch 377/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5185 - accuracy: 0.7555 - val_loss: 0.5201 - val_accuracy: 0.7516\n",
            "\n",
            "Epoch 00377: val_loss did not improve from 0.52004\n",
            "Epoch 378/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5141 - accuracy: 0.7556 - val_loss: 0.5201 - val_accuracy: 0.7516\n",
            "\n",
            "Epoch 00378: val_loss did not improve from 0.52004\n",
            "Epoch 379/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5116 - accuracy: 0.7539 - val_loss: 0.5200 - val_accuracy: 0.7516\n",
            "\n",
            "Epoch 00379: val_loss improved from 0.52004 to 0.52003, saving model to model_5.hdf5\n",
            "Epoch 380/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5164 - accuracy: 0.7519 - val_loss: 0.5200 - val_accuracy: 0.7495\n",
            "\n",
            "Epoch 00380: val_loss improved from 0.52003 to 0.52000, saving model to model_5.hdf5\n",
            "Epoch 381/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5247 - accuracy: 0.7340 - val_loss: 0.5200 - val_accuracy: 0.7516\n",
            "\n",
            "Epoch 00381: val_loss improved from 0.52000 to 0.51996, saving model to model_5.hdf5\n",
            "Epoch 382/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5448 - accuracy: 0.7211 - val_loss: 0.5200 - val_accuracy: 0.7516\n",
            "\n",
            "Epoch 00382: val_loss improved from 0.51996 to 0.51996, saving model to model_5.hdf5\n",
            "Epoch 383/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5287 - accuracy: 0.7493 - val_loss: 0.5199 - val_accuracy: 0.7516\n",
            "\n",
            "Epoch 00383: val_loss improved from 0.51996 to 0.51992, saving model to model_5.hdf5\n",
            "Epoch 384/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5201 - accuracy: 0.7502 - val_loss: 0.5199 - val_accuracy: 0.7516\n",
            "\n",
            "Epoch 00384: val_loss improved from 0.51992 to 0.51991, saving model to model_5.hdf5\n",
            "Epoch 385/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5214 - accuracy: 0.7540 - val_loss: 0.5199 - val_accuracy: 0.7516\n",
            "\n",
            "Epoch 00385: val_loss improved from 0.51991 to 0.51989, saving model to model_5.hdf5\n",
            "Epoch 386/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5134 - accuracy: 0.7636 - val_loss: 0.5199 - val_accuracy: 0.7516\n",
            "\n",
            "Epoch 00386: val_loss improved from 0.51989 to 0.51987, saving model to model_5.hdf5\n",
            "Epoch 387/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5293 - accuracy: 0.7465 - val_loss: 0.5199 - val_accuracy: 0.7516\n",
            "\n",
            "Epoch 00387: val_loss did not improve from 0.51987\n",
            "Epoch 388/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4991 - accuracy: 0.7614 - val_loss: 0.5199 - val_accuracy: 0.7516\n",
            "\n",
            "Epoch 00388: val_loss improved from 0.51987 to 0.51987, saving model to model_5.hdf5\n",
            "Epoch 389/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5162 - accuracy: 0.7444 - val_loss: 0.5199 - val_accuracy: 0.7516\n",
            "\n",
            "Epoch 00389: val_loss improved from 0.51987 to 0.51986, saving model to model_5.hdf5\n",
            "Epoch 390/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.7529 - val_loss: 0.5198 - val_accuracy: 0.7495\n",
            "\n",
            "Epoch 00390: val_loss improved from 0.51986 to 0.51979, saving model to model_5.hdf5\n",
            "Epoch 391/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5342 - accuracy: 0.7371 - val_loss: 0.5198 - val_accuracy: 0.7495\n",
            "\n",
            "Epoch 00391: val_loss improved from 0.51979 to 0.51977, saving model to model_5.hdf5\n",
            "Epoch 392/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5407 - accuracy: 0.7353 - val_loss: 0.5198 - val_accuracy: 0.7495\n",
            "\n",
            "Epoch 00392: val_loss did not improve from 0.51977\n",
            "Epoch 393/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5117 - accuracy: 0.7640 - val_loss: 0.5197 - val_accuracy: 0.7495\n",
            "\n",
            "Epoch 00393: val_loss improved from 0.51977 to 0.51973, saving model to model_5.hdf5\n",
            "Epoch 394/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5184 - accuracy: 0.7474 - val_loss: 0.5198 - val_accuracy: 0.7495\n",
            "\n",
            "Epoch 00394: val_loss did not improve from 0.51973\n",
            "Epoch 395/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5367 - accuracy: 0.7539 - val_loss: 0.5197 - val_accuracy: 0.7495\n",
            "\n",
            "Epoch 00395: val_loss did not improve from 0.51973\n",
            "Epoch 396/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5178 - accuracy: 0.7378 - val_loss: 0.5198 - val_accuracy: 0.7495\n",
            "\n",
            "Epoch 00396: val_loss did not improve from 0.51973\n",
            "Epoch 397/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5210 - accuracy: 0.7415 - val_loss: 0.5198 - val_accuracy: 0.7495\n",
            "\n",
            "Epoch 00397: val_loss did not improve from 0.51973\n",
            "Epoch 398/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5262 - accuracy: 0.7555 - val_loss: 0.5197 - val_accuracy: 0.7495\n",
            "\n",
            "Epoch 00398: val_loss did not improve from 0.51973\n",
            "Epoch 399/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5103 - accuracy: 0.7586 - val_loss: 0.5198 - val_accuracy: 0.7495\n",
            "\n",
            "Epoch 00399: val_loss did not improve from 0.51973\n",
            "Epoch 400/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5402 - accuracy: 0.7139 - val_loss: 0.5198 - val_accuracy: 0.7495\n",
            "\n",
            "Epoch 00400: val_loss did not improve from 0.51973\n",
            "Epoch 401/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5405 - accuracy: 0.7379 - val_loss: 0.5198 - val_accuracy: 0.7495\n",
            "\n",
            "Epoch 00401: val_loss did not improve from 0.51973\n",
            "Epoch 402/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5287 - accuracy: 0.7475 - val_loss: 0.5198 - val_accuracy: 0.7495\n",
            "\n",
            "Epoch 00402: val_loss did not improve from 0.51973\n",
            "Epoch 403/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5223 - accuracy: 0.7494 - val_loss: 0.5197 - val_accuracy: 0.7495\n",
            "\n",
            "Epoch 00403: val_loss did not improve from 0.51973\n",
            "Epoch 404/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5294 - accuracy: 0.7391 - val_loss: 0.5197 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00404: val_loss did not improve from 0.51973\n",
            "Epoch 405/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5143 - accuracy: 0.7341 - val_loss: 0.5197 - val_accuracy: 0.7495\n",
            "\n",
            "Epoch 00405: val_loss did not improve from 0.51973\n",
            "Epoch 406/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.7561 - val_loss: 0.5197 - val_accuracy: 0.7495\n",
            "\n",
            "Epoch 00406: val_loss improved from 0.51973 to 0.51971, saving model to model_5.hdf5\n",
            "Epoch 407/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5183 - accuracy: 0.7602 - val_loss: 0.5197 - val_accuracy: 0.7495\n",
            "\n",
            "Epoch 00407: val_loss did not improve from 0.51971\n",
            "Epoch 408/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5240 - accuracy: 0.7318 - val_loss: 0.5197 - val_accuracy: 0.7495\n",
            "\n",
            "Epoch 00408: val_loss did not improve from 0.51971\n",
            "Epoch 409/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5098 - accuracy: 0.7660 - val_loss: 0.5197 - val_accuracy: 0.7516\n",
            "\n",
            "Epoch 00409: val_loss improved from 0.51971 to 0.51970, saving model to model_5.hdf5\n",
            "Epoch 410/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5256 - accuracy: 0.7423 - val_loss: 0.5197 - val_accuracy: 0.7495\n",
            "\n",
            "Epoch 00410: val_loss improved from 0.51970 to 0.51968, saving model to model_5.hdf5\n",
            "Epoch 411/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5333 - accuracy: 0.7540 - val_loss: 0.5197 - val_accuracy: 0.7495\n",
            "\n",
            "Epoch 00411: val_loss improved from 0.51968 to 0.51968, saving model to model_5.hdf5\n",
            "Epoch 412/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.7635 - val_loss: 0.5197 - val_accuracy: 0.7495\n",
            "\n",
            "Epoch 00412: val_loss did not improve from 0.51968\n",
            "Epoch 413/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5277 - accuracy: 0.7395 - val_loss: 0.5197 - val_accuracy: 0.7495\n",
            "\n",
            "Epoch 00413: val_loss did not improve from 0.51968\n",
            "Epoch 414/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5392 - accuracy: 0.7473 - val_loss: 0.5197 - val_accuracy: 0.7495\n",
            "\n",
            "Epoch 00414: val_loss did not improve from 0.51968\n",
            "Epoch 415/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5110 - accuracy: 0.7593 - val_loss: 0.5197 - val_accuracy: 0.7495\n",
            "\n",
            "Epoch 00415: val_loss did not improve from 0.51968\n",
            "Epoch 416/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5019 - accuracy: 0.7669 - val_loss: 0.5197 - val_accuracy: 0.7495\n",
            "\n",
            "Epoch 00416: val_loss did not improve from 0.51968\n",
            "Epoch 417/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5212 - accuracy: 0.7526 - val_loss: 0.5198 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00417: val_loss did not improve from 0.51968\n",
            "Epoch 418/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5213 - accuracy: 0.7547 - val_loss: 0.5197 - val_accuracy: 0.7495\n",
            "\n",
            "Epoch 00418: val_loss did not improve from 0.51968\n",
            "Epoch 419/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5020 - accuracy: 0.7661 - val_loss: 0.5197 - val_accuracy: 0.7495\n",
            "\n",
            "Epoch 00419: val_loss did not improve from 0.51968\n",
            "Epoch 420/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4990 - accuracy: 0.7619 - val_loss: 0.5197 - val_accuracy: 0.7495\n",
            "\n",
            "Epoch 00420: val_loss did not improve from 0.51968\n",
            "Epoch 421/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5148 - accuracy: 0.7372 - val_loss: 0.5197 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00421: val_loss did not improve from 0.51968\n",
            "Epoch 422/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5343 - accuracy: 0.7475 - val_loss: 0.5197 - val_accuracy: 0.7495\n",
            "\n",
            "Epoch 00422: val_loss improved from 0.51968 to 0.51967, saving model to model_5.hdf5\n",
            "Epoch 423/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5232 - accuracy: 0.7357 - val_loss: 0.5197 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00423: val_loss did not improve from 0.51967\n",
            "Epoch 424/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5285 - accuracy: 0.7427 - val_loss: 0.5197 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00424: val_loss improved from 0.51967 to 0.51965, saving model to model_5.hdf5\n",
            "Epoch 425/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5409 - accuracy: 0.7349 - val_loss: 0.5197 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00425: val_loss did not improve from 0.51965\n",
            "Epoch 426/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7689 - val_loss: 0.5197 - val_accuracy: 0.7495\n",
            "\n",
            "Epoch 00426: val_loss improved from 0.51965 to 0.51965, saving model to model_5.hdf5\n",
            "Epoch 427/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5218 - accuracy: 0.7404 - val_loss: 0.5196 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00427: val_loss improved from 0.51965 to 0.51964, saving model to model_5.hdf5\n",
            "Epoch 428/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5208 - accuracy: 0.7513 - val_loss: 0.5197 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00428: val_loss did not improve from 0.51964\n",
            "Epoch 429/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7567 - val_loss: 0.5197 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00429: val_loss did not improve from 0.51964\n",
            "Epoch 430/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5172 - accuracy: 0.7452 - val_loss: 0.5196 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00430: val_loss improved from 0.51964 to 0.51962, saving model to model_5.hdf5\n",
            "Epoch 431/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.7536 - val_loss: 0.5196 - val_accuracy: 0.7495\n",
            "\n",
            "Epoch 00431: val_loss improved from 0.51962 to 0.51960, saving model to model_5.hdf5\n",
            "Epoch 432/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5607 - accuracy: 0.7226 - val_loss: 0.5196 - val_accuracy: 0.7495\n",
            "\n",
            "Epoch 00432: val_loss did not improve from 0.51960\n",
            "Epoch 433/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5583 - accuracy: 0.7125 - val_loss: 0.5196 - val_accuracy: 0.7495\n",
            "\n",
            "Epoch 00433: val_loss did not improve from 0.51960\n",
            "Epoch 434/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5287 - accuracy: 0.7443 - val_loss: 0.5196 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00434: val_loss did not improve from 0.51960\n",
            "Epoch 435/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5562 - accuracy: 0.7129 - val_loss: 0.5196 - val_accuracy: 0.7495\n",
            "\n",
            "Epoch 00435: val_loss did not improve from 0.51960\n",
            "Epoch 436/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5533 - accuracy: 0.7307 - val_loss: 0.5197 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00436: val_loss did not improve from 0.51960\n",
            "Epoch 437/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5328 - accuracy: 0.7367 - val_loss: 0.5197 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00437: val_loss did not improve from 0.51960\n",
            "Epoch 438/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4923 - accuracy: 0.7561 - val_loss: 0.5197 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00438: val_loss did not improve from 0.51960\n",
            "Epoch 439/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5122 - accuracy: 0.7743 - val_loss: 0.5197 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00439: val_loss did not improve from 0.51960\n",
            "Epoch 440/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5354 - accuracy: 0.7385 - val_loss: 0.5197 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00440: val_loss did not improve from 0.51960\n",
            "Epoch 441/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4944 - accuracy: 0.7621 - val_loss: 0.5197 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00441: val_loss did not improve from 0.51960\n",
            "Epoch 442/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5277 - accuracy: 0.7563 - val_loss: 0.5196 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00442: val_loss did not improve from 0.51960\n",
            "Epoch 443/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5147 - accuracy: 0.7447 - val_loss: 0.5196 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00443: val_loss did not improve from 0.51960\n",
            "Epoch 444/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5204 - accuracy: 0.7565 - val_loss: 0.5196 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00444: val_loss did not improve from 0.51960\n",
            "Epoch 445/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5453 - accuracy: 0.7177 - val_loss: 0.5197 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00445: val_loss did not improve from 0.51960\n",
            "Epoch 446/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7508 - val_loss: 0.5197 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00446: val_loss did not improve from 0.51960\n",
            "Epoch 447/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5302 - accuracy: 0.7474 - val_loss: 0.5197 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00447: val_loss did not improve from 0.51960\n",
            "Epoch 448/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5239 - accuracy: 0.7288 - val_loss: 0.5197 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00448: val_loss did not improve from 0.51960\n",
            "Epoch 449/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5355 - accuracy: 0.7448 - val_loss: 0.5197 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00449: val_loss did not improve from 0.51960\n",
            "Epoch 450/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5321 - accuracy: 0.7438 - val_loss: 0.5196 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00450: val_loss did not improve from 0.51960\n",
            "Epoch 451/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5358 - accuracy: 0.7299 - val_loss: 0.5196 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00451: val_loss did not improve from 0.51960\n",
            "Epoch 452/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5175 - accuracy: 0.7491 - val_loss: 0.5196 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00452: val_loss did not improve from 0.51960\n",
            "Epoch 453/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5270 - accuracy: 0.7514 - val_loss: 0.5196 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00453: val_loss did not improve from 0.51960\n",
            "Epoch 454/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5142 - accuracy: 0.7579 - val_loss: 0.5196 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00454: val_loss did not improve from 0.51960\n",
            "Epoch 455/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7612 - val_loss: 0.5196 - val_accuracy: 0.7495\n",
            "\n",
            "Epoch 00455: val_loss did not improve from 0.51960\n",
            "Epoch 456/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4960 - accuracy: 0.7745 - val_loss: 0.5196 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00456: val_loss did not improve from 0.51960\n",
            "Epoch 457/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5167 - accuracy: 0.7348 - val_loss: 0.5196 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00457: val_loss improved from 0.51960 to 0.51956, saving model to model_5.hdf5\n",
            "Epoch 458/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5207 - accuracy: 0.7471 - val_loss: 0.5195 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00458: val_loss improved from 0.51956 to 0.51953, saving model to model_5.hdf5\n",
            "Epoch 459/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5126 - accuracy: 0.7567 - val_loss: 0.5195 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00459: val_loss improved from 0.51953 to 0.51952, saving model to model_5.hdf5\n",
            "Epoch 460/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7704 - val_loss: 0.5195 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00460: val_loss did not improve from 0.51952\n",
            "Epoch 461/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5289 - accuracy: 0.7391 - val_loss: 0.5196 - val_accuracy: 0.7495\n",
            "\n",
            "Epoch 00461: val_loss did not improve from 0.51952\n",
            "Epoch 462/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5248 - accuracy: 0.7401 - val_loss: 0.5195 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00462: val_loss improved from 0.51952 to 0.51948, saving model to model_5.hdf5\n",
            "Epoch 463/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4982 - accuracy: 0.7633 - val_loss: 0.5195 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00463: val_loss improved from 0.51948 to 0.51946, saving model to model_5.hdf5\n",
            "Epoch 464/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7582 - val_loss: 0.5194 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00464: val_loss improved from 0.51946 to 0.51943, saving model to model_5.hdf5\n",
            "Epoch 465/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7616 - val_loss: 0.5194 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00465: val_loss improved from 0.51943 to 0.51942, saving model to model_5.hdf5\n",
            "Epoch 466/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5249 - accuracy: 0.7392 - val_loss: 0.5194 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00466: val_loss improved from 0.51942 to 0.51941, saving model to model_5.hdf5\n",
            "Epoch 467/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5111 - accuracy: 0.7562 - val_loss: 0.5194 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00467: val_loss improved from 0.51941 to 0.51941, saving model to model_5.hdf5\n",
            "Epoch 468/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7699 - val_loss: 0.5195 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00468: val_loss did not improve from 0.51941\n",
            "Epoch 469/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5343 - accuracy: 0.7305 - val_loss: 0.5194 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00469: val_loss did not improve from 0.51941\n",
            "Epoch 470/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5266 - accuracy: 0.7427 - val_loss: 0.5194 - val_accuracy: 0.7495\n",
            "\n",
            "Epoch 00470: val_loss improved from 0.51941 to 0.51940, saving model to model_5.hdf5\n",
            "Epoch 471/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5254 - accuracy: 0.7432 - val_loss: 0.5194 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00471: val_loss did not improve from 0.51940\n",
            "Epoch 472/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5271 - accuracy: 0.7521 - val_loss: 0.5194 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00472: val_loss did not improve from 0.51940\n",
            "Epoch 473/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5351 - accuracy: 0.7452 - val_loss: 0.5194 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00473: val_loss improved from 0.51940 to 0.51939, saving model to model_5.hdf5\n",
            "Epoch 474/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5183 - accuracy: 0.7458 - val_loss: 0.5194 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00474: val_loss improved from 0.51939 to 0.51938, saving model to model_5.hdf5\n",
            "Epoch 475/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5141 - accuracy: 0.7657 - val_loss: 0.5194 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00475: val_loss improved from 0.51938 to 0.51936, saving model to model_5.hdf5\n",
            "Epoch 476/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7659 - val_loss: 0.5194 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00476: val_loss did not improve from 0.51936\n",
            "Epoch 477/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5112 - accuracy: 0.7670 - val_loss: 0.5194 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00477: val_loss improved from 0.51936 to 0.51936, saving model to model_5.hdf5\n",
            "Epoch 478/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.7561 - val_loss: 0.5193 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00478: val_loss improved from 0.51936 to 0.51931, saving model to model_5.hdf5\n",
            "Epoch 479/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4899 - accuracy: 0.7694 - val_loss: 0.5193 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00479: val_loss improved from 0.51931 to 0.51928, saving model to model_5.hdf5\n",
            "Epoch 480/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5474 - accuracy: 0.7318 - val_loss: 0.5193 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00480: val_loss did not improve from 0.51928\n",
            "Epoch 481/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5174 - accuracy: 0.7557 - val_loss: 0.5193 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00481: val_loss did not improve from 0.51928\n",
            "Epoch 482/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5137 - accuracy: 0.7471 - val_loss: 0.5193 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00482: val_loss did not improve from 0.51928\n",
            "Epoch 483/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5232 - accuracy: 0.7421 - val_loss: 0.5193 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00483: val_loss did not improve from 0.51928\n",
            "Epoch 484/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5281 - accuracy: 0.7247 - val_loss: 0.5193 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00484: val_loss did not improve from 0.51928\n",
            "Epoch 485/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5251 - accuracy: 0.7477 - val_loss: 0.5193 - val_accuracy: 0.7495\n",
            "\n",
            "Epoch 00485: val_loss did not improve from 0.51928\n",
            "Epoch 486/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5341 - accuracy: 0.7553 - val_loss: 0.5193 - val_accuracy: 0.7495\n",
            "\n",
            "Epoch 00486: val_loss did not improve from 0.51928\n",
            "Epoch 487/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5266 - accuracy: 0.7367 - val_loss: 0.5193 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00487: val_loss did not improve from 0.51928\n",
            "Epoch 488/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5306 - accuracy: 0.7495 - val_loss: 0.5193 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00488: val_loss did not improve from 0.51928\n",
            "Epoch 489/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5315 - accuracy: 0.7436 - val_loss: 0.5193 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00489: val_loss did not improve from 0.51928\n",
            "Epoch 490/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7638 - val_loss: 0.5193 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00490: val_loss did not improve from 0.51928\n",
            "Epoch 491/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5019 - accuracy: 0.7553 - val_loss: 0.5192 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00491: val_loss improved from 0.51928 to 0.51925, saving model to model_5.hdf5\n",
            "Epoch 492/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5497 - accuracy: 0.7219 - val_loss: 0.5192 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00492: val_loss improved from 0.51925 to 0.51924, saving model to model_5.hdf5\n",
            "Epoch 493/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5149 - accuracy: 0.7601 - val_loss: 0.5193 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00493: val_loss did not improve from 0.51924\n",
            "Epoch 494/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.7535 - val_loss: 0.5193 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00494: val_loss did not improve from 0.51924\n",
            "Epoch 495/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5294 - accuracy: 0.7409 - val_loss: 0.5193 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00495: val_loss did not improve from 0.51924\n",
            "Epoch 496/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5164 - accuracy: 0.7448 - val_loss: 0.5193 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00496: val_loss did not improve from 0.51924\n",
            "Epoch 497/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5427 - accuracy: 0.7384 - val_loss: 0.5193 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00497: val_loss did not improve from 0.51924\n",
            "Epoch 498/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5242 - accuracy: 0.7551 - val_loss: 0.5193 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00498: val_loss did not improve from 0.51924\n",
            "Epoch 499/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5440 - accuracy: 0.7490 - val_loss: 0.5192 - val_accuracy: 0.7495\n",
            "\n",
            "Epoch 00499: val_loss did not improve from 0.51924\n",
            "Epoch 500/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5316 - accuracy: 0.7273 - val_loss: 0.5192 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00500: val_loss did not improve from 0.51924\n",
            "Epoch 501/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5695 - accuracy: 0.7022 - val_loss: 0.5193 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00501: val_loss did not improve from 0.51924\n",
            "Epoch 502/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5178 - accuracy: 0.7468 - val_loss: 0.5193 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00502: val_loss did not improve from 0.51924\n",
            "Epoch 503/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5232 - accuracy: 0.7483 - val_loss: 0.5193 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00503: val_loss did not improve from 0.51924\n",
            "Epoch 504/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5088 - accuracy: 0.7742 - val_loss: 0.5193 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00504: val_loss did not improve from 0.51924\n",
            "Epoch 505/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5376 - accuracy: 0.7495 - val_loss: 0.5193 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00505: val_loss did not improve from 0.51924\n",
            "Epoch 506/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5205 - accuracy: 0.7512 - val_loss: 0.5193 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00506: val_loss did not improve from 0.51924\n",
            "Epoch 507/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.7591 - val_loss: 0.5193 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00507: val_loss did not improve from 0.51924\n",
            "Epoch 508/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5306 - accuracy: 0.7403 - val_loss: 0.5193 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00508: val_loss did not improve from 0.51924\n",
            "Epoch 509/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5430 - accuracy: 0.7337 - val_loss: 0.5192 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00509: val_loss did not improve from 0.51924\n",
            "Epoch 510/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5289 - accuracy: 0.7458 - val_loss: 0.5193 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00510: val_loss did not improve from 0.51924\n",
            "Epoch 511/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5003 - accuracy: 0.7666 - val_loss: 0.5193 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00511: val_loss did not improve from 0.51924\n",
            "Epoch 512/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5158 - accuracy: 0.7491 - val_loss: 0.5193 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00512: val_loss did not improve from 0.51924\n",
            "Epoch 513/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5175 - accuracy: 0.7433 - val_loss: 0.5193 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00513: val_loss did not improve from 0.51924\n",
            "Epoch 514/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5245 - accuracy: 0.7402 - val_loss: 0.5193 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00514: val_loss did not improve from 0.51924\n",
            "Epoch 515/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5096 - accuracy: 0.7542 - val_loss: 0.5192 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00515: val_loss improved from 0.51924 to 0.51923, saving model to model_5.hdf5\n",
            "Epoch 516/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5456 - accuracy: 0.7266 - val_loss: 0.5192 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00516: val_loss did not improve from 0.51923\n",
            "Epoch 517/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5310 - accuracy: 0.7346 - val_loss: 0.5193 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00517: val_loss did not improve from 0.51923\n",
            "Epoch 518/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5141 - accuracy: 0.7508 - val_loss: 0.5193 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00518: val_loss did not improve from 0.51923\n",
            "Epoch 519/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5212 - accuracy: 0.7371 - val_loss: 0.5193 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00519: val_loss did not improve from 0.51923\n",
            "Epoch 520/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5445 - accuracy: 0.7319 - val_loss: 0.5193 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00520: val_loss did not improve from 0.51923\n",
            "Epoch 521/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5284 - accuracy: 0.7423 - val_loss: 0.5193 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00521: val_loss did not improve from 0.51923\n",
            "Epoch 522/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5213 - accuracy: 0.7410 - val_loss: 0.5192 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00522: val_loss did not improve from 0.51923\n",
            "Epoch 523/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5145 - accuracy: 0.7590 - val_loss: 0.5192 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00523: val_loss did not improve from 0.51923\n",
            "Epoch 524/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5246 - accuracy: 0.7443 - val_loss: 0.5192 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00524: val_loss improved from 0.51923 to 0.51921, saving model to model_5.hdf5\n",
            "Epoch 525/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4923 - accuracy: 0.7656 - val_loss: 0.5192 - val_accuracy: 0.7495\n",
            "\n",
            "Epoch 00525: val_loss improved from 0.51921 to 0.51916, saving model to model_5.hdf5\n",
            "Epoch 526/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5174 - accuracy: 0.7554 - val_loss: 0.5191 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00526: val_loss improved from 0.51916 to 0.51915, saving model to model_5.hdf5\n",
            "Epoch 527/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.7392 - val_loss: 0.5192 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00527: val_loss did not improve from 0.51915\n",
            "Epoch 528/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4889 - accuracy: 0.7673 - val_loss: 0.5192 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00528: val_loss did not improve from 0.51915\n",
            "Epoch 529/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5298 - accuracy: 0.7343 - val_loss: 0.5192 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00529: val_loss did not improve from 0.51915\n",
            "Epoch 530/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.7478 - val_loss: 0.5192 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00530: val_loss did not improve from 0.51915\n",
            "Epoch 531/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5172 - accuracy: 0.7391 - val_loss: 0.5192 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00531: val_loss did not improve from 0.51915\n",
            "Epoch 532/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5274 - accuracy: 0.7329 - val_loss: 0.5192 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00532: val_loss did not improve from 0.51915\n",
            "Epoch 533/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4896 - accuracy: 0.7570 - val_loss: 0.5192 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00533: val_loss did not improve from 0.51915\n",
            "Epoch 534/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5158 - accuracy: 0.7454 - val_loss: 0.5191 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00534: val_loss improved from 0.51915 to 0.51912, saving model to model_5.hdf5\n",
            "Epoch 535/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5225 - accuracy: 0.7391 - val_loss: 0.5192 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00535: val_loss did not improve from 0.51912\n",
            "Epoch 536/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5294 - accuracy: 0.7404 - val_loss: 0.5192 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00536: val_loss did not improve from 0.51912\n",
            "Epoch 537/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5223 - accuracy: 0.7417 - val_loss: 0.5192 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00537: val_loss did not improve from 0.51912\n",
            "Epoch 538/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5276 - accuracy: 0.7533 - val_loss: 0.5191 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00538: val_loss did not improve from 0.51912\n",
            "Epoch 539/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5220 - accuracy: 0.7329 - val_loss: 0.5191 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00539: val_loss did not improve from 0.51912\n",
            "Epoch 540/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5146 - accuracy: 0.7542 - val_loss: 0.5192 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00540: val_loss did not improve from 0.51912\n",
            "Epoch 541/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7688 - val_loss: 0.5192 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00541: val_loss did not improve from 0.51912\n",
            "Epoch 542/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.7508 - val_loss: 0.5191 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00542: val_loss did not improve from 0.51912\n",
            "Epoch 543/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7559 - val_loss: 0.5191 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00543: val_loss did not improve from 0.51912\n",
            "Epoch 544/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.7381 - val_loss: 0.5192 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00544: val_loss did not improve from 0.51912\n",
            "Epoch 545/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5409 - accuracy: 0.7301 - val_loss: 0.5192 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00545: val_loss did not improve from 0.51912\n",
            "Epoch 546/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5265 - accuracy: 0.7369 - val_loss: 0.5191 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00546: val_loss did not improve from 0.51912\n",
            "Epoch 547/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5251 - accuracy: 0.7372 - val_loss: 0.5191 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00547: val_loss improved from 0.51912 to 0.51910, saving model to model_5.hdf5\n",
            "Epoch 548/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5022 - accuracy: 0.7594 - val_loss: 0.5191 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00548: val_loss improved from 0.51910 to 0.51907, saving model to model_5.hdf5\n",
            "Epoch 549/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5312 - accuracy: 0.7449 - val_loss: 0.5190 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00549: val_loss improved from 0.51907 to 0.51904, saving model to model_5.hdf5\n",
            "Epoch 550/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5280 - accuracy: 0.7433 - val_loss: 0.5191 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00550: val_loss did not improve from 0.51904\n",
            "Epoch 551/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5200 - accuracy: 0.7500 - val_loss: 0.5191 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00551: val_loss did not improve from 0.51904\n",
            "Epoch 552/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5129 - accuracy: 0.7487 - val_loss: 0.5190 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00552: val_loss did not improve from 0.51904\n",
            "Epoch 553/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5319 - accuracy: 0.7302 - val_loss: 0.5190 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00553: val_loss improved from 0.51904 to 0.51903, saving model to model_5.hdf5\n",
            "Epoch 554/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4966 - accuracy: 0.7666 - val_loss: 0.5190 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00554: val_loss did not improve from 0.51903\n",
            "Epoch 555/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4932 - accuracy: 0.7756 - val_loss: 0.5190 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00555: val_loss did not improve from 0.51903\n",
            "Epoch 556/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5315 - accuracy: 0.7473 - val_loss: 0.5191 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00556: val_loss did not improve from 0.51903\n",
            "Epoch 557/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5361 - accuracy: 0.7459 - val_loss: 0.5190 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00557: val_loss did not improve from 0.51903\n",
            "Epoch 558/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5206 - accuracy: 0.7364 - val_loss: 0.5191 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00558: val_loss did not improve from 0.51903\n",
            "Epoch 559/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5211 - accuracy: 0.7390 - val_loss: 0.5191 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00559: val_loss did not improve from 0.51903\n",
            "Epoch 560/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4958 - accuracy: 0.7713 - val_loss: 0.5191 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00560: val_loss did not improve from 0.51903\n",
            "Epoch 561/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5017 - accuracy: 0.7534 - val_loss: 0.5191 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00561: val_loss did not improve from 0.51903\n",
            "Epoch 562/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5372 - accuracy: 0.7329 - val_loss: 0.5191 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00562: val_loss did not improve from 0.51903\n",
            "Epoch 563/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5144 - accuracy: 0.7428 - val_loss: 0.5191 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00563: val_loss did not improve from 0.51903\n",
            "Epoch 564/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4938 - accuracy: 0.7689 - val_loss: 0.5191 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00564: val_loss did not improve from 0.51903\n",
            "Epoch 565/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5264 - accuracy: 0.7296 - val_loss: 0.5191 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00565: val_loss did not improve from 0.51903\n",
            "Epoch 566/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7662 - val_loss: 0.5191 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00566: val_loss did not improve from 0.51903\n",
            "Epoch 567/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5007 - accuracy: 0.7690 - val_loss: 0.5192 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00567: val_loss did not improve from 0.51903\n",
            "Epoch 568/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5230 - accuracy: 0.7548 - val_loss: 0.5191 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00568: val_loss did not improve from 0.51903\n",
            "Epoch 569/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5181 - accuracy: 0.7495 - val_loss: 0.5191 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00569: val_loss did not improve from 0.51903\n",
            "Epoch 570/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5380 - accuracy: 0.7360 - val_loss: 0.5191 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00570: val_loss did not improve from 0.51903\n",
            "Epoch 571/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5547 - accuracy: 0.7330 - val_loss: 0.5191 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00571: val_loss did not improve from 0.51903\n",
            "Epoch 572/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 0.7623 - val_loss: 0.5191 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00572: val_loss did not improve from 0.51903\n",
            "Epoch 573/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5237 - accuracy: 0.7372 - val_loss: 0.5191 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00573: val_loss did not improve from 0.51903\n",
            "Epoch 574/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5195 - accuracy: 0.7544 - val_loss: 0.5191 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00574: val_loss did not improve from 0.51903\n",
            "Epoch 575/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7486 - val_loss: 0.5191 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00575: val_loss did not improve from 0.51903\n",
            "Epoch 576/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5214 - accuracy: 0.7484 - val_loss: 0.5191 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00576: val_loss did not improve from 0.51903\n",
            "Epoch 577/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5323 - accuracy: 0.7491 - val_loss: 0.5191 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00577: val_loss did not improve from 0.51903\n",
            "Epoch 578/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5159 - accuracy: 0.7431 - val_loss: 0.5191 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00578: val_loss did not improve from 0.51903\n",
            "Epoch 579/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5136 - accuracy: 0.7417 - val_loss: 0.5192 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00579: val_loss did not improve from 0.51903\n",
            "Epoch 580/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5189 - accuracy: 0.7378 - val_loss: 0.5191 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00580: val_loss did not improve from 0.51903\n",
            "Epoch 581/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5315 - accuracy: 0.7436 - val_loss: 0.5191 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00581: val_loss did not improve from 0.51903\n",
            "Epoch 582/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5285 - accuracy: 0.7291 - val_loss: 0.5192 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00582: val_loss did not improve from 0.51903\n",
            "Epoch 583/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5179 - accuracy: 0.7480 - val_loss: 0.5192 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00583: val_loss did not improve from 0.51903\n",
            "Epoch 584/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.7470 - val_loss: 0.5192 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00584: val_loss did not improve from 0.51903\n",
            "Epoch 585/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5175 - accuracy: 0.7520 - val_loss: 0.5191 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00585: val_loss did not improve from 0.51903\n",
            "Epoch 586/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5316 - accuracy: 0.7451 - val_loss: 0.5191 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00586: val_loss did not improve from 0.51903\n",
            "Epoch 587/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5173 - accuracy: 0.7503 - val_loss: 0.5191 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00587: val_loss did not improve from 0.51903\n",
            "Epoch 588/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4960 - accuracy: 0.7619 - val_loss: 0.5191 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00588: val_loss did not improve from 0.51903\n",
            "Epoch 589/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5111 - accuracy: 0.7472 - val_loss: 0.5191 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00589: val_loss did not improve from 0.51903\n",
            "Epoch 590/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5001 - accuracy: 0.7608 - val_loss: 0.5191 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00590: val_loss did not improve from 0.51903\n",
            "Epoch 591/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5261 - accuracy: 0.7425 - val_loss: 0.5191 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00591: val_loss did not improve from 0.51903\n",
            "Epoch 592/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5238 - accuracy: 0.7486 - val_loss: 0.5191 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00592: val_loss did not improve from 0.51903\n",
            "Epoch 593/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5099 - accuracy: 0.7470 - val_loss: 0.5191 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00593: val_loss did not improve from 0.51903\n",
            "Epoch 594/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5143 - accuracy: 0.7535 - val_loss: 0.5191 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00594: val_loss did not improve from 0.51903\n",
            "Epoch 595/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5253 - accuracy: 0.7408 - val_loss: 0.5191 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00595: val_loss did not improve from 0.51903\n",
            "Epoch 596/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4982 - accuracy: 0.7612 - val_loss: 0.5191 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00596: val_loss did not improve from 0.51903\n",
            "Epoch 597/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5143 - accuracy: 0.7487 - val_loss: 0.5191 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00597: val_loss did not improve from 0.51903\n",
            "Epoch 598/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4881 - accuracy: 0.7795 - val_loss: 0.5191 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00598: val_loss did not improve from 0.51903\n",
            "Epoch 599/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5158 - accuracy: 0.7670 - val_loss: 0.5191 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00599: val_loss did not improve from 0.51903\n",
            "Epoch 600/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5167 - accuracy: 0.7472 - val_loss: 0.5191 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00600: val_loss did not improve from 0.51903\n",
            "Epoch 601/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5122 - accuracy: 0.7528 - val_loss: 0.5191 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00601: val_loss did not improve from 0.51903\n",
            "Epoch 602/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7591 - val_loss: 0.5191 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00602: val_loss did not improve from 0.51903\n",
            "Epoch 603/1000\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7612 - val_loss: 0.5191 - val_accuracy: 0.7474\n",
            "\n",
            "Epoch 00603: val_loss did not improve from 0.51903\n",
            "Epoch 00603: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "4-PZnUkGfdd3",
        "outputId": "934d983b-4e57-42d8-beab-a89bdd280708"
      },
      "source": [
        "plt.plot(history_5.history['accuracy'])\n",
        "plt.plot(history_5.history['val_accuracy'])\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training data', 'validation data'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "zIg_DlQRfeEG",
        "outputId": "dc3e54f7-e08d-41b2-87a1-695f2699b4b5"
      },
      "source": [
        "plt.plot(history_5.history['loss'])\n",
        "plt.plot(history_5.history['val_loss'])\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training data', 'validation data'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-xeneTug-kL"
      },
      "source": [
        "model_5.load_weights('model_5.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtqHuZjV3czU",
        "outputId": "4135d6bc-6611-48aa-adab-b9971b11d212"
      },
      "source": [
        "P5 = model_5.predict(XTRAIN)\n",
        "accuracy_train5 = model_5.evaluate(XTRAIN, YTRAIN)\n",
        " \n",
        "print(accuracy_train5)\n",
        " \n",
        " \n",
        "P6 = model_5.predict(XVALID)\n",
        "accuracy_valid5 = model_5.evaluate(XVALID, YVALID)\n",
        " \n",
        "print(accuracy_valid5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "35/35 [==============================] - 0s 1ms/step - loss: 0.5193 - accuracy: 0.7482\n",
            "[0.5193459391593933, 0.7482143044471741]\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.5190 - accuracy: 0.7474\n",
            "[0.5190311074256897, 0.7473903894424438]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIIO_vOq5xJQ",
        "outputId": "21f812bc-aeab-4a03-a4fa-676f20d3e3bf"
      },
      "source": [
        "mae(accuracy_train5, accuracy_valid5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0005693733692169189"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqdsbosW3qQJ"
      },
      "source": [
        "prediction = model_5.predict(XTRAIN)\n",
        "new_accuracy = accuracy_score(YTRAIN, prediction.round())\n",
        "new_precision = precision_score(YTRAIN, prediction.round())\n",
        "new_recall = recall_score(YTRAIN, prediction.round())\n",
        "new_f1 = f1_score(YTRAIN, prediction.round())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsjpbW0E32nY",
        "outputId": "9343f9e2-ccb9-4366-f405-330aa4c183df"
      },
      "source": [
        "print(new_precision)\n",
        "print(new_recall)\n",
        "print(new_f1)\n",
        "print(new_accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7728813559322034\n",
            "0.7549668874172185\n",
            "0.7638190954773869\n",
            "0.7482142857142857\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9o9jvIN5rW5"
      },
      "source": [
        "model_6 = Sequential()\n",
        "model_6.add(Dense(1, input_dim = len(XTRAIN[0, :]), activation='sigmoid'))\n",
        "model_6.compile(loss='binary_crossentropy', optimizer = 'rmsprop', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jxr9mRe958Vl",
        "outputId": "f277ea34-c353-45f5-c4f6-f637ce6d1987"
      },
      "source": [
        "history_6 = model_6.fit(XTRAIN, YTRAIN, epochs=64, batch_size=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/64\n",
            "112/112 [==============================] - 0s 905us/step - loss: 0.7281 - accuracy: 0.4466\n",
            "Epoch 2/64\n",
            "112/112 [==============================] - 0s 865us/step - loss: 0.7140 - accuracy: 0.4866\n",
            "Epoch 3/64\n",
            "112/112 [==============================] - 0s 930us/step - loss: 0.7075 - accuracy: 0.5168\n",
            "Epoch 4/64\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.7029 - accuracy: 0.5201\n",
            "Epoch 5/64\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.6983 - accuracy: 0.5430\n",
            "Epoch 6/64\n",
            "112/112 [==============================] - 0s 993us/step - loss: 0.6937 - accuracy: 0.5420\n",
            "Epoch 7/64\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.6882 - accuracy: 0.5536\n",
            "Epoch 8/64\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.6821 - accuracy: 0.5799\n",
            "Epoch 9/64\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.6751 - accuracy: 0.5885\n",
            "Epoch 10/64\n",
            "112/112 [==============================] - 0s 1000us/step - loss: 0.6789 - accuracy: 0.5596\n",
            "Epoch 11/64\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.6709 - accuracy: 0.5740\n",
            "Epoch 12/64\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.6707 - accuracy: 0.5884\n",
            "Epoch 13/64\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.6637 - accuracy: 0.6071\n",
            "Epoch 14/64\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.6576 - accuracy: 0.6248\n",
            "Epoch 15/64\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.6530 - accuracy: 0.6350\n",
            "Epoch 16/64\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.6476 - accuracy: 0.6606\n",
            "Epoch 17/64\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.6437 - accuracy: 0.6838\n",
            "Epoch 18/64\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.6443 - accuracy: 0.6946\n",
            "Epoch 19/64\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.6354 - accuracy: 0.6925\n",
            "Epoch 20/64\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.6354 - accuracy: 0.6970\n",
            "Epoch 21/64\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.6319 - accuracy: 0.7108\n",
            "Epoch 22/64\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.6367 - accuracy: 0.7033\n",
            "Epoch 23/64\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.6270 - accuracy: 0.7093\n",
            "Epoch 24/64\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.6194 - accuracy: 0.7142\n",
            "Epoch 25/64\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.6180 - accuracy: 0.7276\n",
            "Epoch 26/64\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.6239 - accuracy: 0.6991\n",
            "Epoch 27/64\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.6130 - accuracy: 0.7338\n",
            "Epoch 28/64\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.6219 - accuracy: 0.6828\n",
            "Epoch 29/64\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.6065 - accuracy: 0.7329\n",
            "Epoch 30/64\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.6083 - accuracy: 0.7110\n",
            "Epoch 31/64\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.5989 - accuracy: 0.7309\n",
            "Epoch 32/64\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.5995 - accuracy: 0.7381\n",
            "Epoch 33/64\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.6165 - accuracy: 0.7020\n",
            "Epoch 34/64\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.5992 - accuracy: 0.7155\n",
            "Epoch 35/64\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.5908 - accuracy: 0.7281\n",
            "Epoch 36/64\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.6015 - accuracy: 0.7056\n",
            "Epoch 37/64\n",
            "112/112 [==============================] - 0s 999us/step - loss: 0.5873 - accuracy: 0.7296\n",
            "Epoch 38/64\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.5942 - accuracy: 0.7204\n",
            "Epoch 39/64\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.5953 - accuracy: 0.7164\n",
            "Epoch 40/64\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.5881 - accuracy: 0.7283\n",
            "Epoch 41/64\n",
            "112/112 [==============================] - 0s 992us/step - loss: 0.5864 - accuracy: 0.7188\n",
            "Epoch 42/64\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.5943 - accuracy: 0.6988\n",
            "Epoch 43/64\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.5714 - accuracy: 0.7526\n",
            "Epoch 44/64\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.5806 - accuracy: 0.7293\n",
            "Epoch 45/64\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.5684 - accuracy: 0.7352\n",
            "Epoch 46/64\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.5704 - accuracy: 0.7544\n",
            "Epoch 47/64\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.5825 - accuracy: 0.7321\n",
            "Epoch 48/64\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.5593 - accuracy: 0.7465\n",
            "Epoch 49/64\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.5811 - accuracy: 0.7259\n",
            "Epoch 50/64\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.5786 - accuracy: 0.7250\n",
            "Epoch 51/64\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.5820 - accuracy: 0.7306\n",
            "Epoch 52/64\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.5703 - accuracy: 0.7348\n",
            "Epoch 53/64\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.5568 - accuracy: 0.7327\n",
            "Epoch 54/64\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.5542 - accuracy: 0.7417\n",
            "Epoch 55/64\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.5657 - accuracy: 0.7291\n",
            "Epoch 56/64\n",
            "112/112 [==============================] - 0s 991us/step - loss: 0.5646 - accuracy: 0.7323\n",
            "Epoch 57/64\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.5604 - accuracy: 0.7235\n",
            "Epoch 58/64\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.5787 - accuracy: 0.7127\n",
            "Epoch 59/64\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.5616 - accuracy: 0.7500\n",
            "Epoch 60/64\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.5614 - accuracy: 0.7443\n",
            "Epoch 61/64\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.5659 - accuracy: 0.7448\n",
            "Epoch 62/64\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.5607 - accuracy: 0.7362\n",
            "Epoch 63/64\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.5559 - accuracy: 0.7405\n",
            "Epoch 64/64\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.5622 - accuracy: 0.7130\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsvIGv6eY2Vx",
        "outputId": "717f8278-3450-4a65-885f-b27a81629c5d"
      },
      "source": [
        "# weights-Calculated \n",
        "print('Model weights - w0(slope m), bias):')\n",
        "w0 = model_6.layers[0].get_weights()[0][0]\n",
        "w1 = model_6.layers[0].get_weights()[0][1]\n",
        "w2 = model_6.layers[0].get_weights()[0][2]\n",
        "w3 = model_6.layers[0].get_weights()[0][3]\n",
        "w4 = model_6.layers[0].get_weights()[0][4]\n",
        "w5 = model_6.layers[0].get_weights()[0][5]\n",
        "w6 = model_6.layers[0].get_weights()[0][6]\n",
        "w7 = model_6.layers[0].get_weights()[0][7]\n",
        "w8 = model_6.layers[0].get_weights()[0][8]\n",
        "w9 = model_6.layers[0].get_weights()[0][9]\n",
        "w10 = model_6.layers[0].get_weights()[0][10]\n",
        "b0 = model_6.layers[0].get_weights()[1]\n",
        "\n",
        "print(w0, w1, w2, w3, w4, w5, w6, w7, w8, w9, w10)\n",
        "print(b0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model weights - w0(slope m), bias):\n",
            "[ 0.08] [-1.96] [ 0.84] [-0.06] [-1.33] [-0.51] [-1.60] [-0.36] [ 0.52] [ 1.50] [ 2.63]\n",
            "[-0.17]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyNhqRS33e_N",
        "outputId": "211c03db-f091-46ac-ce62-45453f9f7d05"
      },
      "source": [
        "prediction = model_6.predict(XTRAIN)\n",
        "\n",
        "print(YTRAIN[:5])\n",
        "print(prediction[:5].T)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 1.00  1.00  0.00  1.00  0.00]\n",
            "[[ 0.46  0.88  0.36  0.40  0.62]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKZTtIXRudCt"
      },
      "source": [
        "import math\n",
        "\n",
        "def sigmoid(s):\n",
        "  return 1/(1+math.exp(-s))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7j_Z6Wt2HME"
      },
      "source": [
        "Z = (w0*XTRAIN[:, 0]+w1*XTRAIN[:, 1]+w2*XTRAIN[:, 2]+w3*XTRAIN[:, 3]+w4*XTRAIN[:, 4]+w5*XTRAIN[:, 5]+w6*XTRAIN[:, 6]+w7*XTRAIN[:, 7]+w8*XTRAIN[:, 8]+w9*XTRAIN[:, 9]+w10*XTRAIN[:, 10])+b0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJCw55O05BJ4",
        "outputId": "0565a517-d0a3-4741-b394-e76c5fed6427"
      },
      "source": [
        "print(Z[:5].T)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-0.15  1.96 -0.56 -0.42  0.50]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvffEwqOvX52",
        "outputId": "e2f2b1a9-6d5b-4dbb-cdb9-92051aa40494"
      },
      "source": [
        "print(sigmoid(Z[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8768293398952487\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sVVPmlExwjR",
        "outputId": "47d1463d-4837-4d72-dad6-108b7a0b042c"
      },
      "source": [
        "print(len(XTRAIN[:,0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1120\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2v8FL1MA-Io",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b921601-1ad5-47d9-b624-af274c9abc17"
      },
      "source": [
        "val=[]\n",
        "def custom_fun():\n",
        "  for j in range(len(XTRAIN[:,0])):\n",
        "    val.append(sigmoid(Z[j]))\n",
        "custom_fun()\n",
        "\n",
        "valu = [ '%.2f' % elem for elem in val ]\n",
        "print(valu[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['0.46', '0.88', '0.36', '0.40', '0.62']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juq3XQFSqwBO"
      },
      "source": [
        "# output as input parameter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sotnKGM97wq"
      },
      "source": [
        "import numpy as np\n",
        "dataset1 = np.genfromtxt('winequality-red0.csv', delimiter = ',', skip_header = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BkqBhZb-EIe"
      },
      "source": [
        "A = dataset1[:, ]\n",
        "B = dataset1[:,-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06mJ_xDF-LcZ",
        "outputId": "a6785806-ac70-4215-f4bb-272b4892374b"
      },
      "source": [
        "print(A.shape , B.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1599, 12) (1599,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bu_ifc_t-PIg"
      },
      "source": [
        "min = A.min(axis = 0) \n",
        "max = A.max(axis = 0) \n",
        "A = (A - min) / (max - min)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjJvOlUx-SpI"
      },
      "source": [
        "import random\n",
        "np.random.shuffle(A)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kfk0Zwvu-WPk",
        "outputId": "7fec171e-585f-4364-820a-431aaae77b58"
      },
      "source": [
        "index_30percent = int(0.3 * len(X[:, 0]))\n",
        "print(index_30percent)\n",
        "AVALID = A[:index_30percent, ]\n",
        "BVALID = A[:index_30percent, -1]\n",
        "ATRAIN = A[index_30percent:, ]\n",
        "BTRAIN = A[index_30percent:, -1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "479\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xkFsNymCd_2",
        "outputId": "4bf5176e-80c6-49fe-d622-e2439060f2b4"
      },
      "source": [
        "print(ATRAIN.shape , BVALID.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1120, 12) (479,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDcsIvYG-6my",
        "outputId": "a4098986-aca4-4633-a312-4178162dcfae"
      },
      "source": [
        "print(ATRAIN)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.60  0.16  0.69 ...  0.17  0.12  1.00]\n",
            " [ 0.27  0.43  0.27 ...  0.07  0.14  0.00]\n",
            " [ 0.25  0.29  0.19 ...  0.21  0.32  0.00]\n",
            " ...\n",
            " [ 0.25  0.27  0.13 ...  0.16  0.37  1.00]\n",
            " [ 0.47  0.22  0.46 ...  0.22  0.54  1.00]\n",
            " [ 0.15  0.59  0.01 ...  0.08  0.43  1.00]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oRig5UF_PaR"
      },
      "source": [
        "model_o = Sequential()\n",
        "model_o.add(Dense(1, input_dim = len(ATRAIN[0, :]), activation='sigmoid'))\n",
        "model_o.compile(loss='binary_crossentropy', optimizer = 'rmsprop', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_esMS-1z_Xs1",
        "outputId": "5b9f20fa-7fd8-4231-d69a-d03e68d14da5"
      },
      "source": [
        "history_o = model_o.fit(ATRAIN, BTRAIN, validation_data=(AVALID, BVALID), epochs = 300, batch_size=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "112/112 [==============================] - 1s 3ms/step - loss: 0.8556 - accuracy: 0.1507 - val_loss: 0.8128 - val_accuracy: 0.1503\n",
            "Epoch 2/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.8143 - accuracy: 0.1629 - val_loss: 0.7748 - val_accuracy: 0.2944\n",
            "Epoch 3/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.7813 - accuracy: 0.2704 - val_loss: 0.7416 - val_accuracy: 0.3946\n",
            "Epoch 4/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.7474 - accuracy: 0.4049 - val_loss: 0.7097 - val_accuracy: 0.4885\n",
            "Epoch 5/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.7051 - accuracy: 0.4996 - val_loss: 0.6792 - val_accuracy: 0.5595\n",
            "Epoch 6/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6824 - accuracy: 0.5364 - val_loss: 0.6499 - val_accuracy: 0.6305\n",
            "Epoch 7/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6490 - accuracy: 0.6238 - val_loss: 0.6221 - val_accuracy: 0.6994\n",
            "Epoch 8/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6286 - accuracy: 0.6864 - val_loss: 0.5945 - val_accuracy: 0.7620\n",
            "Epoch 9/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6012 - accuracy: 0.7336 - val_loss: 0.5678 - val_accuracy: 0.7996\n",
            "Epoch 10/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5644 - accuracy: 0.8019 - val_loss: 0.5421 - val_accuracy: 0.8622\n",
            "Epoch 11/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5479 - accuracy: 0.8343 - val_loss: 0.5177 - val_accuracy: 0.8956\n",
            "Epoch 12/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.5293 - accuracy: 0.8919 - val_loss: 0.4942 - val_accuracy: 0.9207\n",
            "Epoch 13/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4888 - accuracy: 0.9326 - val_loss: 0.4712 - val_accuracy: 0.9436\n",
            "Epoch 14/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.9456 - val_loss: 0.4493 - val_accuracy: 0.9645\n",
            "Epoch 15/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.9607 - val_loss: 0.4292 - val_accuracy: 0.9729\n",
            "Epoch 16/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.9705 - val_loss: 0.4091 - val_accuracy: 0.9791\n",
            "Epoch 17/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.4084 - accuracy: 0.9765 - val_loss: 0.3902 - val_accuracy: 0.9833\n",
            "Epoch 18/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.3875 - accuracy: 0.9882 - val_loss: 0.3719 - val_accuracy: 0.9875\n",
            "Epoch 19/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.3741 - accuracy: 0.9876 - val_loss: 0.3545 - val_accuracy: 0.9875\n",
            "Epoch 20/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.3547 - accuracy: 0.9877 - val_loss: 0.3375 - val_accuracy: 0.9916\n",
            "Epoch 21/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.3389 - accuracy: 0.9943 - val_loss: 0.3213 - val_accuracy: 0.9937\n",
            "Epoch 22/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.3212 - accuracy: 0.9985 - val_loss: 0.3063 - val_accuracy: 0.9937\n",
            "Epoch 23/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.3040 - accuracy: 0.9979 - val_loss: 0.2920 - val_accuracy: 0.9958\n",
            "Epoch 24/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.2967 - accuracy: 0.9963 - val_loss: 0.2783 - val_accuracy: 1.0000\n",
            "Epoch 25/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.2784 - accuracy: 0.9979 - val_loss: 0.2653 - val_accuracy: 1.0000\n",
            "Epoch 26/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.2687 - accuracy: 1.0000 - val_loss: 0.2528 - val_accuracy: 1.0000\n",
            "Epoch 27/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.2585 - accuracy: 1.0000 - val_loss: 0.2408 - val_accuracy: 1.0000\n",
            "Epoch 28/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 1.0000 - val_loss: 0.2294 - val_accuracy: 1.0000\n",
            "Epoch 29/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.2312 - accuracy: 1.0000 - val_loss: 0.2182 - val_accuracy: 1.0000\n",
            "Epoch 30/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.2204 - accuracy: 1.0000 - val_loss: 0.2077 - val_accuracy: 1.0000\n",
            "Epoch 31/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.2101 - accuracy: 1.0000 - val_loss: 0.1977 - val_accuracy: 1.0000\n",
            "Epoch 32/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.1990 - accuracy: 1.0000 - val_loss: 0.1882 - val_accuracy: 1.0000\n",
            "Epoch 33/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.1942 - accuracy: 1.0000 - val_loss: 0.1792 - val_accuracy: 1.0000\n",
            "Epoch 34/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.1804 - accuracy: 1.0000 - val_loss: 0.1705 - val_accuracy: 1.0000\n",
            "Epoch 35/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.1674 - accuracy: 1.0000 - val_loss: 0.1623 - val_accuracy: 1.0000\n",
            "Epoch 36/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.1663 - accuracy: 1.0000 - val_loss: 0.1545 - val_accuracy: 1.0000\n",
            "Epoch 37/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.1572 - accuracy: 1.0000 - val_loss: 0.1471 - val_accuracy: 1.0000\n",
            "Epoch 38/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.1472 - accuracy: 1.0000 - val_loss: 0.1399 - val_accuracy: 1.0000\n",
            "Epoch 39/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.1443 - accuracy: 1.0000 - val_loss: 0.1332 - val_accuracy: 1.0000\n",
            "Epoch 40/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.1326 - accuracy: 1.0000 - val_loss: 0.1269 - val_accuracy: 1.0000\n",
            "Epoch 41/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.1313 - accuracy: 1.0000 - val_loss: 0.1209 - val_accuracy: 1.0000\n",
            "Epoch 42/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.1197 - accuracy: 1.0000 - val_loss: 0.1148 - val_accuracy: 1.0000\n",
            "Epoch 43/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.1138 - accuracy: 1.0000 - val_loss: 0.1094 - val_accuracy: 1.0000\n",
            "Epoch 44/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.1119 - accuracy: 1.0000 - val_loss: 0.1041 - val_accuracy: 1.0000\n",
            "Epoch 45/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.1058 - accuracy: 1.0000 - val_loss: 0.0992 - val_accuracy: 1.0000\n",
            "Epoch 46/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0971 - accuracy: 1.0000 - val_loss: 0.0943 - val_accuracy: 1.0000\n",
            "Epoch 47/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0930 - accuracy: 1.0000 - val_loss: 0.0897 - val_accuracy: 1.0000\n",
            "Epoch 48/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0895 - accuracy: 1.0000 - val_loss: 0.0853 - val_accuracy: 1.0000\n",
            "Epoch 49/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0845 - accuracy: 1.0000 - val_loss: 0.0811 - val_accuracy: 1.0000\n",
            "Epoch 50/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0800 - accuracy: 1.0000 - val_loss: 0.0771 - val_accuracy: 1.0000\n",
            "Epoch 51/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0779 - accuracy: 1.0000 - val_loss: 0.0734 - val_accuracy: 1.0000\n",
            "Epoch 52/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0748 - accuracy: 1.0000 - val_loss: 0.0699 - val_accuracy: 1.0000\n",
            "Epoch 53/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0703 - accuracy: 1.0000 - val_loss: 0.0664 - val_accuracy: 1.0000\n",
            "Epoch 54/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0657 - accuracy: 1.0000 - val_loss: 0.0632 - val_accuracy: 1.0000\n",
            "Epoch 55/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0633 - accuracy: 1.0000 - val_loss: 0.0601 - val_accuracy: 1.0000\n",
            "Epoch 56/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0609 - accuracy: 1.0000 - val_loss: 0.0572 - val_accuracy: 1.0000\n",
            "Epoch 57/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0558 - accuracy: 1.0000 - val_loss: 0.0544 - val_accuracy: 1.0000\n",
            "Epoch 58/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0535 - accuracy: 1.0000 - val_loss: 0.0518 - val_accuracy: 1.0000\n",
            "Epoch 59/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0512 - accuracy: 1.0000 - val_loss: 0.0493 - val_accuracy: 1.0000\n",
            "Epoch 60/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0482 - accuracy: 1.0000 - val_loss: 0.0469 - val_accuracy: 1.0000\n",
            "Epoch 61/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0469 - accuracy: 1.0000 - val_loss: 0.0447 - val_accuracy: 1.0000\n",
            "Epoch 62/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0446 - accuracy: 1.0000 - val_loss: 0.0425 - val_accuracy: 1.0000\n",
            "Epoch 63/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0423 - accuracy: 1.0000 - val_loss: 0.0404 - val_accuracy: 1.0000\n",
            "Epoch 64/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0410 - accuracy: 1.0000 - val_loss: 0.0385 - val_accuracy: 1.0000\n",
            "Epoch 65/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0379 - accuracy: 1.0000 - val_loss: 0.0366 - val_accuracy: 1.0000\n",
            "Epoch 66/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0365 - accuracy: 1.0000 - val_loss: 0.0348 - val_accuracy: 1.0000\n",
            "Epoch 67/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0344 - accuracy: 1.0000 - val_loss: 0.0331 - val_accuracy: 1.0000\n",
            "Epoch 68/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0329 - accuracy: 1.0000 - val_loss: 0.0315 - val_accuracy: 1.0000\n",
            "Epoch 69/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0306 - accuracy: 1.0000 - val_loss: 0.0300 - val_accuracy: 1.0000\n",
            "Epoch 70/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0299 - accuracy: 1.0000 - val_loss: 0.0286 - val_accuracy: 1.0000\n",
            "Epoch 71/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0288 - accuracy: 1.0000 - val_loss: 0.0271 - val_accuracy: 1.0000\n",
            "Epoch 72/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0280 - accuracy: 1.0000 - val_loss: 0.0258 - val_accuracy: 1.0000\n",
            "Epoch 73/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0258 - accuracy: 1.0000 - val_loss: 0.0246 - val_accuracy: 1.0000\n",
            "Epoch 74/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0235 - accuracy: 1.0000 - val_loss: 0.0233 - val_accuracy: 1.0000\n",
            "Epoch 75/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0237 - accuracy: 1.0000 - val_loss: 0.0222 - val_accuracy: 1.0000\n",
            "Epoch 76/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0226 - accuracy: 1.0000 - val_loss: 0.0212 - val_accuracy: 1.0000\n",
            "Epoch 77/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 0.0201 - val_accuracy: 1.0000\n",
            "Epoch 78/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 0.0191 - val_accuracy: 1.0000\n",
            "Epoch 79/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.0182 - val_accuracy: 1.0000\n",
            "Epoch 80/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0187 - accuracy: 1.0000 - val_loss: 0.0173 - val_accuracy: 1.0000\n",
            "Epoch 81/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 0.0165 - val_accuracy: 1.0000\n",
            "Epoch 82/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 0.0157 - val_accuracy: 1.0000\n",
            "Epoch 83/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.0149 - val_accuracy: 1.0000\n",
            "Epoch 84/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.0142 - val_accuracy: 1.0000\n",
            "Epoch 85/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 1.0000\n",
            "Epoch 86/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 1.0000\n",
            "Epoch 87/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 1.0000\n",
            "Epoch 88/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 1.0000\n",
            "Epoch 89/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 1.0000\n",
            "Epoch 90/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.0105 - val_accuracy: 1.0000\n",
            "Epoch 91/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.0100 - val_accuracy: 1.0000\n",
            "Epoch 92/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.0095 - val_accuracy: 1.0000\n",
            "Epoch 93/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.0091 - val_accuracy: 1.0000\n",
            "Epoch 94/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.0086 - val_accuracy: 1.0000\n",
            "Epoch 95/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.0082 - val_accuracy: 1.0000\n",
            "Epoch 96/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
            "Epoch 97/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
            "Epoch 98/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
            "Epoch 99/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
            "Epoch 100/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
            "Epoch 101/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
            "Epoch 102/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
            "Epoch 103/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
            "Epoch 104/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
            "Epoch 105/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
            "Epoch 106/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
            "Epoch 107/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
            "Epoch 108/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
            "Epoch 109/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
            "Epoch 110/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
            "Epoch 111/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
            "Epoch 112/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
            "Epoch 113/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
            "Epoch 114/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
            "Epoch 115/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
            "Epoch 116/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 117/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Epoch 118/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 119/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 120/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 121/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 122/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 123/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 124/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 125/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 126/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 127/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 128/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 129/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 130/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 131/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 132/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 133/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 134/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 135/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 136/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 137/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 138/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 9.9988e-04 - val_accuracy: 1.0000\n",
            "Epoch 139/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 9.7032e-04 - accuracy: 1.0000 - val_loss: 9.5253e-04 - val_accuracy: 1.0000\n",
            "Epoch 140/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 9.3491e-04 - accuracy: 1.0000 - val_loss: 9.0714e-04 - val_accuracy: 1.0000\n",
            "Epoch 141/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 8.5666e-04 - accuracy: 1.0000 - val_loss: 8.6484e-04 - val_accuracy: 1.0000\n",
            "Epoch 142/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 8.3469e-04 - accuracy: 1.0000 - val_loss: 8.2475e-04 - val_accuracy: 1.0000\n",
            "Epoch 143/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 8.3662e-04 - accuracy: 1.0000 - val_loss: 7.8623e-04 - val_accuracy: 1.0000\n",
            "Epoch 144/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 7.6325e-04 - accuracy: 1.0000 - val_loss: 7.4854e-04 - val_accuracy: 1.0000\n",
            "Epoch 145/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 7.2398e-04 - accuracy: 1.0000 - val_loss: 7.1400e-04 - val_accuracy: 1.0000\n",
            "Epoch 146/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 7.1874e-04 - accuracy: 1.0000 - val_loss: 6.8130e-04 - val_accuracy: 1.0000\n",
            "Epoch 147/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 6.7309e-04 - accuracy: 1.0000 - val_loss: 6.4948e-04 - val_accuracy: 1.0000\n",
            "Epoch 148/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 6.4480e-04 - accuracy: 1.0000 - val_loss: 6.1920e-04 - val_accuracy: 1.0000\n",
            "Epoch 149/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 5.8541e-04 - accuracy: 1.0000 - val_loss: 5.9082e-04 - val_accuracy: 1.0000\n",
            "Epoch 150/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 5.6375e-04 - accuracy: 1.0000 - val_loss: 5.6255e-04 - val_accuracy: 1.0000\n",
            "Epoch 151/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 5.6995e-04 - accuracy: 1.0000 - val_loss: 5.3630e-04 - val_accuracy: 1.0000\n",
            "Epoch 152/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 5.2745e-04 - accuracy: 1.0000 - val_loss: 5.1140e-04 - val_accuracy: 1.0000\n",
            "Epoch 153/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 4.9846e-04 - accuracy: 1.0000 - val_loss: 4.8741e-04 - val_accuracy: 1.0000\n",
            "Epoch 154/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 4.8656e-04 - accuracy: 1.0000 - val_loss: 4.6463e-04 - val_accuracy: 1.0000\n",
            "Epoch 155/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 4.7896e-04 - accuracy: 1.0000 - val_loss: 4.4292e-04 - val_accuracy: 1.0000\n",
            "Epoch 156/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 4.3729e-04 - accuracy: 1.0000 - val_loss: 4.2256e-04 - val_accuracy: 1.0000\n",
            "Epoch 157/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 4.0811e-04 - accuracy: 1.0000 - val_loss: 4.0347e-04 - val_accuracy: 1.0000\n",
            "Epoch 158/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 3.9590e-04 - accuracy: 1.0000 - val_loss: 3.8447e-04 - val_accuracy: 1.0000\n",
            "Epoch 159/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 3.7861e-04 - accuracy: 1.0000 - val_loss: 3.6674e-04 - val_accuracy: 1.0000\n",
            "Epoch 160/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 3.5778e-04 - accuracy: 1.0000 - val_loss: 3.4961e-04 - val_accuracy: 1.0000\n",
            "Epoch 161/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 3.2670e-04 - accuracy: 1.0000 - val_loss: 3.3330e-04 - val_accuracy: 1.0000\n",
            "Epoch 162/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 3.2811e-04 - accuracy: 1.0000 - val_loss: 3.1842e-04 - val_accuracy: 1.0000\n",
            "Epoch 163/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 3.1635e-04 - accuracy: 1.0000 - val_loss: 3.0363e-04 - val_accuracy: 1.0000\n",
            "Epoch 164/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 3.0018e-04 - accuracy: 1.0000 - val_loss: 2.8985e-04 - val_accuracy: 1.0000\n",
            "Epoch 165/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 2.8835e-04 - accuracy: 1.0000 - val_loss: 2.7643e-04 - val_accuracy: 1.0000\n",
            "Epoch 166/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 2.6854e-04 - accuracy: 1.0000 - val_loss: 2.6328e-04 - val_accuracy: 1.0000\n",
            "Epoch 167/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 2.4409e-04 - accuracy: 1.0000 - val_loss: 2.5124e-04 - val_accuracy: 1.0000\n",
            "Epoch 168/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 2.5474e-04 - accuracy: 1.0000 - val_loss: 2.3966e-04 - val_accuracy: 1.0000\n",
            "Epoch 169/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 2.3584e-04 - accuracy: 1.0000 - val_loss: 2.2863e-04 - val_accuracy: 1.0000\n",
            "Epoch 170/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 2.0845e-04 - accuracy: 1.0000 - val_loss: 2.1816e-04 - val_accuracy: 1.0000\n",
            "Epoch 171/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 2.1254e-04 - accuracy: 1.0000 - val_loss: 2.0834e-04 - val_accuracy: 1.0000\n",
            "Epoch 172/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 2.0630e-04 - accuracy: 1.0000 - val_loss: 1.9868e-04 - val_accuracy: 1.0000\n",
            "Epoch 173/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 1.8781e-04 - accuracy: 1.0000 - val_loss: 1.8974e-04 - val_accuracy: 1.0000\n",
            "Epoch 174/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 1.9086e-04 - accuracy: 1.0000 - val_loss: 1.8110e-04 - val_accuracy: 1.0000\n",
            "Epoch 175/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 1.7321e-04 - accuracy: 1.0000 - val_loss: 1.7269e-04 - val_accuracy: 1.0000\n",
            "Epoch 176/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 1.6149e-04 - accuracy: 1.0000 - val_loss: 1.6471e-04 - val_accuracy: 1.0000\n",
            "Epoch 177/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 1.5424e-04 - accuracy: 1.0000 - val_loss: 1.5746e-04 - val_accuracy: 1.0000\n",
            "Epoch 178/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 1.4392e-04 - accuracy: 1.0000 - val_loss: 1.4996e-04 - val_accuracy: 1.0000\n",
            "Epoch 179/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 1.4549e-04 - accuracy: 1.0000 - val_loss: 1.4302e-04 - val_accuracy: 1.0000\n",
            "Epoch 180/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 1.3889e-04 - accuracy: 1.0000 - val_loss: 1.3660e-04 - val_accuracy: 1.0000\n",
            "Epoch 181/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 1.3277e-04 - accuracy: 1.0000 - val_loss: 1.3031e-04 - val_accuracy: 1.0000\n",
            "Epoch 182/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 1.2618e-04 - accuracy: 1.0000 - val_loss: 1.2444e-04 - val_accuracy: 1.0000\n",
            "Epoch 183/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 1.2294e-04 - accuracy: 1.0000 - val_loss: 1.1875e-04 - val_accuracy: 1.0000\n",
            "Epoch 184/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 1.1573e-04 - accuracy: 1.0000 - val_loss: 1.1331e-04 - val_accuracy: 1.0000\n",
            "Epoch 185/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 1.0779e-04 - accuracy: 1.0000 - val_loss: 1.0798e-04 - val_accuracy: 1.0000\n",
            "Epoch 186/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 1.0361e-04 - accuracy: 1.0000 - val_loss: 1.0312e-04 - val_accuracy: 1.0000\n",
            "Epoch 187/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 9.8223e-05 - accuracy: 1.0000 - val_loss: 9.8436e-05 - val_accuracy: 1.0000\n",
            "Epoch 188/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 9.4691e-05 - accuracy: 1.0000 - val_loss: 9.3987e-05 - val_accuracy: 1.0000\n",
            "Epoch 189/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 8.8277e-05 - accuracy: 1.0000 - val_loss: 8.9724e-05 - val_accuracy: 1.0000\n",
            "Epoch 190/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 8.4423e-05 - accuracy: 1.0000 - val_loss: 8.5680e-05 - val_accuracy: 1.0000\n",
            "Epoch 191/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 8.7217e-05 - accuracy: 1.0000 - val_loss: 8.1715e-05 - val_accuracy: 1.0000\n",
            "Epoch 192/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 7.5350e-05 - accuracy: 1.0000 - val_loss: 7.8005e-05 - val_accuracy: 1.0000\n",
            "Epoch 193/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 7.4893e-05 - accuracy: 1.0000 - val_loss: 7.4482e-05 - val_accuracy: 1.0000\n",
            "Epoch 194/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 6.9763e-05 - accuracy: 1.0000 - val_loss: 7.1076e-05 - val_accuracy: 1.0000\n",
            "Epoch 195/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 6.8041e-05 - accuracy: 1.0000 - val_loss: 6.7859e-05 - val_accuracy: 1.0000\n",
            "Epoch 196/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 6.7075e-05 - accuracy: 1.0000 - val_loss: 6.4767e-05 - val_accuracy: 1.0000\n",
            "Epoch 197/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 6.3932e-05 - accuracy: 1.0000 - val_loss: 6.1855e-05 - val_accuracy: 1.0000\n",
            "Epoch 198/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 6.2088e-05 - accuracy: 1.0000 - val_loss: 5.9024e-05 - val_accuracy: 1.0000\n",
            "Epoch 199/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 5.7371e-05 - accuracy: 1.0000 - val_loss: 5.6322e-05 - val_accuracy: 1.0000\n",
            "Epoch 200/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 5.5033e-05 - accuracy: 1.0000 - val_loss: 5.3916e-05 - val_accuracy: 1.0000\n",
            "Epoch 201/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 5.4665e-05 - accuracy: 1.0000 - val_loss: 5.1449e-05 - val_accuracy: 1.0000\n",
            "Epoch 202/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 4.9932e-05 - accuracy: 1.0000 - val_loss: 4.9114e-05 - val_accuracy: 1.0000\n",
            "Epoch 203/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 4.7663e-05 - accuracy: 1.0000 - val_loss: 4.6898e-05 - val_accuracy: 1.0000\n",
            "Epoch 204/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 4.7881e-05 - accuracy: 1.0000 - val_loss: 4.4795e-05 - val_accuracy: 1.0000\n",
            "Epoch 205/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 4.3650e-05 - accuracy: 1.0000 - val_loss: 4.2851e-05 - val_accuracy: 1.0000\n",
            "Epoch 206/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 3.7990e-05 - accuracy: 1.0000 - val_loss: 4.0911e-05 - val_accuracy: 1.0000\n",
            "Epoch 207/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 3.7703e-05 - accuracy: 1.0000 - val_loss: 3.9072e-05 - val_accuracy: 1.0000\n",
            "Epoch 208/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 3.7323e-05 - accuracy: 1.0000 - val_loss: 3.7309e-05 - val_accuracy: 1.0000\n",
            "Epoch 209/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 3.6709e-05 - accuracy: 1.0000 - val_loss: 3.5643e-05 - val_accuracy: 1.0000\n",
            "Epoch 210/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 3.6608e-05 - accuracy: 1.0000 - val_loss: 3.3995e-05 - val_accuracy: 1.0000\n",
            "Epoch 211/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 3.1615e-05 - accuracy: 1.0000 - val_loss: 3.2462e-05 - val_accuracy: 1.0000\n",
            "Epoch 212/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 3.1525e-05 - accuracy: 1.0000 - val_loss: 3.0988e-05 - val_accuracy: 1.0000\n",
            "Epoch 213/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 2.9240e-05 - accuracy: 1.0000 - val_loss: 2.9632e-05 - val_accuracy: 1.0000\n",
            "Epoch 214/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 2.9303e-05 - accuracy: 1.0000 - val_loss: 2.8317e-05 - val_accuracy: 1.0000\n",
            "Epoch 215/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 2.7820e-05 - accuracy: 1.0000 - val_loss: 2.7045e-05 - val_accuracy: 1.0000\n",
            "Epoch 216/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 2.7043e-05 - accuracy: 1.0000 - val_loss: 2.5810e-05 - val_accuracy: 1.0000\n",
            "Epoch 217/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 2.3390e-05 - accuracy: 1.0000 - val_loss: 2.4643e-05 - val_accuracy: 1.0000\n",
            "Epoch 218/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 2.4396e-05 - accuracy: 1.0000 - val_loss: 2.3557e-05 - val_accuracy: 1.0000\n",
            "Epoch 219/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 2.2979e-05 - accuracy: 1.0000 - val_loss: 2.2497e-05 - val_accuracy: 1.0000\n",
            "Epoch 220/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 2.1600e-05 - accuracy: 1.0000 - val_loss: 2.1539e-05 - val_accuracy: 1.0000\n",
            "Epoch 221/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 2.2456e-05 - accuracy: 1.0000 - val_loss: 2.0589e-05 - val_accuracy: 1.0000\n",
            "Epoch 222/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 2.0017e-05 - accuracy: 1.0000 - val_loss: 1.9695e-05 - val_accuracy: 1.0000\n",
            "Epoch 223/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 1.9276e-05 - accuracy: 1.0000 - val_loss: 1.8805e-05 - val_accuracy: 1.0000\n",
            "Epoch 224/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 1.8212e-05 - accuracy: 1.0000 - val_loss: 1.7953e-05 - val_accuracy: 1.0000\n",
            "Epoch 225/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 1.6885e-05 - accuracy: 1.0000 - val_loss: 1.7173e-05 - val_accuracy: 1.0000\n",
            "Epoch 226/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 1.7071e-05 - accuracy: 1.0000 - val_loss: 1.6412e-05 - val_accuracy: 1.0000\n",
            "Epoch 227/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 1.6777e-05 - accuracy: 1.0000 - val_loss: 1.5673e-05 - val_accuracy: 1.0000\n",
            "Epoch 228/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 1.5094e-05 - accuracy: 1.0000 - val_loss: 1.4992e-05 - val_accuracy: 1.0000\n",
            "Epoch 229/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 1.4190e-05 - accuracy: 1.0000 - val_loss: 1.4341e-05 - val_accuracy: 1.0000\n",
            "Epoch 230/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 1.4074e-05 - accuracy: 1.0000 - val_loss: 1.3720e-05 - val_accuracy: 1.0000\n",
            "Epoch 231/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 1.3219e-05 - accuracy: 1.0000 - val_loss: 1.3116e-05 - val_accuracy: 1.0000\n",
            "Epoch 232/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 1.2616e-05 - accuracy: 1.0000 - val_loss: 1.2541e-05 - val_accuracy: 1.0000\n",
            "Epoch 233/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 1.1195e-05 - accuracy: 1.0000 - val_loss: 1.2012e-05 - val_accuracy: 1.0000\n",
            "Epoch 234/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 1.1012e-05 - accuracy: 1.0000 - val_loss: 1.1481e-05 - val_accuracy: 1.0000\n",
            "Epoch 235/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 1.0849e-05 - accuracy: 1.0000 - val_loss: 1.0990e-05 - val_accuracy: 1.0000\n",
            "Epoch 236/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 1.0987e-05 - accuracy: 1.0000 - val_loss: 1.0506e-05 - val_accuracy: 1.0000\n",
            "Epoch 237/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 9.9336e-06 - accuracy: 1.0000 - val_loss: 1.0034e-05 - val_accuracy: 1.0000\n",
            "Epoch 238/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 1.0278e-05 - accuracy: 1.0000 - val_loss: 9.6153e-06 - val_accuracy: 1.0000\n",
            "Epoch 239/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 8.7648e-06 - accuracy: 1.0000 - val_loss: 9.1965e-06 - val_accuracy: 1.0000\n",
            "Epoch 240/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 8.9718e-06 - accuracy: 1.0000 - val_loss: 8.8065e-06 - val_accuracy: 1.0000\n",
            "Epoch 241/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 8.0934e-06 - accuracy: 1.0000 - val_loss: 8.4333e-06 - val_accuracy: 1.0000\n",
            "Epoch 242/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 7.4443e-06 - accuracy: 1.0000 - val_loss: 8.0555e-06 - val_accuracy: 1.0000\n",
            "Epoch 243/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 8.0412e-06 - accuracy: 1.0000 - val_loss: 7.7123e-06 - val_accuracy: 1.0000\n",
            "Epoch 244/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 7.6760e-06 - accuracy: 1.0000 - val_loss: 7.3917e-06 - val_accuracy: 1.0000\n",
            "Epoch 245/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 7.1900e-06 - accuracy: 1.0000 - val_loss: 7.0809e-06 - val_accuracy: 1.0000\n",
            "Epoch 246/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 6.9633e-06 - accuracy: 1.0000 - val_loss: 6.7687e-06 - val_accuracy: 1.0000\n",
            "Epoch 247/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 7.2137e-06 - accuracy: 1.0000 - val_loss: 6.4867e-06 - val_accuracy: 1.0000\n",
            "Epoch 248/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 5.8091e-06 - accuracy: 1.0000 - val_loss: 6.2099e-06 - val_accuracy: 1.0000\n",
            "Epoch 249/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 5.8754e-06 - accuracy: 1.0000 - val_loss: 5.9489e-06 - val_accuracy: 1.0000\n",
            "Epoch 250/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 5.6008e-06 - accuracy: 1.0000 - val_loss: 5.6856e-06 - val_accuracy: 1.0000\n",
            "Epoch 251/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 5.6248e-06 - accuracy: 1.0000 - val_loss: 5.4386e-06 - val_accuracy: 1.0000\n",
            "Epoch 252/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 4.9567e-06 - accuracy: 1.0000 - val_loss: 5.2158e-06 - val_accuracy: 1.0000\n",
            "Epoch 253/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 4.7946e-06 - accuracy: 1.0000 - val_loss: 4.9897e-06 - val_accuracy: 1.0000\n",
            "Epoch 254/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 4.7845e-06 - accuracy: 1.0000 - val_loss: 4.7841e-06 - val_accuracy: 1.0000\n",
            "Epoch 255/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 4.6029e-06 - accuracy: 1.0000 - val_loss: 4.5760e-06 - val_accuracy: 1.0000\n",
            "Epoch 256/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 4.3022e-06 - accuracy: 1.0000 - val_loss: 4.3871e-06 - val_accuracy: 1.0000\n",
            "Epoch 257/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 4.0562e-06 - accuracy: 1.0000 - val_loss: 4.2033e-06 - val_accuracy: 1.0000\n",
            "Epoch 258/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 3.9846e-06 - accuracy: 1.0000 - val_loss: 4.0215e-06 - val_accuracy: 1.0000\n",
            "Epoch 259/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 3.7481e-06 - accuracy: 1.0000 - val_loss: 3.8588e-06 - val_accuracy: 1.0000\n",
            "Epoch 260/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 3.7560e-06 - accuracy: 1.0000 - val_loss: 3.6963e-06 - val_accuracy: 1.0000\n",
            "Epoch 261/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 3.6756e-06 - accuracy: 1.0000 - val_loss: 3.5407e-06 - val_accuracy: 1.0000\n",
            "Epoch 262/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 3.2183e-06 - accuracy: 1.0000 - val_loss: 3.3975e-06 - val_accuracy: 1.0000\n",
            "Epoch 263/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 3.3856e-06 - accuracy: 1.0000 - val_loss: 3.2636e-06 - val_accuracy: 1.0000\n",
            "Epoch 264/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 3.0785e-06 - accuracy: 1.0000 - val_loss: 3.1308e-06 - val_accuracy: 1.0000\n",
            "Epoch 265/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 2.9715e-06 - accuracy: 1.0000 - val_loss: 3.0031e-06 - val_accuracy: 1.0000\n",
            "Epoch 266/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 2.8391e-06 - accuracy: 1.0000 - val_loss: 2.8799e-06 - val_accuracy: 1.0000\n",
            "Epoch 267/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 2.6139e-06 - accuracy: 1.0000 - val_loss: 2.7597e-06 - val_accuracy: 1.0000\n",
            "Epoch 268/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 2.7289e-06 - accuracy: 1.0000 - val_loss: 2.6482e-06 - val_accuracy: 1.0000\n",
            "Epoch 269/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 2.4673e-06 - accuracy: 1.0000 - val_loss: 2.5419e-06 - val_accuracy: 1.0000\n",
            "Epoch 270/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 2.4624e-06 - accuracy: 1.0000 - val_loss: 2.4415e-06 - val_accuracy: 1.0000\n",
            "Epoch 271/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 2.3247e-06 - accuracy: 1.0000 - val_loss: 2.3412e-06 - val_accuracy: 1.0000\n",
            "Epoch 272/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 2.1150e-06 - accuracy: 1.0000 - val_loss: 2.2464e-06 - val_accuracy: 1.0000\n",
            "Epoch 273/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 2.2741e-06 - accuracy: 1.0000 - val_loss: 2.1553e-06 - val_accuracy: 1.0000\n",
            "Epoch 274/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 2.1591e-06 - accuracy: 1.0000 - val_loss: 2.0708e-06 - val_accuracy: 1.0000\n",
            "Epoch 275/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 2.0220e-06 - accuracy: 1.0000 - val_loss: 1.9858e-06 - val_accuracy: 1.0000\n",
            "Epoch 276/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 1.9308e-06 - accuracy: 1.0000 - val_loss: 1.9095e-06 - val_accuracy: 1.0000\n",
            "Epoch 277/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 1.7770e-06 - accuracy: 1.0000 - val_loss: 1.8352e-06 - val_accuracy: 1.0000\n",
            "Epoch 278/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 1.7633e-06 - accuracy: 1.0000 - val_loss: 1.7676e-06 - val_accuracy: 1.0000\n",
            "Epoch 279/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 1.6595e-06 - accuracy: 1.0000 - val_loss: 1.6992e-06 - val_accuracy: 1.0000\n",
            "Epoch 280/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 1.5853e-06 - accuracy: 1.0000 - val_loss: 1.6329e-06 - val_accuracy: 1.0000\n",
            "Epoch 281/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 1.5154e-06 - accuracy: 1.0000 - val_loss: 1.5709e-06 - val_accuracy: 1.0000\n",
            "Epoch 282/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 1.4101e-06 - accuracy: 1.0000 - val_loss: 1.5101e-06 - val_accuracy: 1.0000\n",
            "Epoch 283/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 1.4185e-06 - accuracy: 1.0000 - val_loss: 1.4534e-06 - val_accuracy: 1.0000\n",
            "Epoch 284/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 1.3764e-06 - accuracy: 1.0000 - val_loss: 1.3977e-06 - val_accuracy: 1.0000\n",
            "Epoch 285/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 1.3720e-06 - accuracy: 1.0000 - val_loss: 1.3441e-06 - val_accuracy: 1.0000\n",
            "Epoch 286/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 1.2633e-06 - accuracy: 1.0000 - val_loss: 1.2922e-06 - val_accuracy: 1.0000\n",
            "Epoch 287/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 1.2808e-06 - accuracy: 1.0000 - val_loss: 1.2435e-06 - val_accuracy: 1.0000\n",
            "Epoch 288/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 1.1698e-06 - accuracy: 1.0000 - val_loss: 1.1976e-06 - val_accuracy: 1.0000\n",
            "Epoch 289/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 1.1153e-06 - accuracy: 1.0000 - val_loss: 1.1543e-06 - val_accuracy: 1.0000\n",
            "Epoch 290/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 1.1598e-06 - accuracy: 1.0000 - val_loss: 1.1121e-06 - val_accuracy: 1.0000\n",
            "Epoch 291/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 1.1238e-06 - accuracy: 1.0000 - val_loss: 1.0721e-06 - val_accuracy: 1.0000\n",
            "Epoch 292/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 1.0683e-06 - accuracy: 1.0000 - val_loss: 1.0331e-06 - val_accuracy: 1.0000\n",
            "Epoch 293/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 9.3280e-07 - accuracy: 1.0000 - val_loss: 9.9538e-07 - val_accuracy: 1.0000\n",
            "Epoch 294/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 9.9343e-07 - accuracy: 1.0000 - val_loss: 9.6084e-07 - val_accuracy: 1.0000\n",
            "Epoch 295/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 8.9730e-07 - accuracy: 1.0000 - val_loss: 9.2743e-07 - val_accuracy: 1.0000\n",
            "Epoch 296/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 8.9369e-07 - accuracy: 1.0000 - val_loss: 8.9452e-07 - val_accuracy: 1.0000\n",
            "Epoch 297/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 8.9383e-07 - accuracy: 1.0000 - val_loss: 8.6236e-07 - val_accuracy: 1.0000\n",
            "Epoch 298/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 7.9605e-07 - accuracy: 1.0000 - val_loss: 8.3299e-07 - val_accuracy: 1.0000\n",
            "Epoch 299/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 7.6323e-07 - accuracy: 1.0000 - val_loss: 8.0271e-07 - val_accuracy: 1.0000\n",
            "Epoch 300/300\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 7.6778e-07 - accuracy: 1.0000 - val_loss: 7.7646e-07 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "KaGOBTLG_yMK",
        "outputId": "fd5d71dd-2d9d-4382-a243-572ecdce1850"
      },
      "source": [
        "plt.plot(history_o.history['accuracy'])\n",
        "plt.plot(history_o.history['val_accuracy'])\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training data', 'validation data'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "yC44pWL9_2uM",
        "outputId": "7d75b6c0-fcf3-4f8c-d6dc-7f56f76973b3"
      },
      "source": [
        "plt.plot(history_o.history['loss'])\n",
        "plt.plot(history_o.history['val_loss'])\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training data', 'validation data'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}